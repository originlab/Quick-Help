<h1 class="firstHeading">2.3.1 Algorithm for Attribute Agreement Analysis</h1><p class='urlname' style='display: none'>Algorithm-Attribute-Agreement-Analysis</p>
<div id="toc" class="toc"><div id="toctitle"><h2>Contents</h2></div>
<ul>
<li class="toclevel-1 tocsection-1"><a href="#Assessment_Agreement"><span class="tocnumber">1</span> <span class="toctext">Assessment Agreement</span></a>
<ul>
<li class="toclevel-2 tocsection-2"><a href="#Percent_Agreement"><span class="tocnumber">1.1</span> <span class="toctext">Percent Agreement</span></a></li>
<li class="toclevel-2 tocsection-3"><a href="#Confidence_Intervals_for_Percent_Agreement"><span class="tocnumber">1.2</span> <span class="toctext">Confidence Intervals for Percent Agreement</span></a>
<ul>
<li class="toclevel-3 tocsection-4"><a href="#Lower_Bound"><span class="tocnumber">1.2.1</span> <span class="toctext">Lower Bound</span></a></li>
<li class="toclevel-3 tocsection-5"><a href="#Upper_Bound"><span class="tocnumber">1.2.2</span> <span class="toctext">Upper Bound</span></a></li>
</ul>
</li>
</ul>
</li>
<li class="toclevel-1 tocsection-6"><a href="#Assessment_Disagreement"><span class="tocnumber">2</span> <span class="toctext">Assessment Disagreement</span></a>
<ul>
<li class="toclevel-2 tocsection-7"><a href="#Percent_Disagreement"><span class="tocnumber">2.1</span> <span class="toctext">Percent Disagreement</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-8"><a href="#Fleiss.27_Kappa_Statistics"><span class="tocnumber">3</span> <span class="toctext">Fleiss' Kappa Statistics</span></a>
<ul>
<li class="toclevel-2 tocsection-9"><a href="#Unknown_Standard"><span class="tocnumber">3.1</span> <span class="toctext">Unknown Standard</span></a></li>
<li class="toclevel-2 tocsection-10"><a href="#Known_Standard"><span class="tocnumber">3.2</span> <span class="toctext">Known Standard</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-11"><a href="#Cohen.27s_Kappa_Statistics"><span class="tocnumber">4</span> <span class="toctext">Cohen's Kappa Statistics</span></a>
<ul>
<li class="toclevel-2 tocsection-12"><a href="#Unknown_Standard_2"><span class="tocnumber">4.1</span> <span class="toctext">Unknown Standard</span></a></li>
<li class="toclevel-2 tocsection-13"><a href="#Known_Standard_2"><span class="tocnumber">4.2</span> <span class="toctext">Known Standard</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-14"><a href="#Kendall.27s_Statistics"><span class="tocnumber">5</span> <span class="toctext">Kendall's Statistics</span></a>
<ul>
<li class="toclevel-2 tocsection-15"><a href="#Kendall.27s_Coefficient_of_Concordance"><span class="tocnumber">5.1</span> <span class="toctext">Kendall's Coefficient of Concordance</span></a></li>
<li class="toclevel-2 tocsection-16"><a href="#Testing_Significance_of_Kendall.27s_Coefficient_of_Concordance"><span class="tocnumber">5.2</span> <span class="toctext">Testing Significance of Kendall's Coefficient of Concordance</span></a></li>
<li class="toclevel-2 tocsection-17"><a href="#Kendall.27s_Correlation_Coefficient"><span class="tocnumber">5.3</span> <span class="toctext">Kendall's Correlation Coefficient</span></a></li>
<li class="toclevel-2 tocsection-18"><a href="#Testing_Significance_of_Kendall.27s_Correlation_Coefficient"><span class="tocnumber">5.4</span> <span class="toctext">Testing Significance of Kendall's Correlation Coefficient</span></a></li>
</ul>
</li>
</ul>
</div>

<h2><a name="Assessment_Agreement"></a><span class="mw-headline">Assessment Agreement</span></h2>
<h3><a name="Percent_Agreement"></a><span class="mw-headline">Percent Agreement</span></h3>
<dl><dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-6917c1b76957134ae6252fac3807c73e.png?v=0" title="Percent = 100*m/N" alt="Percent = 100*m/N" class="tex"/></dd></dl>
<p>where
</p>
<dl><dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-843f38405071c44c21ae948cfe82b695.png?v=0" title="m:" alt="m:" class="tex"/> the number of matched ratings.</dd>
<dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-fd8df296232c32c3ac2f6930f1f93bf9.png?v=0" title="N:" alt="N:" class="tex"/> the total number of samples.</dd></dl>
<ul><li> Within Appraisers</li></ul>
<p>It needs each appraiser rates each sample at least twice. The matched event is that all the trials to the same sample for each appraiser are given the same rating. Otherwise, the rating of that sample for the appraiser is not matched. 
</p>
<ul><li> Each Appraiser VS Standard</li></ul>
<p>The standard/attribute for each sample has to be known. The matched event is that all the trials to the same sample for each appraiser are the same with the known standard of this sample. Otherwise, it is not matched.
</p>
<ul><li> Between Appraisers</li></ul>
<p>The matched event is that, to the same sample, all the trials from all appraisers are the same. 
</p>
<ul><li> All Appraisers VS Standard</li></ul>
<p>The standard/attribute for each sample has to be known. The matched event is that, to the same sample, all the trials from all appraisers are the same with the known standard of this sample. 
</p>
<h3><a name="Confidence_Intervals_for_Percent_Agreement"></a><span class="mw-headline">Confidence Intervals for Percent Agreement</span></h3>
<p>Given <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-7b7f9dbfea05c83784f8b85149852f08.png?v=0" title="\alpha" alt="\alpha" class="tex"/>, the confidence intervals (lower bound and upper bound) for the percent agreement are computed as following (if <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-3327f3a691462711db979d98694b9bde.png?v=0" title="\alpha=0.05" alt="\alpha=0.05" class="tex"/>, it is 95% lower bound and upper bound).
</p>
<h4><a name="Lower_Bound"></a><span class="mw-headline">Lower Bound</span></h4>
<dl><dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-7ecc244408b49ec37c89f22a1b15b494.png?v=0" title="LB=\frac{\nu_1F_{\nu_1,\nu_2,\alpha/2}}{\nu_2+\nu_1F_{\nu_1,\nu_2,\alpha/2}}" alt="LB=\frac{\nu_1F_{\nu_1,\nu_2,\alpha/2}}{\nu_2+\nu_1F_{\nu_1,\nu_2,\alpha/2}}" class="tex"/></dd></dl>
<p>where
</p>
<dl><dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-ae4eff5818b916621e6a954ab389ad8d.png?v=0" title="\nu_1=2m" alt="\nu_1=2m" class="tex"/></dd>
<dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-91c02c28430b36afcda36c4cc5fea2d0.png?v=0" title="\nu_2=2(N-m+1)" alt="\nu_2=2(N-m+1)" class="tex"/></dd>
<dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-843f38405071c44c21ae948cfe82b695.png?v=0" title="m:" alt="m:" class="tex"/> the number of matches.</dd>
<dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-fd8df296232c32c3ac2f6930f1f93bf9.png?v=0" title="N:" alt="N:" class="tex"/> the number of samples.</dd>
<dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-9f56b71ac12ce7b3122d69d3a1df1a30.png?v=0" title="F_{\nu_1,\nu_2,\alpha/2}:" alt="F_{\nu_1,\nu_2,\alpha/2}:" class="tex"/> the <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-3254a84b213d2bdd68551c1613af6ef9.png?v=0" title="(100*\alpha/2)^{th}" alt="(100*\alpha/2)^{th}" class="tex"/> percentile of the F distribution with <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-ebfdd136331841a1b59f835c998ca593.png?v=0" title="\nu_1" alt="\nu_1" class="tex"/> and <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-1ff7af9a810bd160a7334c3de425ed9d.png?v=0" title="\nu_2" alt="\nu_2" class="tex"/> degrees of freedom.</dd></dl>
<p>If no agreement, that is <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-ea38dfd69af7dd6caf2127d8489c6cfa.png?v=0" title="Percent=0" alt="Percent=0" class="tex"/>, or <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-e6753e61990bc639ae1869683cb421b7.png?v=0" title="m=0" alt="m=0" class="tex"/>, the lower bound is 0. If perfect agreement, that is <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-193b851a53f6cd06a3c5cf889875a317.png?v=0" title="Percent=100" alt="Percent=100" class="tex"/>, or <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-e4dca0e0acdf6e47c5ce237421ee47e5.png?v=0" title="m=N" alt="m=N" class="tex"/>, <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-7b7f9dbfea05c83784f8b85149852f08.png?v=0" title="\alpha" alt="\alpha" class="tex"/> is used instead of <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-7fd42cc193f8f63db5451c8c6db7d048.png?v=0" title="\alpha/2" alt="\alpha/2" class="tex"/> in the formula.
</p>
<h4><a name="Upper_Bound"></a><span class="mw-headline">Upper Bound</span></h4>
<dl><dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-d87876a712c96f5910de277c320d0a09.png?v=0" title="UB=\frac{\nu_1F_{\nu_1,\nu_2,1-\alpha/2}}{\nu_2+\nu_1F_{\nu_1,\nu_2,1-\alpha/2}}" alt="UB=\frac{\nu_1F_{\nu_1,\nu_2,1-\alpha/2}}{\nu_2+\nu_1F_{\nu_1,\nu_2,1-\alpha/2}}" class="tex"/></dd></dl>
<p>where
</p>
<dl><dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-2d45da15d60f20767aa6000e5cfce06f.png?v=0" title="\nu_1=2(m+1)" alt="\nu_1=2(m+1)" class="tex"/></dd>
<dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-ff07b8cf4211c493c45cbc89deba0068.png?v=0" title="\nu_2=2(N-m)" alt="\nu_2=2(N-m)" class="tex"/></dd>
<dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-843f38405071c44c21ae948cfe82b695.png?v=0" title="m:" alt="m:" class="tex"/> the number of matches.</dd>
<dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-fd8df296232c32c3ac2f6930f1f93bf9.png?v=0" title="N:" alt="N:" class="tex"/> the number of samples.</dd>
<dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-8aeb1ff3b5be3178a15e9ea81cefddf8.png?v=0" title="F_{\nu_1,\nu_2,1-\alpha/2}:" alt="F_{\nu_1,\nu_2,1-\alpha/2}:" class="tex"/> the <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-aba95546a8702b17f8978c4e58ba7b92.png?v=0" title="(100*(1-\alpha/2))^{th}" alt="(100*(1-\alpha/2))^{th}" class="tex"/> percentile of the F distribution with <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-ebfdd136331841a1b59f835c998ca593.png?v=0" title="\nu_1" alt="\nu_1" class="tex"/> and <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-1ff7af9a810bd160a7334c3de425ed9d.png?v=0" title="\nu_2" alt="\nu_2" class="tex"/> degrees of freedom.</dd></dl>
<p>If no agreement, that is <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-ea38dfd69af7dd6caf2127d8489c6cfa.png?v=0" title="Percent=0" alt="Percent=0" class="tex"/>, or <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-e6753e61990bc639ae1869683cb421b7.png?v=0" title="m=0" alt="m=0" class="tex"/>, <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-7b7f9dbfea05c83784f8b85149852f08.png?v=0" title="\alpha" alt="\alpha" class="tex"/> is used instead of <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-7fd42cc193f8f63db5451c8c6db7d048.png?v=0" title="\alpha/2" alt="\alpha/2" class="tex"/> in the formula. If perfect agreement, that is <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-193b851a53f6cd06a3c5cf889875a317.png?v=0" title="Percent=100" alt="Percent=100" class="tex"/>, or <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-e4dca0e0acdf6e47c5ce237421ee47e5.png?v=0" title="m=N" alt="m=N" class="tex"/>, the upper bound is 1.
</p>
<h2><a name="Assessment_Disagreement"></a><span class="mw-headline">Assessment Disagreement</span></h2>
<p>The assessment disagreement is the difference from the known standard ratings. So, the standard/attribute for each sample has to be known.
</p>
<h3><a name="Percent_Disagreement"></a><span class="mw-headline">Percent Disagreement</span></h3>
<dl><dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-69b202369ba8621636c270e698fbe203.png?v=0" title="Percent=100*c/N" alt="Percent=100*c/N" class="tex"/></dd></dl>
<p>where
</p>
<dl><dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-8d6095a666c371a003417bc3edbf2b0f.png?v=0" title="c:" alt="c:" class="tex"/> the number of assessments different from the known standard rating.</dd>
<dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-fd8df296232c32c3ac2f6930f1f93bf9.png?v=0" title="N:" alt="N:" class="tex"/> the total number of trials.</dd></dl>
<p>The percent disagreement indicates the percentage of non-matches in the ratings. The non-matched event is that, for each sample, and each appraiser, if the trial is not rating the same with the known standard of that sample. For each non-matched event, the non-matched count increases by 1.
</p>
<h2><a name="Fleiss.27_Kappa_Statistics"></a><span class="mw-headline">Fleiss' Kappa Statistics</span></h2>
<h3><a name="Unknown_Standard"></a><span class="mw-headline">Unknown Standard</span></h3>
<p>There are two cases for computing the Fleiss' kappa statistics with unknown standard, agreement within each appraiser and agreement between all appraisers.
</p><p>Agreement within each appraiser is to examine the agreement between the trials within each appraiser. so, it needs the number of trials within each appraiser to be greater than 1.
</p><p>Agreement between all appraisers is interested in the agreement of all the appraisers. So, the number of appraisers is assumed to be greater than 1, and then the number of trials within each appraiser can be 1 or greater than 1.
</p>
<ul><li> Overall Kappa
<dl><dd> The overall kappa coefficient is defined by:
<dl><dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-31dfb71db9f4828df9178656e0db2902.png?v=0" title="K = \frac{P_o-P_e}{1-P_e}" alt="K = \frac{P_o-P_e}{1-P_e}" class="tex"/></dd></dl></dd>
<dd> where
<dl><dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-fe0b6f8afc3aa46833338def167e5cbe.png?v=0" title="P_o=\frac{\sum_{i=1}^n\sum_{j=1}^kx_{ij}^2-nm}{nm(m-1)}:" alt="P_o=\frac{\sum_{i=1}^n\sum_{j=1}^kx_{ij}^2-nm}{nm(m-1)}:" class="tex"/> the observed proportion of the pairwise agreement among the trials.</dd>
<dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-ae95c4a151695e10258fbbc6faf6906a.png?v=0" title="P_e=\sum_{j=1}^kp_j^2:" alt="P_e=\sum_{j=1}^kp_j^2:" class="tex"/> the expected proportion of agreement.</dd>
<dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-8664ef462c92203ca6e5acbc48a80913.png?v=0" title="p_j=\frac{1}{nm}\sum_{i=1}^nx_{ij}:" alt="p_j=\frac{1}{nm}\sum_{i=1}^nx_{ij}:" class="tex"/> the overall proportion of ratings in category <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-363b122c528f54df4a0446b6bab05515.png?v=0" title="j" alt="j" class="tex"/>.</dd>
<dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-f1f9250fcac74ed2166c0ada034fdc38.png?v=0" title="k:" alt="k:" class="tex"/> the total number of categories.</dd>
<dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-843f38405071c44c21ae948cfe82b695.png?v=0" title="m:" alt="m:" class="tex"/> the number of trials. For agreement within each appraiser, it is the number of trials for each appraiser. For agreement between all appraisers, it is the number of trials for all appraisers.</dd>
<dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-41a51e6f53b03ff2f11c5f8464ef315a.png?v=0" title="n:" alt="n:" class="tex"/> the number of samples.</dd>
<dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-1dbf53e441ba9d0626fb091e26c3de6c.png?v=0" title="x_{ij}:" alt="x_{ij}:" class="tex"/> the number of ratings on sample <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-865c0c0b4ab0e063e5caa3387c1a8741.png?v=0" title="i" alt="i" class="tex"/> into category <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-363b122c528f54df4a0446b6bab05515.png?v=0" title="j" alt="j" class="tex"/>.</dd></dl></dd></dl></li></ul>
<ul><li> Kappa for Single Category
<dl><dd> The formula for the kappa coefficient for the <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-d6c87401ed2f8589600d6db807438139.png?v=0" title="j^{th}" alt="j^{th}" class="tex"/> category is defined by:
<dl><dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-df1446abd85ed7b1310c91cfd7d93d7b.png?v=0" title="K_j=1-\frac{\sum_{i=1}^nx_{ij}(m-x_{ij})}{nm(m-1)p_j(1-p_j)}" alt="K_j=1-\frac{\sum_{i=1}^nx_{ij}(m-x_{ij})}{nm(m-1)p_j(1-p_j)}" class="tex"/></dd></dl></dd>
<dd> Each parameter has the same meaning as described above for Overall Kappa.</dd></dl></li></ul>
<ul><li> Testing Significance
<dl><dd> The following <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-21c2e59531c8710156d34a3c30ac81d5.png?v=0" title="Z" alt="Z" class="tex"/> statistic is used to test if <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-95b273fc87c84814ce286c9fd6c24cc1.png?v=0" title="K &gt; 0" alt="K &gt; 0" class="tex"/>:
<dl><dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-4f115aaf0e8781782712b02442fde6f6.png?v=0" title="Z = \frac{K}{\sqrt{Var(K)}}" alt="Z = \frac{K}{\sqrt{Var(K)}}" class="tex"/></dd></dl></dd>
<dd> where
<dl><dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-0d19ce4730e893ffc9c165d880302e40.png?v=0" title="K:" alt="K:" class="tex"/> the overall kappa coefficient.</dd>
<dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-d95c6c73ba34464e73318f060f8f297e.png?v=0" title="Var(K)=\frac{2}{nm(m-1)\left(\sum_{j=1}^kp_j(1-p_j)\right)^2}\left(\left(\sum_{j=1}^kp_j(1-p_j)\right)^2-\sum_{j=1}^kp_j(1-p_j)(1-2p_j)\right)" alt="Var(K)=\frac{2}{nm(m-1)\left(\sum_{j=1}^kp_j(1-p_j)\right)^2}\left(\left(\sum_{j=1}^kp_j(1-p_j)\right)^2-\sum_{j=1}^kp_j(1-p_j)(1-2p_j)\right)" class="tex"/></dd>
<dd> Other parameters have the same meanings as described above for Overall Kappa.</dd></dl></dd>
<dd> For the <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-d6c87401ed2f8589600d6db807438139.png?v=0" title="j^{th}" alt="j^{th}" class="tex"/> category, the following <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-3fc71dc8994616f376a40c8104cf3835.png?v=0" title="Z_j" alt="Z_j" class="tex"/> statistic is used for testing if <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-d719c9f8938a5a88d2b1b7027f38e096.png?v=0" title="K_j&gt;0" alt="K_j&gt;0" class="tex"/>:
<dl><dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-e446777b6fdcc287a6900fb5b731be2d.png?v=0" title="Z_j=\frac{K_j}{\sqrt{Var(K_j)}}" alt="Z_j=\frac{K_j}{\sqrt{Var(K_j)}}" class="tex"/></dd></dl></dd>
<dd> where
<dl><dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-46e4346e76cbd27bac542d85429ec4a9.png?v=0" title="K_j:" alt="K_j:" class="tex"/> the kappa coefficient for the <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-d6c87401ed2f8589600d6db807438139.png?v=0" title="j^{th}" alt="j^{th}" class="tex"/> category.</dd>
<dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-e4c1542dc040b5941998e69e6c32e00e.png?v=0" title="Var(K_j) = \frac{2}{nm(m-1)}" alt="Var(K_j) = \frac{2}{nm(m-1)}" class="tex"/></dd>
<dd> Other parameters have the same meanings as described above for Overall Kappa.</dd></dl></dd></dl></li></ul>
<h3><a name="Known_Standard"></a><span class="mw-headline">Known Standard</span></h3>
<ul><li> Kappa Statistics
<dl><dd> If the standard is known, the following steps are used for computing kappa coefficients, including overall and single category.</dd></dl>
<ol><li> Consider the standard as one trial, then for each trial, combine with the standard to treat as two trials ratings, and then use the formulas in <a href="../../App/App/Algorithm_Attribute_Agreement_Analysis.html#Unknown_Standard" title="App:Algorithm Attribute Agreement Analysis">Unknown Standard</a> to estimate kappa coefficients for these two combined trials.</li>
<li> Repeat all the trials (assumed there are <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-6f8f57715090da2632453988d9a1501b.png?v=0" title="m" alt="m" class="tex"/> trials) to get the <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-6f8f57715090da2632453988d9a1501b.png?v=0" title="m" alt="m" class="tex"/> sets of kappa coefficients (including both overall and single category).</li>
<li> Calculate the average of the estimated <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-6f8f57715090da2632453988d9a1501b.png?v=0" title="m" alt="m" class="tex"/> sets of kappa coefficients, and the results are the overall kappa coefficient and single category kappa coefficients respectively.</li></ol></li></ul>
<ul><li> Testing Significance
<ol><li> Follow the same steps as calculation for Kappa Statistics above, and get <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-6f8f57715090da2632453988d9a1501b.png?v=0" title="m" alt="m" class="tex"/> variances of the kappa statistic (<img src="../images/Algorithm_Attribute_Agreement_Analysis/math-11b76bbfffb608e08e86354c714b0529.png?v=0" title="Var(K)" alt="Var(K)" class="tex"/> and <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-4bcb6c3db5198a60d5cc4ccef7020efe.png?v=0" title="Var(K_j)" alt="Var(K_j)" class="tex"/>).</li>
<li> The variance of overall kappa with known standard is then calculated by the sum of the <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-6f8f57715090da2632453988d9a1501b.png?v=0" title="m" alt="m" class="tex"/> variances, <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-11b76bbfffb608e08e86354c714b0529.png?v=0" title="Var(K)" alt="Var(K)" class="tex"/>, and divided by <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-e09d672ddab652ec34133c73dc054f2e.png?v=0" title="m^2" alt="m^2" class="tex"/>.</li>
<li> Similarly, calculate the variance of kappa for a specific category with known standard by the sum of the <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-6f8f57715090da2632453988d9a1501b.png?v=0" title="m" alt="m" class="tex"/> variances for the kappa for a specific category, (<img src="../images/Algorithm_Attribute_Agreement_Analysis/math-4bcb6c3db5198a60d5cc4ccef7020efe.png?v=0" title="Var(K_j)" alt="Var(K_j)" class="tex"/>), and divided by <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-e09d672ddab652ec34133c73dc054f2e.png?v=0" title="m^2" alt="m^2" class="tex"/>.</li>
<li> Finally, use the same formulas in <a href="../../App/App/Algorithm_Attribute_Agreement_Analysis.html#Unknown_Standard" title="App:Algorithm Attribute Agreement Analysis">Unknown Standard</a> to calculate the <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-21c2e59531c8710156d34a3c30ac81d5.png?v=0" title="Z" alt="Z" class="tex"/> statistic with the obtained variances of overall and singe category in previous steps.</li></ol></li></ul>
<h2><a name="Cohen.27s_Kappa_Statistics"></a><span class="mw-headline">Cohen's Kappa Statistics</span></h2>
<h3><a name="Unknown_Standard_2"></a><span class="mw-headline">Unknown Standard</span></h3>
<p>There are two cases to calculate Cohen's kappa statistic with unknown standard, and each case should meet its own condition.
</p><p>For within appraiser, the condition is that, each appraiser should have exactly two trials for each sample.
</p><p>For between appraisers, the number of appraisers should be exactly two, and each has only one trial.
</p><p>Assumed there are <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-8ce4b16b22b58894aa86c421e8759df3.png?v=0" title="k" alt="k" class="tex"/> categories, for the ratings from two trials (within appraiser) or two appraisers (one trial for each appraiser), the following table can be used for the calculation.
</p>
<table class="wikitable" style="margin:auto; text-align: center; width: 90%;">

<tr>
<td>
</td>
<td colspan="5">Trial 2 (or Appraiser 2)
</td></tr>
<tr>
<td> Trial 1 (or Appraiser 1)
</td>
<td> 1
</td>
<td> 2
</td>
<td> ...
</td>
<td> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-8ce4b16b22b58894aa86c421e8759df3.png?v=0" title="k" alt="k" class="tex"/>
</td>
<td> Total
</td></tr>
<tr>
<td> 1
</td>
<td> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-339d71a8ccb5cb1599b3aecfd4317268.png?v=0" title="p_{11}" alt="p_{11}" class="tex"/>
</td>
<td> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-8ac495503b526e68b4582d402a46e545.png?v=0" title="p_{12}" alt="p_{12}" class="tex"/>
</td>
<td> ...
</td>
<td> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-3a841f0958e55abf7a9fd30f9feddaf0.png?v=0" title="p_{1k}" alt="p_{1k}" class="tex"/>
</td>
<td> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-e87754a5340fef38bb500290e5430eaa.png?v=0" title="p_{1+}" alt="p_{1+}" class="tex"/>
</td></tr>
<tr>
<td> 2
</td>
<td> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-2d29061dbb9fc90b0a5db13824b57c2d.png?v=0" title="p_{21}" alt="p_{21}" class="tex"/>
</td>
<td> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-126b453400fbd521e123db0b0e33a719.png?v=0" title="p_{22}" alt="p_{22}" class="tex"/>
</td>
<td> ...
</td>
<td> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-9cff17ce9bea98f9d10c104b2ac1a823.png?v=0" title="p_{2k}" alt="p_{2k}" class="tex"/>
</td>
<td> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-783602a6786511cee525b0186d6c97a6.png?v=0" title="p_{2+}" alt="p_{2+}" class="tex"/>
</td></tr>
<tr>
<td> ...
</td>
<td> ...
</td>
<td> ...
</td>
<td> ...
</td>
<td> ...
</td>
<td> ...
</td></tr>
<tr>
<td> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-8ce4b16b22b58894aa86c421e8759df3.png?v=0" title="k" alt="k" class="tex"/>
</td>
<td> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-1072c63566d09c105b706d24127bf0db.png?v=0" title="p_{k1}" alt="p_{k1}" class="tex"/>
</td>
<td> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-89f5d98c1f24112b846a9e45d8d40e74.png?v=0" title="p_{k2}" alt="p_{k2}" class="tex"/>
</td>
<td> ...
</td>
<td> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-efc76b92bf2c085d26b42bf9832dd02c.png?v=0" title="p_{kk}" alt="p_{kk}" class="tex"/>
</td>
<td> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-5d9f6d93dcf7d81d3e0bd3a753b4a84b.png?v=0" title="p_{k+}" alt="p_{k+}" class="tex"/>
</td></tr>
<tr>
<td> Total
</td>
<td> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-e6edb6b2d812125b495b3893fadbc572.png?v=0" title="p_{+1}" alt="p_{+1}" class="tex"/>
</td>
<td> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-e5675262718d6cfa5fc0c7af44e5841a.png?v=0" title="p_{+2}" alt="p_{+2}" class="tex"/>
</td>
<td> ...
</td>
<td> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-0dcfd9255870a2dc9b4d5055038150b8.png?v=0" title="p_{+k}" alt="p_{+k}" class="tex"/>
</td>
<td> 1
</td></tr></table>
<p>where
</p>
<dl><dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-89623466ba84f97d5b330389ee5ecf64.png?v=0" title="p_{ij}=\frac{n_{ij}}{N}" alt="p_{ij}=\frac{n_{ij}}{N}" class="tex"/></dd>
<dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-1725c5ffa7ab312d40aa9408a4bd45e5.png?v=0" title="n_{ij}:" alt="n_{ij}:" class="tex"/> the number of samples that the first trial (appraiser) is rating category <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-865c0c0b4ab0e063e5caa3387c1a8741.png?v=0" title="i" alt="i" class="tex"/>, and the second trial (appraiser) is rating category <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-363b122c528f54df4a0446b6bab05515.png?v=0" title="j" alt="j" class="tex"/>.</dd>
<dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-fd8df296232c32c3ac2f6930f1f93bf9.png?v=0" title="N:" alt="N:" class="tex"/> the total number of samples.</dd>
<dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-639d9a050f9ca3ecfc2819c073ee9938.png?v=0" title="p_{+i}=\sum_{j=1}^kp_{ji}" alt="p_{+i}=\sum_{j=1}^kp_{ji}" class="tex"/></dd>
<dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-7613e7f0b43c011ca734aa4e7ae626ca.png?v=0" title="p_{i+}=\sum_{j=1}^kp_{ij}" alt="p_{i+}=\sum_{j=1}^kp_{ij}" class="tex"/></dd></dl>
<ul><li> Overall Kappa
<dl><dd> The overall kappa coefficient is defined by:
<dl><dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-31dfb71db9f4828df9178656e0db2902.png?v=0" title="K = \frac{P_o-P_e}{1-P_e}" alt="K = \frac{P_o-P_e}{1-P_e}" class="tex"/></dd></dl></dd>
<dd> where
<dl><dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-5adf7c88830eba2ca2d164e023134380.png?v=0" title="P_o=\sum_{i=1}^kp_{ii}:" alt="P_o=\sum_{i=1}^kp_{ii}:" class="tex"/> the observed proportion of agreement.</dd>
<dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-7800c5abbea1d793e6640a8ff010f18d.png?v=0" title="P_e=\sum_{i=1}^kp_{i+}p_{+i}:" alt="P_e=\sum_{i=1}^kp_{i+}p_{+i}:" class="tex"/> the expected proportion of agreement.</dd></dl></dd></dl></li></ul>
<ul><li> Kappa for Single Category
<dl><dd> The formula for the kappa coefficient for the <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-d6c87401ed2f8589600d6db807438139.png?v=0" title="j^{th}" alt="j^{th}" class="tex"/> category is calculated by:
<dl><dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-33a5ea78a572f4ae773d4f98c68c4a27.png?v=0" title="K_j=\frac{p_{jj}-p_{+j}p_{j+}}{(p_{+j}+p_{j+})/2-p_{+j}p_{j+}}" alt="K_j=\frac{p_{jj}-p_{+j}p_{j+}}{(p_{+j}+p_{j+})/2-p_{+j}p_{j+}}" class="tex"/></dd></dl></dd></dl></li></ul>
<ul><li> Testing Significance
<dl><dd> The following <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-21c2e59531c8710156d34a3c30ac81d5.png?v=0" title="Z" alt="Z" class="tex"/> statistic is used to test if <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-95b273fc87c84814ce286c9fd6c24cc1.png?v=0" title="K &gt; 0" alt="K &gt; 0" class="tex"/>:
<dl><dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-c7de67752f6d007561adbde252e6c768.png?v=0" title="Z = \frac{K}{SE}" alt="Z = \frac{K}{SE}" class="tex"/></dd></dl></dd>
<dd> where
<dl><dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-0d19ce4730e893ffc9c165d880302e40.png?v=0" title="K:" alt="K:" class="tex"/> the overall kappa coefficient.</dd>
<dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-1fc629db7b42ee1d2d57d90ed68d4eb2.png?v=0" title="SE=\frac{\sqrt{P_e+P_e^2-\sum_{i=1}^kp_{i+}p_{+i}(p_{i+}+p_{+i})}}{(1-P_e)\sqrt{N}}:" alt="SE=\frac{\sqrt{P_e+P_e^2-\sum_{i=1}^kp_{i+}p_{+i}(p_{i+}+p_{+i})}}{(1-P_e)\sqrt{N}}:" class="tex"/> the standard error of kappa coefficient.</dd></dl></dd>
<dd> For the <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-d6c87401ed2f8589600d6db807438139.png?v=0" title="j^{th}" alt="j^{th}" class="tex"/> category, the following <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-3fc71dc8994616f376a40c8104cf3835.png?v=0" title="Z_j" alt="Z_j" class="tex"/> statistic is used for testing if <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-d719c9f8938a5a88d2b1b7027f38e096.png?v=0" title="K_j&gt;0" alt="K_j&gt;0" class="tex"/>:
<dl><dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-3663c4ce588598c22be3f23a15ce37d6.png?v=0" title="Z_j=\frac{K_j}{SE_j}" alt="Z_j=\frac{K_j}{SE_j}" class="tex"/></dd></dl></dd>
<dd> where
<dl><dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-46e4346e76cbd27bac542d85429ec4a9.png?v=0" title="K_j:" alt="K_j:" class="tex"/> the kappa coefficient for the <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-d6c87401ed2f8589600d6db807438139.png?v=0" title="j^{th}" alt="j^{th}" class="tex"/> category.</dd>
<dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-15d988838e2f397fd26a7504acc6a826.png?v=0" title="SE_j = \frac{\sqrt{p_{+j}p_{j+}+p_{+j}^2p_{j+}^2-p_{+j}p_{j+}(p_{+j}+p_{j+})}}{((p_{+j}+p_{j+})/2-p_{+j}p_{j+})\sqrt{N}}:" alt="SE_j = \frac{\sqrt{p_{+j}p_{j+}+p_{+j}^2p_{j+}^2-p_{+j}p_{j+}(p_{+j}+p_{j+})}}{((p_{+j}+p_{j+})/2-p_{+j}p_{j+})\sqrt{N}}:" class="tex"/> the standard error of kappa coefficient of the <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-d6c87401ed2f8589600d6db807438139.png?v=0" title="j^{th}" alt="j^{th}" class="tex"/> category.</dd></dl></dd></dl></li></ul>
<h3><a name="Known_Standard_2"></a><span class="mw-headline">Known Standard</span></h3>
<p>To calculate Cohen's kappa statistic with known standard, the similar procedure is used as <a href="../../App/App/Algorithm_Attribute_Agreement_Analysis.html#Unknown_Standard_2" title="App:Algorithm Attribute Agreement Analysis">Unknown Standard</a>.
</p><p>Assumed there are <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-8ce4b16b22b58894aa86c421e8759df3.png?v=0" title="k" alt="k" class="tex"/> categories for standard, for the ratings from each trial, the following table can be used for the similar calculation.
</p>
<table class="wikitable" style="margin:auto; text-align: center; width: 90%;">

<tr>
<td>
</td>
<td colspan="5">Standard
</td></tr>
<tr>
<td> Trial
</td>
<td> 1
</td>
<td> 2
</td>
<td> ...
</td>
<td> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-8ce4b16b22b58894aa86c421e8759df3.png?v=0" title="k" alt="k" class="tex"/>
</td>
<td> Total
</td></tr>
<tr>
<td> 1
</td>
<td> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-339d71a8ccb5cb1599b3aecfd4317268.png?v=0" title="p_{11}" alt="p_{11}" class="tex"/>
</td>
<td> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-8ac495503b526e68b4582d402a46e545.png?v=0" title="p_{12}" alt="p_{12}" class="tex"/>
</td>
<td> ...
</td>
<td> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-3a841f0958e55abf7a9fd30f9feddaf0.png?v=0" title="p_{1k}" alt="p_{1k}" class="tex"/>
</td>
<td> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-e87754a5340fef38bb500290e5430eaa.png?v=0" title="p_{1+}" alt="p_{1+}" class="tex"/>
</td></tr>
<tr>
<td> 2
</td>
<td> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-2d29061dbb9fc90b0a5db13824b57c2d.png?v=0" title="p_{21}" alt="p_{21}" class="tex"/>
</td>
<td> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-126b453400fbd521e123db0b0e33a719.png?v=0" title="p_{22}" alt="p_{22}" class="tex"/>
</td>
<td> ...
</td>
<td> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-9cff17ce9bea98f9d10c104b2ac1a823.png?v=0" title="p_{2k}" alt="p_{2k}" class="tex"/>
</td>
<td> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-783602a6786511cee525b0186d6c97a6.png?v=0" title="p_{2+}" alt="p_{2+}" class="tex"/>
</td></tr>
<tr>
<td> ...
</td>
<td> ...
</td>
<td> ...
</td>
<td> ...
</td>
<td> ...
</td>
<td> ...
</td></tr>
<tr>
<td> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-8ce4b16b22b58894aa86c421e8759df3.png?v=0" title="k" alt="k" class="tex"/>
</td>
<td> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-1072c63566d09c105b706d24127bf0db.png?v=0" title="p_{k1}" alt="p_{k1}" class="tex"/>
</td>
<td> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-89f5d98c1f24112b846a9e45d8d40e74.png?v=0" title="p_{k2}" alt="p_{k2}" class="tex"/>
</td>
<td> ...
</td>
<td> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-efc76b92bf2c085d26b42bf9832dd02c.png?v=0" title="p_{kk}" alt="p_{kk}" class="tex"/>
</td>
<td> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-5d9f6d93dcf7d81d3e0bd3a753b4a84b.png?v=0" title="p_{k+}" alt="p_{k+}" class="tex"/>
</td></tr>
<tr>
<td> Total
</td>
<td> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-e6edb6b2d812125b495b3893fadbc572.png?v=0" title="p_{+1}" alt="p_{+1}" class="tex"/>
</td>
<td> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-e5675262718d6cfa5fc0c7af44e5841a.png?v=0" title="p_{+2}" alt="p_{+2}" class="tex"/>
</td>
<td> ...
</td>
<td> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-0dcfd9255870a2dc9b4d5055038150b8.png?v=0" title="p_{+k}" alt="p_{+k}" class="tex"/>
</td>
<td> 1
</td></tr></table>
<p>where
</p>
<dl><dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-89623466ba84f97d5b330389ee5ecf64.png?v=0" title="p_{ij}=\frac{n_{ij}}{N}" alt="p_{ij}=\frac{n_{ij}}{N}" class="tex"/></dd>
<dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-1725c5ffa7ab312d40aa9408a4bd45e5.png?v=0" title="n_{ij}:" alt="n_{ij}:" class="tex"/> the number of samples that the trial is rating category <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-865c0c0b4ab0e063e5caa3387c1a8741.png?v=0" title="i" alt="i" class="tex"/>, and the standard is category <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-363b122c528f54df4a0446b6bab05515.png?v=0" title="j" alt="j" class="tex"/>.</dd>
<dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-fd8df296232c32c3ac2f6930f1f93bf9.png?v=0" title="N:" alt="N:" class="tex"/> the total number of samples.</dd>
<dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-639d9a050f9ca3ecfc2819c073ee9938.png?v=0" title="p_{+i}=\sum_{j=1}^kp_{ji}" alt="p_{+i}=\sum_{j=1}^kp_{ji}" class="tex"/></dd>
<dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-7613e7f0b43c011ca734aa4e7ae626ca.png?v=0" title="p_{i+}=\sum_{j=1}^kp_{ij}" alt="p_{i+}=\sum_{j=1}^kp_{ij}" class="tex"/></dd></dl>
<ul><li> Kappa
<ul><li> Each Appraiser VS Standard
<ol><li> For the <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-97361f12a3555fc4fc4e2ffce1799ac3.png?v=0" title="i^{th}" alt="i^{th}" class="tex"/> trial, calculate <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-7314a4287d213ba824fb4cc4b8dd4853.png?v=0" title="K^{(i)}" alt="K^{(i)}" class="tex"/> and <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-c9b9a5ada800372700e3299acd1ea3a7.png?v=0" title="K_j^{(i)}" alt="K_j^{(i)}" class="tex"/> using the same formulas as <a href="../../App/App/Algorithm_Attribute_Agreement_Analysis.html#Unknown_Standard_2" title="App:Algorithm Attribute Agreement Analysis">Unknown Standard</a>.</li>
<li> Sum up all <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-7314a4287d213ba824fb4cc4b8dd4853.png?v=0" title="K^{(i)}" alt="K^{(i)}" class="tex"/> and <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-c9b9a5ada800372700e3299acd1ea3a7.png?v=0" title="K_j^{(i)}" alt="K_j^{(i)}" class="tex"/> from all trials respectively, and then divided by the number of trials, <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-6f8f57715090da2632453988d9a1501b.png?v=0" title="m" alt="m" class="tex"/>, that is:
<dl><dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-64d657794672a694ed15d6d4156955e5.png?v=0" title="K=\frac{\sum_{i=1}^mK^{(i)}}{m}" alt="K=\frac{\sum_{i=1}^mK^{(i)}}{m}" class="tex"/></dd>
<dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-31196976b8c6bdee49d28242998f1fc5.png?v=0" title="K_j=\frac{\sum_{i=1}^mK_j^{(i)}}{m}" alt="K_j=\frac{\sum_{i=1}^mK_j^{(i)}}{m}" class="tex"/></dd></dl></li></ol></li>
<li> All Appraisers VS Standard
<ol><li> For the <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-97361f12a3555fc4fc4e2ffce1799ac3.png?v=0" title="i^{th}" alt="i^{th}" class="tex"/> trial from the <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-aa2e85feba6197a03aae3e37bb3927bc.png?v=0" title="l^{th}" alt="l^{th}" class="tex"/> appraiser, calculate <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-402b815aa4b222b75edab6e8b5264ee0.png?v=0" title="K^{(il)}" alt="K^{(il)}" class="tex"/> and <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-3a1254f2a53c4257f6bc122d8ec1ee68.png?v=0" title="K_j^{(il)}" alt="K_j^{(il)}" class="tex"/> using the same formulas as <a href="../../App/App/Algorithm_Attribute_Agreement_Analysis.html#Unknown_Standard_2" title="App:Algorithm Attribute Agreement Analysis">Unknown Standard</a>.</li>
<li> Sum up all <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-402b815aa4b222b75edab6e8b5264ee0.png?v=0" title="K^{(il)}" alt="K^{(il)}" class="tex"/> and <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-3a1254f2a53c4257f6bc122d8ec1ee68.png?v=0" title="K_j^{(il)}" alt="K_j^{(il)}" class="tex"/> from all trials and all appraisers respectively, and then divided by the number of trials, <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-6f8f57715090da2632453988d9a1501b.png?v=0" title="m" alt="m" class="tex"/>, and the number of appraisers, <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-d20caec3b48a1eef164cb4ca81ba2587.png?v=0" title="L" alt="L" class="tex"/>, that is:
<dl><dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-2882d00e17adc62ffe8cf1f4f175885b.png?v=0" title="K=\frac{\sum_{i=1}^m\sum_{l=1}^LK^{(il)}}{mL}" alt="K=\frac{\sum_{i=1}^m\sum_{l=1}^LK^{(il)}}{mL}" class="tex"/></dd>
<dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-1c93f0f263300b7b0efa96672e8189e0.png?v=0" title="K_j=\frac{\sum_{i=1}^m\sum_{l=1}^LK_j^{(il)}}{mL}" alt="K_j=\frac{\sum_{i=1}^m\sum_{l=1}^LK_j^{(il)}}{mL}" class="tex"/></dd></dl></li></ol></li></ul></li></ul>
<ul><li> Testing Significance
<ul><li> Each Appraiser VS Standard
<ol><li> For the <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-97361f12a3555fc4fc4e2ffce1799ac3.png?v=0" title="i^{th}" alt="i^{th}" class="tex"/> trial, calculate <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-c998dc6953fc48ca39b930043b0bec49.png?v=0" title="SE^{(i)}" alt="SE^{(i)}" class="tex"/> and <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-91d4389e38afc23c61acb6ab958eec4c.png?v=0" title="SE_j^{(i)}" alt="SE_j^{(i)}" class="tex"/> using the same formulas as <a href="../../App/App/Algorithm_Attribute_Agreement_Analysis.html#Unknown_Standard_2" title="App:Algorithm Attribute Agreement Analysis">Unknown Standard</a>.</li>
<li> Sum up all <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-b2321070f3d57af830246cf73d8acfea.png?v=0" title="SE^{(i)}*SE^{(i)}" alt="SE^{(i)}*SE^{(i)}" class="tex"/> and <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-0daa366dd9381ff5e747b6cd5985067e.png?v=0" title="SE_j^{(i)}*SE_j^{(i)}" alt="SE_j^{(i)}*SE_j^{(i)}" class="tex"/> from all trials respectively, and then get the sum of variances.</li>
<li> The final calculation of <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-f003c44deab679aa2edfaff864c77402.png?v=0" title="SE" alt="SE" class="tex"/> and <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-ad089dac105ee105fae3d4cb09f612cd.png?v=0" title="SE_j" alt="SE_j" class="tex"/> is:
<dl><dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-fc4c59320bb9d57eb02a0962ef266713.png?v=0" title="SE=\frac{\sqrt{\sum_{i=1}^m\frac{SE^{(i)}*SE^{(i)}}{m}}}{\sqrt{m}}" alt="SE=\frac{\sqrt{\sum_{i=1}^m\frac{SE^{(i)}*SE^{(i)}}{m}}}{\sqrt{m}}" class="tex"/></dd>
<dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-a595f331c64adc4c3e19709ff9d0f869.png?v=0" title="SE_j=\frac{\sqrt{\sum_{i=1}^m\frac{SE_j^{(i)}*SE_j^{(i)}}{m}}}{\sqrt{m}}" alt="SE_j=\frac{\sqrt{\sum_{i=1}^m\frac{SE_j^{(i)}*SE_j^{(i)}}{m}}}{\sqrt{m}}" class="tex"/></dd>
<dd> where <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-6f8f57715090da2632453988d9a1501b.png?v=0" title="m" alt="m" class="tex"/> is the number of trials.</dd></dl></li>
<li> Then <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-21c2e59531c8710156d34a3c30ac81d5.png?v=0" title="Z" alt="Z" class="tex"/> and <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-3fc71dc8994616f376a40c8104cf3835.png?v=0" title="Z_j" alt="Z_j" class="tex"/> are calculated by:
<dl><dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-f6b7db5bb00435193a7df0a13e947c26.png?v=0" title="Z=\frac{K}{SE}" alt="Z=\frac{K}{SE}" class="tex"/> and <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-3663c4ce588598c22be3f23a15ce37d6.png?v=0" title="Z_j=\frac{K_j}{SE_j}" alt="Z_j=\frac{K_j}{SE_j}" class="tex"/></dd></dl></li></ol></li>
<li> All Appraisers VS Standard
<ol><li> For the <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-97361f12a3555fc4fc4e2ffce1799ac3.png?v=0" title="i^{th}" alt="i^{th}" class="tex"/> trial from the <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-aa2e85feba6197a03aae3e37bb3927bc.png?v=0" title="l^{th}" alt="l^{th}" class="tex"/> appraiser, calculate <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-fc15ba325b339564ffbbc0f4474c3878.png?v=0" title="SE^{(il)}" alt="SE^{(il)}" class="tex"/> and <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-9223973e688d018465ae1059c16765ac.png?v=0" title="SE_j^{(il)}" alt="SE_j^{(il)}" class="tex"/> using the same formulas as <a href="../../App/App/Algorithm_Attribute_Agreement_Analysis.html#Unknown_Standard_2" title="App:Algorithm Attribute Agreement Analysis">Unknown Standard</a>.</li>
<li> Sum up all <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-065f761999b6bdfa372847d10abcf407.png?v=0" title="SE^{(il)}*SE^{(il)}" alt="SE^{(il)}*SE^{(il)}" class="tex"/> and <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-b91b93a29a3ead535e96de8164ccd6f4.png?v=0" title="SE_j^{(il)}*SE_j^{(il)}" alt="SE_j^{(il)}*SE_j^{(il)}" class="tex"/> from all trials and all appraisers respectively, and get the sum of variances.</li>
<li> The final calculation of <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-f003c44deab679aa2edfaff864c77402.png?v=0" title="SE" alt="SE" class="tex"/> and <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-ad089dac105ee105fae3d4cb09f612cd.png?v=0" title="SE_j" alt="SE_j" class="tex"/> is:
<dl><dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-46f60ddc6dd62e25736a00eda180f119.png?v=0" title="SE=\frac{\sqrt{\sum_{i=1}^m\sum_{l=1}^L\frac{SE^{(il)}*SE^{(il)}}{mL}}}{\sqrt{mL}}" alt="SE=\frac{\sqrt{\sum_{i=1}^m\sum_{l=1}^L\frac{SE^{(il)}*SE^{(il)}}{mL}}}{\sqrt{mL}}" class="tex"/></dd>
<dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-4238e689efe093ab5a0e361093416e52.png?v=0" title="SE_j=\frac{\sqrt{\sum_{i=1}^m\sum_{l=1}^L\frac{SE_j^{(il)}*SE_j^{(il)}}{mL}}}{\sqrt{mL}}" alt="SE_j=\frac{\sqrt{\sum_{i=1}^m\sum_{l=1}^L\frac{SE_j^{(il)}*SE_j^{(il)}}{mL}}}{\sqrt{mL}}" class="tex"/></dd>
<dd> where <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-6f8f57715090da2632453988d9a1501b.png?v=0" title="m" alt="m" class="tex"/> is the number of trials, and <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-d20caec3b48a1eef164cb4ca81ba2587.png?v=0" title="L" alt="L" class="tex"/> is the number of appraisers.</dd></dl></li>
<li> Then <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-21c2e59531c8710156d34a3c30ac81d5.png?v=0" title="Z" alt="Z" class="tex"/> and <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-3fc71dc8994616f376a40c8104cf3835.png?v=0" title="Z_j" alt="Z_j" class="tex"/> are calculated by:
<dl><dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-f6b7db5bb00435193a7df0a13e947c26.png?v=0" title="Z=\frac{K}{SE}" alt="Z=\frac{K}{SE}" class="tex"/> and <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-3663c4ce588598c22be3f23a15ce37d6.png?v=0" title="Z_j=\frac{K_j}{SE_j}" alt="Z_j=\frac{K_j}{SE_j}" class="tex"/></dd></dl></li></ol></li></ul></li></ul>
<h2><a name="Kendall.27s_Statistics"></a><span class="mw-headline">Kendall's Statistics</span></h2>
<p>To calculate Kendall's statistics, it assumes the ratings and standard are ordinal data, and there are at least 3 or more levels.
</p><p>If standard is unknown, the Kendall's coefficient of concordance is computed for within appraiser and between appraisers. For within appraiser, there should be at least 2 trials for each appraiser. And for between appraisers, the number of appraisers should be at least 2.
</p><p>If standard is known, the Kendall's correlation coefficient is computed for each appraiser vs standard and all appraisers vs standard. For all appraisers vs standard, there should be at least 2 appraisers.
</p>
<h3><a name="Kendall.27s_Coefficient_of_Concordance"></a><span class="mw-headline">Kendall's Coefficient of Concordance</span></h3>
<p>The Kendall's coefficient of concordance is estimated by:
</p>
<dl><dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-f2e34120f020586ec18fbd8fc20bb2f7.png?v=0" title="W=\frac{12\sum_{i=1}^NR_i^2-3K^2N(N+1)^2}{K^2N(N^2-1)-K\sum_{j=1}^KT_j}" alt="W=\frac{12\sum_{i=1}^NR_i^2-3K^2N(N+1)^2}{K^2N(N^2-1)-K\sum_{j=1}^KT_j}" class="tex"/></dd></dl>
<p>where
</p>
<dl><dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-fd8df296232c32c3ac2f6930f1f93bf9.png?v=0" title="N:" alt="N:" class="tex"/> the number of samples.</dd>
<dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-0d19ce4730e893ffc9c165d880302e40.png?v=0" title="K:" alt="K:" class="tex"/> the number of trials for within appraiser. For between appraisers, it is <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-fb7f4667b85d151c5d9c00e75288bb9b.png?v=0" title="K=m*L" alt="K=m*L" class="tex"/> where <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-6f8f57715090da2632453988d9a1501b.png?v=0" title="m" alt="m" class="tex"/> is the number of trials and <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-d20caec3b48a1eef164cb4ca81ba2587.png?v=0" title="L" alt="L" class="tex"/> is the number of appraisers.</dd>
<dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-48703e7c5bb4e93d20c33b09771380fb.png?v=0" title="R_i=\sum_{k=1}^KR_i^{(k)}:" alt="R_i=\sum_{k=1}^KR_i^{(k)}:" class="tex"/> the sum of ranks for the <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-97361f12a3555fc4fc4e2ffce1799ac3.png?v=0" title="i^{th}" alt="i^{th}" class="tex"/> sample, and <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-a663bc475daf03bcf1506ffbe1af06b9.png?v=0" title="R_i^{(k)}" alt="R_i^{(k)}" class="tex"/> is the rank of each trial from each appraiser for the <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-97361f12a3555fc4fc4e2ffce1799ac3.png?v=0" title="i^{th}" alt="i^{th}" class="tex"/> sample.</dd>
<dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-9420f0845cb21f5396027435206d1832.png?v=0" title="T_j=\sum_{i=1}^{g_j}(t_i^3-t_i):" alt="T_j=\sum_{i=1}^{g_j}(t_i^3-t_i):" class="tex"/> the penalty from the <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-d6c87401ed2f8589600d6db807438139.png?v=0" title="j^{th}" alt="j^{th}" class="tex"/> trial.</dd>
<dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-08b5b2c0d836b83473bb87c7b38ecfa9.png?v=0" title="t_i:" alt="t_i:" class="tex"/> the number of tied ranks in the <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-97361f12a3555fc4fc4e2ffce1799ac3.png?v=0" title="i^{th}" alt="i^{th}" class="tex"/> tie (level).</dd>
<dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-0f28f92db67c0a5f3664b560404e8bc4.png?v=0" title="g_j:" alt="g_j:" class="tex"/> the number of ties (levels) in the <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-d6c87401ed2f8589600d6db807438139.png?v=0" title="j^{th}" alt="j^{th}" class="tex"/> trial.</dd></dl>
<h3><a name="Testing_Significance_of_Kendall.27s_Coefficient_of_Concordance"></a><span class="mw-headline">Testing Significance of Kendall's Coefficient of Concordance</span></h3>
<p>The following formula is used to test the significance of Kendall's coefficient of concordance:
</p>
<dl><dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-2508a9e65795c63dbe87cba141c92788.png?v=0" title="c^2=K(N-1)W" alt="c^2=K(N-1)W" class="tex"/></dd></dl>
<p>where
</p>
<dl><dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-95356370e2833e18bc64e5ae353f2e4a.png?v=0" title="c^2:" alt="c^2:" class="tex"/> the chi-square distribution with <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-5b1ba2fe7e642d05d58d3df27466b069.png?v=0" title="N-1" alt="N-1" class="tex"/> degrees of freedom.</dd>
<dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-fd8df296232c32c3ac2f6930f1f93bf9.png?v=0" title="N:" alt="N:" class="tex"/> the number of samples.</dd>
<dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-0d19ce4730e893ffc9c165d880302e40.png?v=0" title="K:" alt="K:" class="tex"/> the number of trials for within appraiser. For between appraisers, it is <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-fb7f4667b85d151c5d9c00e75288bb9b.png?v=0" title="K=m*L" alt="K=m*L" class="tex"/> where <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-6f8f57715090da2632453988d9a1501b.png?v=0" title="m" alt="m" class="tex"/> is the number of trials and <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-d20caec3b48a1eef164cb4ca81ba2587.png?v=0" title="L" alt="L" class="tex"/> is the number of appraisers.</dd>
<dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-c6a20743102f7996cc1da5e8146374c7.png?v=0" title="W:" alt="W:" class="tex"/> the calculated Kendall's coefficient of concordance.</dd></dl>
<h3><a name="Kendall.27s_Correlation_Coefficient"></a><span class="mw-headline">Kendall's Correlation Coefficient</span></h3>
<p>To calculate Kendall's correlation coefficient between each trial and the standard, the table below is used (assumed there are <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-8ce4b16b22b58894aa86c421e8759df3.png?v=0" title="k" alt="k" class="tex"/> levels).
</p>
<table class="wikitable" style="margin:auto; text-align: center; width: 90%;">

<tr>
<td>
</td>
<td colspan="5">Standard
</td></tr>
<tr>
<td> Trial
</td>
<td> 1
</td>
<td> 2
</td>
<td> ...
</td>
<td> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-8ce4b16b22b58894aa86c421e8759df3.png?v=0" title="k" alt="k" class="tex"/>
</td>
<td> Total
</td></tr>
<tr>
<td> 1
</td>
<td> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-6ee150b948f7ee2f82dcdac99a2212ac.png?v=0" title="n_{11}" alt="n_{11}" class="tex"/>
</td>
<td> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-cc682e113fdaa16babdaafdacc090d29.png?v=0" title="n_{12}" alt="n_{12}" class="tex"/>
</td>
<td> ...
</td>
<td> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-927914b97c21fa0240115ff580015bc9.png?v=0" title="n_{1k}" alt="n_{1k}" class="tex"/>
</td>
<td> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-e0c111be2fec08f94cc195bd0fd9df51.png?v=0" title="n_{1+}" alt="n_{1+}" class="tex"/>
</td></tr>
<tr>
<td> 2
</td>
<td> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-de56794f4ed5d78d201c8f0dac33c7ae.png?v=0" title="n_{21}" alt="n_{21}" class="tex"/>
</td>
<td> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-b27b6e863470114f30a5d638cdb5daf8.png?v=0" title="n_{22}" alt="n_{22}" class="tex"/>
</td>
<td> ...
</td>
<td> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-a066372552006e8330cf69a5b7556c32.png?v=0" title="n_{2k}" alt="n_{2k}" class="tex"/>
</td>
<td> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-14703477ad9982dd53775abff6b6c5a4.png?v=0" title="n_{2+}" alt="n_{2+}" class="tex"/>
</td></tr>
<tr>
<td> ...
</td>
<td> ...
</td>
<td> ...
</td>
<td> ...
</td>
<td> ...
</td>
<td> ...
</td></tr>
<tr>
<td> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-8ce4b16b22b58894aa86c421e8759df3.png?v=0" title="k" alt="k" class="tex"/>
</td>
<td> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-c86bc37bda77090d974075d27ed95221.png?v=0" title="n_{k1}" alt="n_{k1}" class="tex"/>
</td>
<td> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-dd77e13e4a19cd17a4db0d6d4dad8906.png?v=0" title="n_{k2}" alt="n_{k2}" class="tex"/>
</td>
<td> ...
</td>
<td> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-ee094923495b9f81a86711d5405ac023.png?v=0" title="n_{kk}" alt="n_{kk}" class="tex"/>
</td>
<td> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-f0f9e24907e46e69e122bf4a2ff17f2f.png?v=0" title="n_{k+}" alt="n_{k+}" class="tex"/>
</td></tr>
<tr>
<td> Total
</td>
<td> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-52564c2b4d3c8e373d92e5b54b549e59.png?v=0" title="n_{+1}" alt="n_{+1}" class="tex"/>
</td>
<td> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-cbea1eac57f34d328cc92cae5a8271cf.png?v=0" title="n_{+2}" alt="n_{+2}" class="tex"/>
</td>
<td> ...
</td>
<td> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-8869bfb0c6d78670490e97b7b2d2dce8.png?v=0" title="n_{+k}" alt="n_{+k}" class="tex"/>
</td>
<td> N
</td></tr></table>
<p>where
</p>
<dl><dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-1725c5ffa7ab312d40aa9408a4bd45e5.png?v=0" title="n_{ij}:" alt="n_{ij}:" class="tex"/> the number of samples that the trial is rating category (level) <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-865c0c0b4ab0e063e5caa3387c1a8741.png?v=0" title="i" alt="i" class="tex"/>, and the standard is category (level) <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-363b122c528f54df4a0446b6bab05515.png?v=0" title="j" alt="j" class="tex"/>.</dd>
<dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-fd8df296232c32c3ac2f6930f1f93bf9.png?v=0" title="N:" alt="N:" class="tex"/> the total number of samples.</dd>
<dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-99dca638f74a00df111833fe58187d89.png?v=0" title="n_{+i}=\sum_{j=1}^kn_{ji}" alt="n_{+i}=\sum_{j=1}^kn_{ji}" class="tex"/></dd>
<dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-3a64263ff8afb67eab3697ec111f5df1.png?v=0" title="n_{i+}=\sum_{j=1}^kn_{ij}" alt="n_{i+}=\sum_{j=1}^kn_{ij}" class="tex"/></dd></dl>
<p>Then the Kendall's correlation coefficient between each trial and the standard is computed by:
</p>
<dl><dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-dc089401da5a59e6c1ce1ec953712c8c.png?v=0" title="\tau_c^{(i)}=\frac{C-D}{\sqrt{N(N-1)/2-T_r}\sqrt{N(N-1)/2-T_c}}" alt="\tau_c^{(i)}=\frac{C-D}{\sqrt{N(N-1)/2-T_r}\sqrt{N(N-1)/2-T_c}}" class="tex"/></dd></dl>
<p>where
</p>
<dl><dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-210e6c9880f30b765a3166fcf0055a51.png?v=0" title="(i):" alt="(i):" class="tex"/> for the <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-97361f12a3555fc4fc4e2ffce1799ac3.png?v=0" title="i^{th}" alt="i^{th}" class="tex"/> trial from each appraiser.</dd>
<dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-d0af1851d4ad639ffd4124799b040f08.png?v=0" title="T_r=\sum_{i=1}^kn_{i+}(n_{i+}-1)/2:" alt="T_r=\sum_{i=1}^kn_{i+}(n_{i+}-1)/2:" class="tex"/> the number of pairs tied on row.</dd>
<dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-89bdda45755f9bdfc7cd7d025476b899.png?v=0" title="T_c=\sum_{i=1}^kn_{+i}(n_{+i}-1)/2:" alt="T_c=\sum_{i=1}^kn_{+i}(n_{+i}-1)/2:" class="tex"/> the number of pairs tied on column.</dd>
<dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-88c245d78a82104c6f79395b8eb04c8a.png?v=0" title="C=\sum_{a=1}^{k-1}\sum_{b=1}^{k-1}\left(n_{ab}\sum_{c=a+1}^{k}\sum_{d=b+1}^{k}n_{cd}\right):" alt="C=\sum_{a=1}^{k-1}\sum_{b=1}^{k-1}\left(n_{ab}\sum_{c=a+1}^{k}\sum_{d=b+1}^{k}n_{cd}\right):" class="tex"/> the number of concordant pairs.</dd>
<dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-c98c70c55e244db46d8a37ccb1088293.png?v=0" title="D=\sum_{a=2}^{k-1}\sum_{b=1}^{k-1}\left(n_{ab}\sum_{c=1}^{a-1}\sum_{d=b+1}^{k}n_{cd}\right):" alt="D=\sum_{a=2}^{k-1}\sum_{b=1}^{k-1}\left(n_{ab}\sum_{c=1}^{a-1}\sum_{d=b+1}^{k}n_{cd}\right):" class="tex"/> the number of discordant pairs.</dd></dl>
<p>And the final Kendall's correlation coefficient is the average of all trials from each appraiser:
</p>
<dl><dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-bd207ed19a80da1c5d769b93259b80d4.png?v=0" title="\tau_c=\frac{\sum_{i=1}^K\tau_c^{(i)}}{K}" alt="\tau_c=\frac{\sum_{i=1}^K\tau_c^{(i)}}{K}" class="tex"/></dd></dl>
<p>where 
</p>
<dl><dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-0d19ce4730e893ffc9c165d880302e40.png?v=0" title="K:" alt="K:" class="tex"/> the number of trials for each appraiser vs standard, otherwise for all appraisers vs standard, <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-033d4f4e87f78cc3cf17a20cb0ba775d.png?v=0" title="K=mL" alt="K=mL" class="tex"/>, where <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-6f8f57715090da2632453988d9a1501b.png?v=0" title="m" alt="m" class="tex"/> is the number of trials and <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-d20caec3b48a1eef164cb4ca81ba2587.png?v=0" title="L" alt="L" class="tex"/> is the number of appraisers.</dd></dl>
<h3><a name="Testing_Significance_of_Kendall.27s_Correlation_Coefficient"></a><span class="mw-headline">Testing Significance of Kendall's Correlation Coefficient</span></h3>
<p>When the standard is known, use the following formula for testing the significance of Kendall's correlation coefficient.
</p>
<dl><dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-9c6b5bcba9eed6fca74262598ad2de80.png?v=0" title="Z=\frac{3\left(\tau_c-\frac{2}{KN(N-1)}\right)\sqrt{KN(N-1)}}{\sqrt{2(2N+5)}},\tau_c &gt; 0" alt="Z=\frac{3\left(\tau_c-\frac{2}{KN(N-1)}\right)\sqrt{KN(N-1)}}{\sqrt{2(2N+5)}},\tau_c &gt; 0" class="tex"/></dd>
<dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-7b356e37a88c50374dc70015d9aebf7a.png?v=0" title="Z=\frac{3\left(\tau_c+\frac{2}{KN(N-1)}\right)\sqrt{KN(N-1)}}{\sqrt{2(2N+5)}},\tau_c\leq 0" alt="Z=\frac{3\left(\tau_c+\frac{2}{KN(N-1)}\right)\sqrt{KN(N-1)}}{\sqrt{2(2N+5)}},\tau_c\leq 0" class="tex"/></dd></dl>
<p>where
</p>
<dl><dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-0d19ce4730e893ffc9c165d880302e40.png?v=0" title="K:" alt="K:" class="tex"/> the number of trials for each appraiser vs standard, otherwise for all appraisers vs standard, <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-033d4f4e87f78cc3cf17a20cb0ba775d.png?v=0" title="K=mL" alt="K=mL" class="tex"/>, where <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-6f8f57715090da2632453988d9a1501b.png?v=0" title="m" alt="m" class="tex"/> is the number of trials and <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-d20caec3b48a1eef164cb4ca81ba2587.png?v=0" title="L" alt="L" class="tex"/> is the number of appraisers.</dd>
<dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-fd8df296232c32c3ac2f6930f1f93bf9.png?v=0" title="N:" alt="N:" class="tex"/> the total number of samples.</dd>
<dd> <img src="../images/Algorithm_Attribute_Agreement_Analysis/math-870d81fba16ed8f77d89ab8adfca61d1.png?v=0" title="\tau_c:" alt="\tau_c:" class="tex"/> the calculated Kendall's correlation coefficient.</dd></dl>






