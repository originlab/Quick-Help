<h1 class="firstHeading">17.4.2.3 Interpreting Results of Repeated Measures ANOVA</h1><p class='urlname' style='display: none'>RMANOVA-ResultInterpret</p>
<div id="toc" class="toc"><div id="toctitle"><h2>Contents</h2></div>
<ul>
<li class="toclevel-1 tocsection-1"><a href="#Multivariate_Tests"><span class="tocnumber">1</span> <span class="toctext">Multivariate Tests</span></a></li>
<li class="toclevel-1 tocsection-2"><a href="#Mauchly.27s_Test_of_Sphericity"><span class="tocnumber">2</span> <span class="toctext">Mauchly's Test of Sphericity</span></a></li>
<li class="toclevel-1 tocsection-3"><a href="#Tests_of_Within-Subjects_Effects"><span class="tocnumber">3</span> <span class="toctext">Tests of Within-Subjects Effects</span></a></li>
<li class="toclevel-1 tocsection-4"><a href="#Tests_of_Between-Subjects_Effects"><span class="tocnumber">4</span> <span class="toctext">Tests of Between-Subjects Effects</span></a></li>
<li class="toclevel-1 tocsection-5"><a href="#Descriptive_Statistics"><span class="tocnumber">5</span> <span class="toctext">Descriptive Statistics</span></a></li>
<li class="toclevel-1 tocsection-6"><a href="#Pairwise_Comparison"><span class="tocnumber">6</span> <span class="toctext">Pairwise Comparison</span></a></li>
<li class="toclevel-1 tocsection-7"><a href="#Plot"><span class="tocnumber">7</span> <span class="toctext">Plot</span></a></li>
</ul>
</div>

<h3><a name="Multivariate_Tests"></a><span class="mw-headline">Multivariate Tests</span></h3>
<p>Origin will automatically perform multivariate tests along with repeated measures ANOVA. In most cases, multivariate tests are not as powerful as repeated measures ANOVA, so we should use repeated measures ANOVA. However, under certain circumstances, for example large sample size and a serious violation of sphericity assumption, the multivariate tests would be a better choice. 
</p><p>As a report of multivariate tests, Origin outputs four rows, each shows the statistics of a separate multivariate test method: <b>Pillai's trace</b>, <b>Wilks' lambda</b>, <b>Hotelling's trace</b>, and <b>Roy's largest root</b>. Additionally to the statistics results, for each of these test methods, the information of <b>value</b> , <b>F</b>, <b>Num DF</b>, <b>DF</b> and <b>Prob &gt; F</b> is provided, where <b>Prob &gt; F</b> is the significance level. And when the significance level is smaller than 0.05, it is possible to conclude that the means are significantly different.
</p><p>Normally, the<b> Wilk's lambda</b> test is the one to be used, but it may not always be the best choice. <b>Pillai's trace</b> is also used quite often because of its powerfulness and robustness. 
</p><p>Please note that for the <b>Roy's largest root</b> test, a lower bound estimate of the probability of F is given, therefore, if the calculated significance level (<b>Prob&gt;F</b> value) is smaller than 0.05 while the results from other tests are not, we could disregard the results from <b>Roy's largest root</b> test.
</p>
<h3><a name="Mauchly.27s_Test_of_Sphericity"></a><span class="mw-headline">Mauchly's Test of Sphericity</span></h3>
<p><b> Mauchly's test</b> is a commonly used test to determine whether the Sphericity assumption can be held. In the <b> Mauchly's Test of Sphericity</b> table of Origin result sheet, if the value of <b>Prob&gt;ChiSq</b> is greater than or equal to 0.05, Sphericity can be assumed. In contrast, when the value <b>Prob&gt;ChiSq</b> is less than 0.05, sphericity can not be assumed, and this leads to an increase in the Type I error. Therefore, modifications need to be made to the degrees of freedom so as to obtain a valid F-ratio. Luckily, the statistic <b>epsilon</b> of three correlations in the <a href="../../UserGuide/UserGuide/Interpreting_Results_of_Repeated_Measures_ANOVA.html#Tests_of_Within-Subjects_Effects" title="UserGuide:Interpreting Results of Repeated Measures ANOVA">tests of within-subjects effects table</a> can be used to evaluated that to which degree Sphericity has been violated and also make modifications to the degrees of freedom. In Origin, epsilons are generated using three methods: <b>Greenhouse-Geisser</b>, <b>Huynh-Feldt</b>, and <b>Lower-bound</b>. When <b>epsilon</b> is equal to 1,  Sphericity is perfectly met. And the smaller the value of <b>epsilon</b>, the more serious the violation of Sphericity.
</p>
<h3><a name="Tests_of_Within-Subjects_Effects"></a><span class="mw-headline">Tests of Within-Subjects Effects</span></h3>
<p>Tests of within-subjects effects can be performed by four methods in Origin: <b>Sphericity Assumed</b>, <b>Greenhouse-Geisser</b> , <b>Huynh-Feldt</b>, and <b>Lower-bound</b>. Basically, we can use the <b>Sphericity  Assumed</b> method when sphericity is assumed (the value of <b>Prob&gt;F</b> in <a href="../../UserGuide/UserGuide/Interpreting_Results_of_Repeated_Measures_ANOVA.html#Mauchly.27s_Test_of_Sphericity" title="UserGuide:Interpreting Results of Repeated Measures ANOVA">Mauchly's test</a> is no less than 0.05). But some statisticians believe that statistical correction is still needed even when sphericity is assumed. For details of the three corrections, please refer to the following table: 
</p>
<table class="simple">

<tr>
<th>Correction method
</th>
<th>Comparison
</th>
<th>When to use
</th></tr>
<tr>
<th>Greenhouse-Geisser
</th>
<td><div style="text-align: center;">
<p>conservative
</p>
</div>
</td>
<td><div style="text-align: center;">
<p>epsilon &lt; 0.75
</p>
</div>
</td></tr>
<tr>
<th>Huynh-Feldt
</th>
<td><div style="text-align: center;">
<p>least conservative
</p>
</div>
</td>
<td><div style="text-align: center;">
<p>epsilon near or above 0.75
</p>
</div>
</td></tr>
<tr>
<th>Lower-bound
</th>
<td><div style="text-align: center;">
<p>most conservative
</p>
</div>
</td>
<td><div style="text-align: center;">
<p>the worst possible case
</p>
</div>
</td></tr></table>
<h3><a name="Tests_of_Between-Subjects_Effects"></a><span class="mw-headline">Tests of Between-Subjects Effects</span></h3>
<p>Tests of Between-Subjects Effects provide tests for each between-subjects factor in your design (In two-way repeated measures ANOVA, one factor can be set as between-subjects factor) as well as any interactions which involve only the between-subjects factors (there should be at least two between-subjects factors). In Origin result sheet, you get the summary information, which includes the values of <b>Sum of Squares</b>, <b>DF</b>, <b>mean square</b>, <b>F</b>, and<b> Prob&gt;F</b>.
</p>
<h3><a name="Descriptive_Statistics"></a><span class="mw-headline">Descriptive Statistics</span></h3>
<p>In this table the results of descriptive statistics for the factor and subject are listed.
</p>
<h3><a name="Pairwise_Comparison"></a><span class="mw-headline">Pairwise Comparison</span></h3>
<p>Multiple comparison procedures are commonly used in an ANOVA after obtaining a significant omnibus test result. The significant ANOVA result suggests that the global null hypothesis, H0, is rejected. The H0 hypothesis states that the means are the same across the groups being compared. We can use multiple comparison to determine which means are different.
</p><p>Origin provides eight different methods for means comparison. They are <b>Tukey</b>, <b>Bonferroni</b>, <b>Dunn-Sidak</b>, <b>Fisher LSD</b>, <b> Scheffe</b>, <b> Dunnett</b>, <b>Holm-Bonferroni</b>, and
<b>Holm-Sidak</b>. 
</p>
<table class="simple">

<tr>
<th>Tukey
</th>
<td>The Tukey method controls the overall Type I error. When Tukey is used, the overall confidence level is <img src="../images/Interpreting_Results_of_Repeated_Measures_ANOVA/math-378df00d12056b404d7d02aef9d8650b.png?v=0" title="1-\alpha" alt="1-\alpha" class="tex"/> with equal sample sizes, that is, the risk of a Type I error is exactly <img src="../images/Interpreting_Results_of_Repeated_Measures_ANOVA/math-7b7f9dbfea05c83784f8b85149852f08.png?v=0" title="\alpha" alt="\alpha" class="tex"/>&#160;; while for unequal sample sizes, the risk of a Type I error is less than <img src="../images/Interpreting_Results_of_Repeated_Measures_ANOVA/math-7b7f9dbfea05c83784f8b85149852f08.png?v=0" title="\alpha" alt="\alpha" class="tex"/>
</td></tr>
<tr>
<th>Bonferroni
</th>
<td>The Bonferroni method controls the overall Type I error and is more conservative than Tukey. The method is commonly used for all pairwise comparisons tests.
</td></tr>
<tr>
<th>Fisher's LSD
</th>
<td>Fishers LSD test dose not control the overall Type I error. Therefore, it should only be used for the significant overall F-test and the small number of comparisons.
</td></tr>
<tr>
<th>Scheffé
</th>
<td>When the number of comparisons is small, Scheffé is very conservative (and more than Bonferroni). Scheffé is more powerful in cases of complex multiple comparisons, so it is used for complex multiple comparisons.
</td></tr>
<tr>
<th>Dunnett
</th>
<td>Dunnett is a powerful test when comparing each treatment to a control and it is more capable to detect real differences.
</td></tr>
<tr>
<th>Dunn-Sidak
</th>
<td>This is a more powerful method than the Dunnett test method, especially when the number of comparisons is large.
</td></tr>
<tr>
<th>Holm-Bonferroni
</th>
<td>This method is less conservative and more powerful than the Bonferroni method. Hence you have more chances to reject null hypotheses with the Bonferroni-Holm method.
</td></tr>
<tr>
<th>Holm-Sidak
</th>
<td>The method is more powerful than Holm test. However, it can not be used to compute a set of confidence intervals.
</td></tr></table>
<h3><a name="Plot"></a><span class="mw-headline">Plot</span></h3>
<p>Origin provides three plots: <b>Bar Chart </b>, <b>Means Plot (SE as Error)</b>, and <b>Means Comparison Plot</b>.
</p><p><b>Note:</b> These three plots are only supported for the One-way repeated measures ANOVA, but not for two-way repeated measures ANOVA.
</p>





