<h1 class="firstHeading">17.4.1.4 Algorithms (Two-Way ANOVA)</h1><p class='urlname' style='display: none'>TwoWayANOVA-Algorithm</p>
<p><br />
</p>
<div id="toc" class="toc"><div id="toctitle"><h2>Contents</h2></div>
<ul>
<li class="toclevel-1 tocsection-1"><a href="#Theory_of_Two-Way_ANOVA"><span class="tocnumber">1</span> <span class="toctext">Theory of Two-Way ANOVA</span></a></li>
<li class="toclevel-1 tocsection-2"><a href="#Multiple_Means_Comparisons"><span class="tocnumber">2</span> <span class="toctext">Multiple Means Comparisons</span></a></li>
<li class="toclevel-1 tocsection-3"><a href="#Power_Analysis"><span class="tocnumber">3</span> <span class="toctext">Power Analysis</span></a></li>
</ul>
</div>

<h2><a name="Theory_of_Two-Way_ANOVA"></a><span class="mw-headline">Theory of Two-Way ANOVA</span></h2>
<p>Let <img src="../images/Algorithms_(ANOVATwoWay)/math-24e1348a922751ccbd4fc0a55d9f6ca8.png?v=0" title="y_{ij,k}\,\!" alt="y_{ij,k}\,\!" class="tex"/> denotes the <i>k</i>th observation at level <i>I</i> of factor A and level <i>j</i> of factor B, the two-way ANOVA model can be rewritten as
</p><p><img src="../images/Algorithms_(ANOVATwoWay)/math-0effb5dfe043214d3b87ff3ca0b1e4d4.png?v=0" title="y_{ij,k}=\mu +\alpha _i+\beta _j+\gamma _{ij}+\varepsilon _{ij,k}" alt="y_{ij,k}=\mu +\alpha _i+\beta _j+\gamma _{ij}+\varepsilon _{ij,k}" class="tex"/>
</p><p>where <img src="../images/Algorithms_(ANOVATwoWay)/math-74b8eddf4b37de80c7c8eed1b64e46fc.png?v=0" title="\mu \,\!" alt="\mu \,\!" class="tex"/> is the whole response data mean, <img src="../images/Algorithms_(ANOVATwoWay)/math-d015b015788a3872acceec61ded52bfb.png?v=0" title="\alpha _i\,\!" alt="\alpha _i\,\!" class="tex"/> is deviation at level <i>I</i> of factor A; <img src="../images/Algorithms_(ANOVATwoWay)/math-193f021d9028eb9706698a6f5c0f1e0a.png?v=0" title="\beta _j\,\!" alt="\beta _j\,\!" class="tex"/> is the deviation at level <i>j</i> of factor <i>B</i>, <img src="../images/Algorithms_(ANOVATwoWay)/math-4893dd2481ae10c24164553d3930b4b6.png?v=0" title="\gamma _{ij}\,\!" alt="\gamma _{ij}\,\!" class="tex"/>, is interaction term between two factors, and <img src="../images/Algorithms_(ANOVATwoWay)/math-2d8e26c124bbaaff2975eca997214c41.png?v=0" title="\varepsilon _{ij,k}\,\!" alt="\varepsilon _{ij,k}\,\!" class="tex"/> is the error term. Then the sample variation was divided into three part, so we can make three hypotheses test:
</p><p>For factor <i>A</i>, the null hypothesis is that the means of the <i>r</i> different populations are the same, and the alternate hypothesis is at least one population’s mean is different from the others:
</p><p><img src="../images/Algorithms_(ANOVATwoWay)/math-c33acaa27b66cec3e5a477ef1a4ec7ec.png?v=0" title="H_{01}:\alpha _1=\alpha _2=\ldots =\alpha _r=0" alt="H_{01}:\alpha _1=\alpha _2=\ldots =\alpha _r=0" class="tex"/>
</p><p><img src="../images/Algorithms_(ANOVATwoWay)/math-1bcb49c656d9c9add5863d0330032e26.png?v=0" title="H_{A1}:\alpha _p\neq \alpha _q" alt="H_{A1}:\alpha _p\neq \alpha _q" class="tex"/>,  for some <i>p</i> and <i>q</i>, 1 ≤ <i>p</i>, <i>q</i> ≥ <i>r</i>;
</p><p>For factor <i>B</i>, the null hypothesis is that the means of the <i>s</i> different populations are the same, and the alternate hypothesis is at least one population’s mean is different from the others:
</p><p><img src="../images/Algorithms_(ANOVATwoWay)/math-b0c76e650b839f11332fb55bc4916f4a.png?v=0" title="H_{02}:\beta _1=\beta _2=\ldots =\beta _s=0" alt="H_{02}:\beta _1=\beta _2=\ldots =\beta _s=0" class="tex"/>;
</p><p><img src="../images/Algorithms_(ANOVATwoWay)/math-7a89b6844c46c8800f73742ac898bdbc.png?v=0" title="H_{A2}:\beta _p\neq \beta _q" alt="H_{A2}:\beta _p\neq \beta _q" class="tex"/>,  for some <i>p</i> and <i>q</i>, 1 ≤ <i>p</i>, <i>q</i> ≥ <i>s</i>;
</p><p>For the interaction term, the null hypothesis is that there is no interaction between the two factors:
</p><p><img src="../images/Algorithms_(ANOVATwoWay)/math-e7658574652ff84922c7e45311aa9711.png?v=0" title="H_{03}:\gamma _1=\gamma _2=\ldots =\gamma _{rs}=0" alt="H_{03}:\gamma _1=\gamma _2=\ldots =\gamma _{rs}=0" class="tex"/>;
</p><p><img src="../images/Algorithms_(ANOVATwoWay)/math-caba9da65b46245805574ee743414b93.png?v=0" title="H_{A3}:\gamma _p\neq \gamma _q" alt="H_{A3}:\gamma _p\neq \gamma _q" class="tex"/>,  for some <i>p</i> and <i>q</i>, 1 ≤ <i>p</i>, <i>q</i> ≥ <i>rs</i>;
</p><p>To test these hypotheses, Then partition the variance of the whole sample into four parts and estimate by the sample variation:
</p><p><img src="../images/Algorithms_(ANOVATwoWay)/math-2c795d2f616da7e117502bbcf9cb9a87.png?v=0" title="SS_{Total}=SS_{Error}+SS_A+SS_B+SS_{AB}\,\!" alt="SS_{Total}=SS_{Error}+SS_A+SS_B+SS_{AB}\,\!" class="tex"/>
</p><p>where
</p><p><img src="../images/Algorithms_(ANOVATwoWay)/math-47e7f804f075b9c157584ec06cce79cd.png?v=0" title="SS_{Total}=\sum_{i=1}^r\sum_{j=1}^s\sum_{k=1}^t(y_{ij,k}-\bar y)^2" alt="SS_{Total}=\sum_{i=1}^r\sum_{j=1}^s\sum_{k=1}^t(y_{ij,k}-\bar y)^2" class="tex"/>
</p><p><img src="../images/Algorithms_(ANOVATwoWay)/math-df8189819caf3b152811459af23977f2.png?v=0" title="SS_{Error}=\sum_{i=1}^r\sum_{j=1}^s\sum_{k=1}^t(y_{ij,k}-\bar y_{ijm})^2" alt="SS_{Error}=\sum_{i=1}^r\sum_{j=1}^s\sum_{k=1}^t(y_{ij,k}-\bar y_{ijm})^2" class="tex"/>
</p><p><img src="../images/Algorithms_(ANOVATwoWay)/math-af748babfd23e3bfd39704d86135daa5.png?v=0" title="SS_A=st\sum_{i=1}^r(\bar y_{imm}-\bar y)^2" alt="SS_A=st\sum_{i=1}^r(\bar y_{imm}-\bar y)^2" class="tex"/>
</p><p><img src="../images/Algorithms_(ANOVATwoWay)/math-07adec886e53b88c568666a7f5ad66d9.png?v=0" title="SS_B=rt\sum_{j=1}^s(\bar y_{mjm}-\bar y)^2" alt="SS_B=rt\sum_{j=1}^s(\bar y_{mjm}-\bar y)^2" class="tex"/>
</p><p><img src="../images/Algorithms_(ANOVATwoWay)/math-472bd2d14aa56baec128037732f9c276.png?v=0" title="S_{AB}=t\sum_{i=1}^r\sum_{j=1}^s(\bar y_{ijm}-\bar y_{imm}-\bar y_{mjm}+\bar y)^2" alt="S_{AB}=t\sum_{i=1}^r\sum_{j=1}^s(\bar y_{ijm}-\bar y_{imm}-\bar y_{mjm}+\bar y)^2" class="tex"/>
</p><p>and we have
</p><p><img src="../images/Algorithms_(ANOVATwoWay)/math-74c3be6091d315b1d45889451f08c9f1.png?v=0" title="\bar y=\frac 1{rst}\sum_{i=1}^r\sum_{j=1}^s\sum_{k=1}^ty_{ij,k}" alt="\bar y=\frac 1{rst}\sum_{i=1}^r\sum_{j=1}^s\sum_{k=1}^ty_{ij,k}" class="tex"/>
</p><p><img src="../images/Algorithms_(ANOVATwoWay)/math-8c782727576bb980e6cef0ccfd682cdf.png?v=0" title="\bar y_{ij}=\frac 1t\sum_{k=1}^ty_{ij,k}" alt="\bar y_{ij}=\frac 1t\sum_{k=1}^ty_{ij,k}" class="tex"/>
</p><p><img src="../images/Algorithms_(ANOVATwoWay)/math-2ae3b31c7b66edb18f543169b3f2c9fa.png?v=0" title="\bar y_{imm}=\frac 1{st}\sum_{j=1}^s\sum_{k=1}^ty_{ij,k}" alt="\bar y_{imm}=\frac 1{st}\sum_{j=1}^s\sum_{k=1}^ty_{ij,k}" class="tex"/>
</p><p><img src="../images/Algorithms_(ANOVATwoWay)/math-6b23df9fc156465fe8f63b0c088432ec.png?v=0" title="\bar y_{mjm}=\frac 1{rt}\sum_{i=1}^r\sum_{k=1}^ty_{ij,k}" alt="\bar y_{mjm}=\frac 1{rt}\sum_{i=1}^r\sum_{k=1}^ty_{ij,k}" class="tex"/>
</p><p><img src="../images/Algorithms_(ANOVATwoWay)/math-100f5db42fc55631c7b4e798218f6a8f.png?v=0" title="SS_{Total}" alt="SS_{Total}" class="tex"/> is the total sum of square, <img src="../images/Algorithms_(ANOVATwoWay)/math-8d95f5934baa7c353f18fd77c675e92c.png?v=0" title="SS_A" alt="SS_A" class="tex"/> represents the variability of the average differences from factor <i>A</i>, <img src="../images/Algorithms_(ANOVATwoWay)/math-8abe5e40ad8ae7fd4ed12d2d27a1a7dd.png?v=0" title="SS_B" alt="SS_B" class="tex"/> represents the variability of the average differences from factor<i> B</i>, <img src="../images/Algorithms_(ANOVATwoWay)/math-23d40e491f33023cbce6ed1898054a81.png?v=0" title="SS_{AB}" alt="SS_{AB}" class="tex"/> represents the variability of interaction, and <img src="../images/Algorithms_(ANOVATwoWay)/math-349fb0475e9b16a6353bbc1aae235e6a.png?v=0" title="SS_{Error}" alt="SS_{Error}" class="tex"/> represents the variability of all individual samples. Then, F test can be used to test the significance of variance between them, and we have:
</p><p><img src="../images/Algorithms_(ANOVATwoWay)/math-fd17c1de0001a4efd8b9a0c82993d061.png?v=0" title="F_A=\frac{MS_A}{MS_{Error}}=\frac{SS_A/(r-1)}{SS_{Error}/(rs(t-1))}\sim F_\alpha (r-1,rs(t-1))" alt="F_A=\frac{MS_A}{MS_{Error}}=\frac{SS_A/(r-1)}{SS_{Error}/(rs(t-1))}\sim F_\alpha (r-1,rs(t-1))" class="tex"/>
</p><p><img src="../images/Algorithms_(ANOVATwoWay)/math-44845adb89d0b9dd10565f5ff22f742a.png?v=0" title="F_B=\frac{MS_B}{MS_{Error}}=\frac{SS_B/(s-1)}{SS_{Error}/(rs(t-1))}\sim F_\alpha (s-1,rs(t-1))" alt="F_B=\frac{MS_B}{MS_{Error}}=\frac{SS_B/(s-1)}{SS_{Error}/(rs(t-1))}\sim F_\alpha (s-1,rs(t-1))" class="tex"/>
</p><p><img src="../images/Algorithms_(ANOVATwoWay)/math-57af428ccc9c055f5a80fdc87089b1c2.png?v=0" title="F_{AB}=\frac{MS_{AB}}{MS_{Error}}=\frac{SS_{AB}/((r-1)(s-1))}{SS_{Error}/(rs(t-1))}\sim F_\alpha ((r-1)(s-1),rs(t-1))" alt="F_{AB}=\frac{MS_{AB}}{MS_{Error}}=\frac{SS_{AB}/((r-1)(s-1))}{SS_{Error}/(rs(t-1))}\sim F_\alpha ((r-1)(s-1),rs(t-1))" class="tex"/>
</p><p>Given a certain significance level <img src="../images/Algorithms_(ANOVATwoWay)/math-7b7f9dbfea05c83784f8b85149852f08.png?v=0" title="\alpha" alt="\alpha" class="tex"/> , we can reject the null hypotheses if the <i>F</i> statistic exceeds the critical value <img src="../images/Algorithms_(ANOVATwoWay)/math-61ee10cfeb9c8fea41d940edebb82588.png?v=0" title="F_\alpha" alt="F_\alpha" class="tex"/> , or equivalently, if the associated <i>p</i>-value of the <i>F</i> statistic is less than the significance level <img src="../images/Algorithms_(ANOVATwoWay)/math-7b7f9dbfea05c83784f8b85149852f08.png?v=0" title="\alpha" alt="\alpha" class="tex"/>, <img src="../images/Algorithms_(ANOVATwoWay)/math-e65765bedcabe42c66ec93228769e82a.png?v=0" title="H_0" alt="H_0" class="tex"/> will be rejected.
</p><p>The calculation of two-way ANOVA table is summarized as below:
</p>
<table class="simple">
<tr>
<th>Source of Variation
</th>
<th>Degrees of Freedom (DF)
</th>
<th>Sum of Squares (SS)
</th>
<th>Mean Square (MS)
</th>
<th><i>F</i> Value
</th>
<th><i>Prob &gt; F</i>
</th></tr>
<tr>
<th>Factor A
</th>
<td><i>r</i> - 1
</td>
<td><img src="../images/Algorithms_(ANOVATwoWay)/math-8d95f5934baa7c353f18fd77c675e92c.png?v=0" title="SS_A" alt="SS_A" class="tex"/>
</td>
<td><img src="../images/Algorithms_(ANOVATwoWay)/math-d8cf712091994539169b7f92bcabdd67.png?v=0" title="MS_A" alt="MS_A" class="tex"/>
</td>
<td><img src="../images/Algorithms_(ANOVATwoWay)/math-d8cf712091994539169b7f92bcabdd67.png?v=0" title="MS_A" alt="MS_A" class="tex"/> / <img src="../images/Algorithms_(ANOVATwoWay)/math-ff8dc369a4b279c7e064cb1ef6fc4ba1.png?v=0" title="MS_{Error}" alt="MS_{Error}" class="tex"/>
</td>
<td><img src="../images/Algorithms_(ANOVATwoWay)/math-336e88336f1a211d0c3f3e2f533edff3.png?v=0" title="P\{F\geq F_{(r-1,rs(t-1),\alpha )}\}" alt="P\{F\geq F_{(r-1,rs(t-1),\alpha )}\}" class="tex"/>
</td></tr>
<tr>
<th>Factor B
</th>
<td>s - 1
</td>
<td><img src="../images/Algorithms_(ANOVATwoWay)/math-8abe5e40ad8ae7fd4ed12d2d27a1a7dd.png?v=0" title="SS_B" alt="SS_B" class="tex"/>
</td>
<td><img src="../images/Algorithms_(ANOVATwoWay)/math-666cadb9e58dc0e560e052a20e3a510f.png?v=0" title="MS_B" alt="MS_B" class="tex"/>
</td>
<td><img src="../images/Algorithms_(ANOVATwoWay)/math-666cadb9e58dc0e560e052a20e3a510f.png?v=0" title="MS_B" alt="MS_B" class="tex"/> / <img src="../images/Algorithms_(ANOVATwoWay)/math-ff8dc369a4b279c7e064cb1ef6fc4ba1.png?v=0" title="MS_{Error}" alt="MS_{Error}" class="tex"/>
</td>
<td><img src="../images/Algorithms_(ANOVATwoWay)/math-b9560f30879a8b17bbee7eebd41b9efa.png?v=0" title="P\{F\geq F_{(s-1,rs(t-1),\alpha )}\}" alt="P\{F\geq F_{(s-1,rs(t-1),\alpha )}\}" class="tex"/>
</td></tr>
<tr>
<th>Interaction
</th>
<td>(<i>r</i>- 1) (<i>s</i> - 1)
</td>
<td><img src="../images/Algorithms_(ANOVATwoWay)/math-23d40e491f33023cbce6ed1898054a81.png?v=0" title="SS_{AB}" alt="SS_{AB}" class="tex"/>
</td>
<td><img src="../images/Algorithms_(ANOVATwoWay)/math-bcd1cd8741b39cdd8c3e290f145ae5a1.png?v=0" title="MS_{AB}" alt="MS_{AB}" class="tex"/>
</td>
<td><img src="../images/Algorithms_(ANOVATwoWay)/math-bcd1cd8741b39cdd8c3e290f145ae5a1.png?v=0" title="MS_{AB}" alt="MS_{AB}" class="tex"/> / <img src="../images/Algorithms_(ANOVATwoWay)/math-ff8dc369a4b279c7e064cb1ef6fc4ba1.png?v=0" title="MS_{Error}" alt="MS_{Error}" class="tex"/>
</td>
<td><img src="../images/Algorithms_(ANOVATwoWay)/math-50ceeeecbb0c9e5fec9e00f101ebad0c.png?v=0" title="P\{F\geq F_{((r-1)(s-1),rs(t-1),\alpha )}\}" alt="P\{F\geq F_{((r-1)(s-1),rs(t-1),\alpha )}\}" class="tex"/>
</td></tr>
<tr>
<th>Error
</th>
<td>rs (t - 1)
</td>
<td><img src="../images/Algorithms_(ANOVATwoWay)/math-349fb0475e9b16a6353bbc1aae235e6a.png?v=0" title="SS_{Error}" alt="SS_{Error}" class="tex"/>
</td>
<td><img src="../images/Algorithms_(ANOVATwoWay)/math-ff8dc369a4b279c7e064cb1ef6fc4ba1.png?v=0" title="MS_{Error}" alt="MS_{Error}" class="tex"/>
</td>
<td>
</td>
<td>
</td></tr>
<tr>
<th>Total
</th>
<td>rst - 1
</td>
<td><img src="../images/Algorithms_(ANOVATwoWay)/math-100f5db42fc55631c7b4e798218f6a8f.png?v=0" title="SS_{Total}" alt="SS_{Total}" class="tex"/>
</td>
<td>
</td>
<td>
</td>
<td>
</td></tr></table>
<p>Origin’s two-way analysis of variance makes use of several NAG functions. The NAG function  <a class="external text" href="http://www.originlab.com/pdfs/nagcl09/manual/pdf/g04/g04eac.pdf" target="_blank"><b>nag_dummy_vars (g04eac)</b></a> is used to create the necessary design matrices and the NAG function <a class="external text" href="http://www.originlab.com/pdfs/nagcl09/manual/pdf/g02/g02dac.pdf" target="_blank"><b>nag_regsn_mult_linear (g02dac)</b></a> is used to perform the linear regressions of the design matrices. The results of the linear regressions are then used to construct the two-way ANOVA table. See the NAG documentation for more detailed information.
</p>
<h2><a name="Multiple_Means_Comparisons"></a><span class="mw-headline">Multiple Means Comparisons</span></h2>
<p>Given that a two-way ANOVA experiment has determined that at least one factor level mean is statistically different than the other factor level means of that factor, a means comparison subsequently compares all possible pairs of factor level means of that factor to determine which mean (or means) is ( or are ) significantly different. There are various methods for multiple means comparison in Origin, and we use the NAG function <a class="external text" href="http://www.originlab.com/pdfs/nagcl09/manual/pdf/g04/g04dbc.pdf" target="_blank"><b>nag_anova_confid_interval (g04dbc)</b></a>to perform means comparisons. 
</p><p>two types of multiple means comparison methods: 
</p><p>Single-step method. It creates simultaneous confidence intervals to show how the means differ, including Tukey-Kramer, Bonferroni, Dunn-Sidak, Fisher’s LSD, Scheffé, and Dunnett mothods.
</p><p>Stepwise method. Sequentially perform the hypothesis tests, including Holm-Bonferroni and Holm-Sidak tests
</p>
<h2><a name="Power_Analysis"></a><span class="mw-headline">Power Analysis</span></h2>
<p>The power analysis procedure calculates the actual power for the sample data, as well as the hypothetical power if additional sample sizes are specified.
</p><p>The power of a two-way analysis of variance is a measurement of its sensitivity. Power is the probability that the ANOVA will detect differences in the population means when real differences exist. In terms of the null and alternative hypotheses, power is the probability that the test statistic F will be extreme enough to reject the null hypothesis when it should be rejected actually (i.e. given the null hypothesis is not true).
</p><p>The Origin Two-Way ANOVA dialog can compute powers for the Factor A and Factor B sources.  If the Interactions check box is selected, Origin also can compute power for the Interaction source <i>A*B</i>.
</p><p>Power is defined by the equation:  
</p><p><img src="../images/Algorithms_(ANOVATwoWay)/math-e3a9b7f790e5b9b01d2fe974337ea4cf.png?v=0" title="power=1-probf(f,df,dfe,nc)\,\!" alt="power=1-probf(f,df,dfe,nc)\,\!" class="tex"/>
</p><p>where <i>f</i> is the deviate from the non-central <i>F</i>-distribution with <i>df</i> and <i>dfe</i> degrees of freedom and <i>nc = SS/MSE</i>.  SS is the sum of squares of the source <i>A</i>, <i>B</i>, or <i>A*B</i>, MSE is the mean square of the Errors, df is the degrees of freedom of the numerator for the source <i>A</i>, <i>B</i>, or <i>A*B</i>, <i>dfe</i> is the degrees of freedom of the Errors.  All values (<i>SS</i>, <i>MSE</i>, <i>df</i>, and <i>dfe</i>) are obtained from the ANOVA table. The value of <i>probf( )</i> is obtained using the NAG function <a class="external text" href="http://www.originlab.com/pdfs/nagcl09/manual/pdf/g01/g01gdc.pdf" target="_blank"><b>nag_prob_non_central_f_dist (g01gdc)</b></a> 
. See the NAG documentation for more detailed information.
</p><p>All the above is a brief algorithm outline of one-way analysis of variation, for more information about the detail mathematical deduction, please reference to the corresponding part of the user's manual and NAG document.
</p>





