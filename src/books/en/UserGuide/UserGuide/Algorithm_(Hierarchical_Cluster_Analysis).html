<h1 class="firstHeading">17.7.3.3 Algorithms (Hierarchical Cluster Analysis)</h1><p class='urlname' style='display: none'>HCA-Algorithm</p>
<p><br />
</p>
<div id="toc" class="toc"><div id="toctitle"><h2>Contents</h2></div>
<ul>
<li class="toclevel-1 tocsection-1"><a href="#Distance_Matrix"><span class="tocnumber">1</span> <span class="toctext">Distance Matrix</span></a>
<ul>
<li class="toclevel-2 tocsection-2"><a href="#Cluster_Observations"><span class="tocnumber">1.1</span> <span class="toctext">Cluster Observations</span></a></li>
<li class="toclevel-2 tocsection-3"><a href="#Cluster_Variables"><span class="tocnumber">1.2</span> <span class="toctext">Cluster Variables</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-4"><a href="#Linkage_Method"><span class="tocnumber">2</span> <span class="toctext">Linkage Method</span></a></li>
<li class="toclevel-1 tocsection-5"><a href="#Dendrogram"><span class="tocnumber">3</span> <span class="toctext">Dendrogram</span></a></li>
<li class="toclevel-1 tocsection-6"><a href="#Group_Objects"><span class="tocnumber">4</span> <span class="toctext">Group Objects</span></a></li>
</ul>
</div>

<p><b>Hierarchical Cluster Analysis</b> is used to build a hierarchical tree. It starts with n clusters, each with a single object and then at each of n âˆ’ 1 stages, merges two clusters to form a larger cluster, until all objects are in a single cluster. The process can be shown in a <b>Dendrogram</b>.
</p><p>Objects to be clustered in <b>Hierarchical Cluster Analysis</b> can be observations or variables.
</p>
<h2><a name="Distance_Matrix"></a><span class="mw-headline">Distance Matrix</span></h2>
<p>A distance, or dissimilarity, matrix is a symmetric matrix with zero diagonal elements.  The <i>ij</i>th element represents how far or how dissimilar the <i>i</i>th and <i>j</i>th objects are. Methods to calculate the distance between two objects are different for clustering observations and clustering variables.
</p>
<h3><a name="Cluster_Observations"></a><span class="mw-headline">Cluster Observations</span></h3>
<p>Origin supports standardization of data before distance calculation for clustering observations. Observations containing one or more missing values will be excluded in the analysis.
</p>
<ul><li> Standardize Variables
<ol><li> Normalize to N(0,1)
<br /> For a variable <img src="../images/Algorithm_(Hierarchical_Cluster_Analysis)/math-1ff32f369704bbf722cb41dd4727b5ea.png?v=0" title="x_j\ " alt="x_j\ " class="tex"/>, it is normalized as: <img src="../images/Algorithm_(Hierarchical_Cluster_Analysis)/math-8a2aa7bf0d735426ff95edf02207ad93.png?v=0" title="(x_j-\bar{x}_j)/\sigma_j" alt="(x_j-\bar{x}_j)/\sigma_j" class="tex"/>, where <img src="../images/Algorithm_(Hierarchical_Cluster_Analysis)/math-9a256199940d00c2536a5816e8562a68.png?v=0" title="\bar{x}_j\ " alt="\bar{x}_j\ " class="tex"/> and <img src="../images/Algorithm_(Hierarchical_Cluster_Analysis)/math-a4ff3192674d9d65f2d0d7d64cf24c70.png?v=0" title="\sigma_j\ " alt="\sigma_j\ " class="tex"/> are the mean and standard deviation of the variable. The standardized variable will have zero mean and unit standard deviation.
<li> Normalize to (0,1)
<br /> For a variable <img src="../images/Algorithm_(Hierarchical_Cluster_Analysis)/math-1ff32f369704bbf722cb41dd4727b5ea.png?v=0" title="x_j\ " alt="x_j\ " class="tex"/>, it is normalized as: <img src="../images/Algorithm_(Hierarchical_Cluster_Analysis)/math-da8bfea696c5d55d5c80213b624edaae.png?v=0" title="(x_j-\mathrm{min}(x_j))/(\mathrm{max}(x_j)-\mathrm{min}(x_j))\ " alt="(x_j-\mathrm{min}(x_j))/(\mathrm{max}(x_j)-\mathrm{min}(x_j))\ " class="tex"/>. The variable will be standardized in the range of 0 and 1.
</ol>
</ul>
<p>Origin supports these distance types:
</p>
<ul><li> Distance Type
<br /> For a standardized matrix <img src="../images/Algorithm_(Hierarchical_Cluster_Analysis)/math-61b39f8b9a10e8428d4a1ee092fe90cd.png?v=0" title="x_{ij}\ " alt="x_{ij}\ " class="tex"/> with <i>n</i> observations and <i>p</i> variables, the distance between the <i>i</i>th observation and the <i>k</i>th observation can be expressed as follows.
<ol><li> Euclidean
<br /> <img src="../images/Algorithm_(Hierarchical_Cluster_Analysis)/math-9b4e398de3c2f5d2506b9b45fe329ccc.png?v=0" title="d_{ik}=\Big\{\sum_{j=1}^p (x_{ij}-x_{kj})^2 \Big\}^{\frac{1}{2}}" alt="d_{ik}=\Big\{\sum_{j=1}^p (x_{ij}-x_{kj})^2 \Big\}^{\frac{1}{2}}" class="tex"/>
<li> Squared Euclidean
<br /> <img src="../images/Algorithm_(Hierarchical_Cluster_Analysis)/math-00782c326cb91952af29de57a841a9c2.png?v=0" title="d_{ik}=\sum_{j=1}^p (x_{ij}-x_{kj})^2" alt="d_{ik}=\sum_{j=1}^p (x_{ij}-x_{kj})^2" class="tex"/>
<li> Absolute (City block metric)
<br /> <img src="../images/Algorithm_(Hierarchical_Cluster_Analysis)/math-95f211a025ebc7daa3e1605459b1cbd2.png?v=0" title="d_{ik}=\sum_{j=1}^p |x_{ij}-x_{kj}|" alt="d_{ik}=\sum_{j=1}^p |x_{ij}-x_{kj}|" class="tex"/>
<li> Cosine
<br /> <img src="../images/Algorithm_(Hierarchical_Cluster_Analysis)/math-b9b1c3b4992cc70b4946348c159f37e6.png?v=0" title="d_{ik}=1-\frac{\sum_{j=1}^p x_{ij}x_{kj}}{\sqrt{\sum_{j=1}^p x_{ij}^2}\sqrt{\sum_{j=1}^p x_{kj}^2}}" alt="d_{ik}=1-\frac{\sum_{j=1}^p x_{ij}x_{kj}}{\sqrt{\sum_{j=1}^p x_{ij}^2}\sqrt{\sum_{j=1}^p x_{kj}^2}}" class="tex"/>
<li> Pearson correlation
<br /> <img src="../images/Algorithm_(Hierarchical_Cluster_Analysis)/math-36d3bef9314267d27776738195752c04.png?v=0" title="d_{ik}=1-\frac{\sum_{j=1}^p (x_{ij}- \bar x_i)(x_{kj}- \bar x_k)}{\sqrt{\sum_{j=1}^p (x_{ij}- \bar x_i)^2}\sqrt{\sum_{j=1}^p (x_{kj}- \bar x_k)^2}}" alt="d_{ik}=1-\frac{\sum_{j=1}^p (x_{ij}- \bar x_i)(x_{kj}- \bar x_k)}{\sqrt{\sum_{j=1}^p (x_{ij}- \bar x_i)^2}\sqrt{\sum_{j=1}^p (x_{kj}- \bar x_k)^2}}" class="tex"/>
<br />
where <img src="../images/Algorithm_(Hierarchical_Cluster_Analysis)/math-0ff233a32e8ef8117a1b351b11a3a544.png?v=0" title="\bar x_i=\sum_{j=1}^p x_{ij}" alt="\bar x_i=\sum_{j=1}^p x_{ij}" class="tex"/> and <img src="../images/Algorithm_(Hierarchical_Cluster_Analysis)/math-026de1a29e08504cc940a5d530450259.png?v=0" title="\bar x_k=\sum_{j=1}^p x_{kj}" alt="\bar x_k=\sum_{j=1}^p x_{kj}" class="tex"/>
<li> Jaccard
<br /> <img src="../images/Algorithm_(Hierarchical_Cluster_Analysis)/math-c8ba27ae461ab7e05dfd221d6f617dfe.png?v=0" title="d_{ik}=\frac{\sum_{j=1}^p ( (x_{ij} \ne x_{kj}) \bigcap (x_{ij} \ne 0 \bigcup x_{kj} \ne 0) )&#160;? 1:0 }{\sum_{j=1}^p (x_{ij} \ne 0 \bigcup x_{kj} \ne 0) )&#160;? 1:0}" alt="d_{ik}=\frac{\sum_{j=1}^p ( (x_{ij} \ne x_{kj}) \bigcap (x_{ij} \ne 0 \bigcup x_{kj} \ne 0) )&#160;? 1:0 }{\sum_{j=1}^p (x_{ij} \ne 0 \bigcup x_{kj} \ne 0) )&#160;? 1:0}" class="tex"/>
</ol>
</ul>
<h3><a name="Cluster_Variables"></a><span class="mw-headline">Cluster Variables</span></h3>
<p>Origin supports two distance types for clustering variables. Observations will be excluded in the calculation of the correlation between two variables if missing values exist in either of the variables. 
</p>
<ul><li> Distance Type
<br /> For a matrix <img src="../images/Algorithm_(Hierarchical_Cluster_Analysis)/math-61b39f8b9a10e8428d4a1ee092fe90cd.png?v=0" title="x_{ij}\ " alt="x_{ij}\ " class="tex"/> with <i>n</i> observations and <i>p</i> variables, the distance between the <i>j</i>th variable and the <i>k</i>th variable can be expressed as follows:
<ol><li> Correlation
<br /> <img src="../images/Algorithm_(Hierarchical_Cluster_Analysis)/math-1fb6205bac10ad6d294c90cb9837e9c5.png?v=0" title="d_{jk}=1-\mathrm{corr}(x_j, x_k)\ " alt="d_{jk}=1-\mathrm{corr}(x_j, x_k)\ " class="tex"/> where <img src="../images/Algorithm_(Hierarchical_Cluster_Analysis)/math-c3683cdadf1e9d4e33ea12a052c0f174.png?v=0" title="\mathrm{corr}(x_j, x_k)\ " alt="\mathrm{corr}(x_j, x_k)\ " class="tex"/> is the correlation between the <i>j</i>th variable and the <i>k</i>th variable.
<li> Absolute correlation
<br /> <img src="../images/Algorithm_(Hierarchical_Cluster_Analysis)/math-51b38858ea57d12c43210595a9d3661f.png?v=0" title="d_{jk}=1-|\mathrm{corr}(x_j, x_k)|\ " alt="d_{jk}=1-|\mathrm{corr}(x_j, x_k)|\ " class="tex"/>
</ol>
</ul>
<h2><a name="Linkage_Method"></a><span class="mw-headline">Linkage Method</span></h2>
<p>At each stage, the two clusters that are nearest are merged. Origin provides several methods to calculate the distance between the new cluster and other clusters. Let clusters <i>j</i> and <i>k</i> be merged as cluster <i>jk</i>. Let <img src="../images/Algorithm_(Hierarchical_Cluster_Analysis)/math-4977ea7b014aa7a99a12a7a0c45b76f6.png?v=0" title="n_i\ " alt="n_i\ " class="tex"/>, <img src="../images/Algorithm_(Hierarchical_Cluster_Analysis)/math-f898efd8ac64b6621a2aeed350ce3164.png?v=0" title="n_j\ " alt="n_j\ " class="tex"/> and <img src="../images/Algorithm_(Hierarchical_Cluster_Analysis)/math-fd91d2523217931bfcd6f684555f4d7f.png?v=0" title="n_k\ " alt="n_k\ " class="tex"/> be number of objects of Cluster <i>i</i>, Cluster <i>j</i> and Cluster <i>k</i> respectively, and let <img src="../images/Algorithm_(Hierarchical_Cluster_Analysis)/math-2a81a0fc16ebf02e971257997dafa28b.png?v=0" title="d_{ij}\ " alt="d_{ij}\ " class="tex"/>, <img src="../images/Algorithm_(Hierarchical_Cluster_Analysis)/math-c198e05d8ed1e6f1af582129382f6495.png?v=0" title="d_{ik}\ " alt="d_{ik}\ " class="tex"/> and <img src="../images/Algorithm_(Hierarchical_Cluster_Analysis)/math-e2ed69879e29cc9517eb1a1f2ecab0cb.png?v=0" title="d_{jk}\ " alt="d_{jk}\ " class="tex"/> be the distance between two clusters.  The distance between Cluster <i>jk</i> and Cluster <i>i</i> <img src="../images/Algorithm_(Hierarchical_Cluster_Analysis)/math-a473b8369dd26440ac973f3cf3de62ed.png?v=0" title="d_{i,jk}\ " alt="d_{i,jk}\ " class="tex"/>can then be calculated in the following ways:
</p>
<ol><li>Single link or Nearest neighbor
<br /> <img src="../images/Algorithm_(Hierarchical_Cluster_Analysis)/math-1decc6265d2731648206786ae0cc44e7.png?v=0" title="d_{i,jk}=\mathrm{min}(d_{ij},d_{ik})\ " alt="d_{i,jk}=\mathrm{min}(d_{ij},d_{ik})\ " class="tex"/>
<li>Complete link or Furthest neighbor
<br /> <img src="../images/Algorithm_(Hierarchical_Cluster_Analysis)/math-88af2544aa89b6c5eb3bd10fbfc65fac.png?v=0" title="d_{i,jk}=\mathrm{max}(d_{ij},d_{ik})\ " alt="d_{i,jk}=\mathrm{max}(d_{ij},d_{ik})\ " class="tex"/>
<li>Group average
<br /> <img src="../images/Algorithm_(Hierarchical_Cluster_Analysis)/math-a117d8802250e31ee98a59d789fb3728.png?v=0" title="d_{i,jk}=\frac{n_j}{n_j+n_k}d_{ij}+\frac{n_k}{n_j+n_k}d_{ik}\ " alt="d_{i,jk}=\frac{n_j}{n_j+n_k}d_{ij}+\frac{n_k}{n_j+n_k}d_{ik}\ " class="tex"/>
<li>Centroid
<br /> <img src="../images/Algorithm_(Hierarchical_Cluster_Analysis)/math-a1e87a55511ee73bf5adfe0699ff3114.png?v=0" title="d_{i,jk}=\frac{n_j}{n_j+n_k}d_{ij}+\frac{n_k}{n_j+n_k}d_{ik}-\frac{n_jn_k}{(n_j+n_k)^2}d_{jk}\ " alt="d_{i,jk}=\frac{n_j}{n_j+n_k}d_{ij}+\frac{n_k}{n_j+n_k}d_{ik}-\frac{n_jn_k}{(n_j+n_k)^2}d_{jk}\ " class="tex"/>
<li>Median
<br /> <img src="../images/Algorithm_(Hierarchical_Cluster_Analysis)/math-f7defcfc31776fe2c1319c4424b56a88.png?v=0" title="d_{i,jk}=\frac{1}{2}d_{ij}+\frac{1}{2}d_{ik}-\frac{1}{4}d_{jk}\ " alt="d_{i,jk}=\frac{1}{2}d_{ij}+\frac{1}{2}d_{ik}-\frac{1}{4}d_{jk}\ " class="tex"/>
<li>Minimum variance or Ward
<br /> <img src="../images/Algorithm_(Hierarchical_Cluster_Analysis)/math-ebce4775175a80790a9f3ce946072790.png?v=0" title="d_{i,jk}=\frac{(n_i+n_j)d_{ij}+(n_i+n_k)d_{ik}-n_id_{jk}}{n_i+n_j+n_k}\ " alt="d_{i,jk}=\frac{(n_i+n_j)d_{ij}+(n_i+n_k)d_{ik}-n_id_{jk}}{n_i+n_j+n_k}\ " class="tex"/>
</ol>
<p>If clusters <i>j</i> and <i>k</i>, <i>j</i>&lt;<i>k</i>, merge then the new cluster will be referred to as Cluster <i>j</i> in the <b>Cluster Stages</b> table.
</p>
<h2><a name="Dendrogram"></a><span class="mw-headline">Dendrogram</span></h2>
<p>The <b>Dendrogram</b> plot is a hierarchical tree that shows the distance at which two clusters merge. Each stage is represented as a unit in the <b>Dendrogram</b>. The top of the unit for each stage represents the new cluster by the merging of two clusters. Its height corresponds to the distance between two merged clusters.
</p><p>The end-points of the <b>Dendrogram</b> represent <i>n</i> objects. <i>n</i> objects in the <b>Dendrogram</b> are sorted so that the clusters that merge are adjacent. The first end-point in the <b>Dendrogram</b> always corresponds to the first object.
</p>
<h2><a name="Group_Objects"></a><span class="mw-headline">Group Objects</span></h2>
<p>Membership of <i>n</i> objects for specified <i>k</i> clusters can be determined from the information in the <b>Dendrogram</b> plot or <b>Cluster Stages</b> table. <i>k</i> clusters exist at the <i>n-k</i>th stage, which means membership of each object can be known from the first <i>n-k</i>th stages. Object 1 always belongs to Cluster 1.
</p><p>Cluster centers, the distance between cluster centers, and the distance between observations and clusters, are calculated for clustering observations. Note that observations are standardized in the calculation if standardization is chosen in the analysis.
</p>





