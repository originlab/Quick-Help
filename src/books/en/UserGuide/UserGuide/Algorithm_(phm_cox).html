<h1 class="firstHeading">17.6.2.2 Algorithms (Cox Proportional Hazard Regression)</h1><p class='urlname' style='display: none'>PHM-Cox-Algorithm</p>
<p>Let <img src="../images/Algorithm_(phm_cox)/math-b4a096d9d2236359a73b7386af0c9ab6.png?v=0" title="t_i\,\!" alt="t_i\,\!" class="tex"/>,for <i>i = 1, 2,&#160;?, n</i>, be the failure time or censored time for the <i>i</i>th observation with the vector of <i>p</i> covariates <img src="../images/Algorithm_(phm_cox)/math-e9b2a0e549182ce07a674b99d3bdd987.png?v=0" title="Z_j(j=1,2,\ldots ,p)" alt="Z_j(j=1,2,\ldots ,p)" class="tex"/>. It is assumed that the failure and censored mechanisms are independent. The hazard function, <img src="../images/Algorithm_(phm_cox)/math-b4edeac500164ed31e65913d1bf90051.png?v=0" title="\lambda (z,t)\,\!" alt="\lambda (z,t)\,\!" class="tex"/> , is the probability that an individual with covariates z fails at time <i>t</i> given that the individual survived up to time <i>t</i>. In the Cox proportional model is of the form:
</p><p><img src="../images/Algorithm_(phm_cox)/math-7fd25fca62158bf07a508af6b3048824.png?v=0" title="\lambda (z,t)=\lambda _0(t)\exp (z^{T}\beta +\omega )\,\!" alt="\lambda (z,t)=\lambda _0(t)\exp (z^{T}\beta +\omega )\,\!" class="tex"/>
</p><p>where <img src="../images/Algorithm_(phm_cox)/math-3edc1ca1e622708969948a2514e800f2.png?v=0" title="\lambda _0\,\!" alt="\lambda _0\,\!" class="tex"/> is the base-line hazard function, an unspecified function of time, <img src="../images/Algorithm_(phm_cox)/math-5b320b6d3d3254d936c752ae308dbfd8.png?v=0" title="\beta \,\!" alt="\beta \,\!" class="tex"/> is a vector of unknown parameters and <img src="../images/Algorithm_(phm_cox)/math-f2f1b18a419c6fddc9ad79a13a5946e3.png?v=0" title="\omega\,\!" alt="\omega\,\!" class="tex"/> is a known offset.
</p><p>Assuming there are ties in the failure time giving <img src="../images/Algorithm_(phm_cox)/math-99af4576b28fa0e44da190e42ca9fdfb.png?v=0" title="n_d &lt; n\,\!" alt="n_d &lt; n\,\!" class="tex"/> distinct failure times, <img src="../images/Algorithm_(phm_cox)/math-afdb5212c7209b37b90b950f8e435844.png?v=0" title="t_{(1)} &lt; t_{(2)} &lt;&#160;?&lt; t_{(nd)}" alt="t_{(1)} &lt; t_{(2)} &lt;&#160;?&lt; t_{(nd)}" class="tex"/> , such that <img src="../images/Algorithm_(phm_cox)/math-40b4081d7e04c18f0529a2e70a11e290.png?v=0" title="d_i\,\!" alt="d_i\,\!" class="tex"/> individuals fail at <img src="../images/Algorithm_(phm_cox)/math-659eb06b406d2e114b139d0dd37ba959.png?v=0" title="t_{(i)}\,\!" alt="t_{(i)}\,\!" class="tex"/> , it follows that the marginal likelihood for <img src="../images/Algorithm_(phm_cox)/math-b0603860fcffe94e5b8eec59ed813421.png?v=0" title="\beta" alt="\beta" class="tex"/> is well approximated by:
</p>
<table class="formula">

<tr>
<td>
<p><img src="../images/Algorithm_(phm_cox)/math-746fdd59f1f86341fb6c80f477eef31d.png?v=0" title="L=\prod_{i=1}^{n_d}\frac{\exp (s_i^{T}\beta +\omega _i)}{[\sum_{l\in R(t_{(1)})}\exp (z_i^{T}\beta +\omega _i)]^{d_{i}}}" alt="L=\prod_{i=1}^{n_d}\frac{\exp (s_i^{T}\beta +\omega _i)}{[\sum_{l\in R(t_{(1)})}\exp (z_i^{T}\beta +\omega _i)]^{d_{i}}}" class="tex"/>                
</p>
</td>
<td>
<p>(1)  
</p>
</td></tr></table>
<p>where <img src="../images/Algorithm_(phm_cox)/math-df637c345145e684f09c3e2bf73732cf.png?v=0" title="s_i\,\!" alt="s_i\,\!" class="tex"/> is the sum of covariate of individuals observed fail at <img src="../images/Algorithm_(phm_cox)/math-659eb06b406d2e114b139d0dd37ba959.png?v=0" title="t_{(i)}\,\!" alt="t_{(i)}\,\!" class="tex"/> and <img src="../images/Algorithm_(phm_cox)/math-ee91b0d4f1eaf7196ca8b86c689bce4c.png?v=0" title="R(t_{(i)})\,\!" alt="R(t_{(i)})\,\!" class="tex"/> is the set of individuals at risk just prior to <img src="../images/Algorithm_(phm_cox)/math-659eb06b406d2e114b139d0dd37ba959.png?v=0" title="t_{(i)}\,\!" alt="t_{(i)}\,\!" class="tex"/> , that is it is all the individuals that fail or censored at time <img src="../images/Algorithm_(phm_cox)/math-f82bfe760d9b9727abfa6b9f205b4291.png?v=0" title="t_{(i)}" alt="t_{(i)}" class="tex"/> along with all individuals survived beyond the time <img src="../images/Algorithm_(phm_cox)/math-659eb06b406d2e114b139d0dd37ba959.png?v=0" title="t_{(i)}\,\!" alt="t_{(i)}\,\!" class="tex"/> . The MLE (maximum likelihood estimates) of <img src="../images/Algorithm_(phm_cox)/math-8d2bf18dffee8005942fdde98a69f3a1.png?v=0" title="\beta\,\!" alt="\beta\,\!" class="tex"/>, given by<img src="../images/Algorithm_(phm_cox)/math-950a1c15a15d3e439fc0c39729c41abe.png?v=0" title="\hat \beta\,\!" alt="\hat \beta\,\!" class="tex"/>, are obtained by maximizing (1) using a Newton-Raphson iteration technique that includes step having and utilizes the first and second partial derivatives of (1) which are given by (2) and (3) below:
</p>
<table class="formula">

<tr>
<td>
<p><img src="../images/Algorithm_(phm_cox)/math-2f4266ed0d3815eaca058ea19e181c0e.png?v=0" title="U_j(\beta )=\frac{\partial Ln(L)}{\partial \beta _j}=\sum_{i=1}^{n_d}[s_{ji}-d_i\alpha _{ji}(\beta )]=0" alt="U_j(\beta )=\frac{\partial Ln(L)}{\partial \beta _j}=\sum_{i=1}^{n_d}[s_{ji}-d_i\alpha _{ji}(\beta )]=0" class="tex"/>       
</p>
</td>
<td>
<p>(2)  
</p>
</td></tr></table>
<p>for <i>j = 1, 2,&#160;?, p</i>, where <img src="../images/Algorithm_(phm_cox)/math-c187e0049b758f53e5e0d9889f652f49.png?v=0" title="s_{ji}\,\!" alt="s_{ji}\,\!" class="tex"/> is the <i>j</i>th element in the vector <img src="../images/Algorithm_(phm_cox)/math-df637c345145e684f09c3e2bf73732cf.png?v=0" title="s_i\,\!" alt="s_i\,\!" class="tex"/> and
</p><p><img src="../images/Algorithm_(phm_cox)/math-a28a80d6e7722fccef4fc3249adc4ca2.png?v=0" title="\alpha _{ji}(\beta )=\frac{\sum_{l\in R(t_{(1)})}z_{jl}\exp (z_l^{T}\beta +\omega _l)}{\sum_{l\in R(t_{(1)})}\exp (z_l^{T}\beta +\omega _l)}" alt="\alpha _{ji}(\beta )=\frac{\sum_{l\in R(t_{(1)})}z_{jl}\exp (z_l^{T}\beta +\omega _l)}{\sum_{l\in R(t_{(1)})}\exp (z_l^{T}\beta +\omega _l)}" class="tex"/>
</p><p>Similarly, 
</p>
<table class="formula">

<tr>
<td>
<p><img src="../images/Algorithm_(phm_cox)/math-f7f5ed8c6b97518204b6c96b8797c7d9.png?v=0" title="I_{hj}(\beta )=-\frac{\partial ^2Ln(L)}{\partial \beta _h\partial \beta _j}=\sum_{i=1}^{n_d}d_i\gamma _{hji}" alt="I_{hj}(\beta )=-\frac{\partial ^2Ln(L)}{\partial \beta _h\partial \beta _j}=\sum_{i=1}^{n_d}d_i\gamma _{hji}" class="tex"/>               
</p>
</td>
<td>
<p>(3)  
</p>
</td></tr></table>
<p>where  <img src="../images/Algorithm_(phm_cox)/math-b9afb94ffa7c4b399e7da601d15f214c.png?v=0" title="\gamma _{hji}=\frac{\sum_{l\in R(t_{(1)})}z_{hl}z_{jl}\exp (z_l^{T}\beta +\omega _l)}{\sum_{l\in R(t_{(1)})}\exp (z_l^{T}\beta +\omega _l)}-\alpha _{hi}(\beta )\alpha _{ji}(\beta )" alt="\gamma _{hji}=\frac{\sum_{l\in R(t_{(1)})}z_{hl}z_{jl}\exp (z_l^{T}\beta +\omega _l)}{\sum_{l\in R(t_{(1)})}\exp (z_l^{T}\beta +\omega _l)}-\alpha _{hi}(\beta )\alpha _{ji}(\beta )" class="tex"/>   <i> h</i>, <i>j = 1,&#160;? p</i>.
</p><p><img src="../images/Algorithm_(phm_cox)/math-94b61be7dbb72780127ba83b9a55c19f.png?v=0" title="U_j(\beta )\,\!" alt="U_j(\beta )\,\!" class="tex"/> is the <i>j</i>th component of a score vector <img src="../images/Algorithm_(phm_cox)/math-1a14fac8fed1c86899f6f323acabceea.png?v=0" title="I_{hi}(\beta )\,\!" alt="I_{hi}(\beta )\,\!" class="tex"/> is the (<i>h, j</i>) element of the observed information matrix <img src="../images/Algorithm_(phm_cox)/math-a139862e5a9fa67a8d14878476236d55.png?v=0" title="I(\beta )\,\!" alt="I(\beta )\,\!" class="tex"/> whose inverse <img src="../images/Algorithm_(phm_cox)/math-3d35c360006c6b692bb24cfaa0162d4b.png?v=0" title="I(\beta )^{-1}=I_{hi}(\beta )^{-1}\,\!" alt="I(\beta )^{-1}=I_{hi}(\beta )^{-1}\,\!" class="tex"/> gives the variance-covariance matrix of <img src="../images/Algorithm_(phm_cox)/math-8d2bf18dffee8005942fdde98a69f3a1.png?v=0" title="\beta\,\!" alt="\beta\,\!" class="tex"/>.
</p><p>It should be noted that if a covariate or a linear combination of covariates is monotonically increasing or decreasing with time ,then one or more of the <img src="../images/Algorithm_(phm_cox)/math-35ddbb0efc4d0c98d6f19a3b84c1db78.png?v=0" title="\beta _j^{\prime }s" alt="\beta _j^{\prime }s" class="tex"/> will be infinite.
</p><p>If <img src="../images/Algorithm_(phm_cox)/math-8883b73ab26908c75308092259b6d141.png?v=0" title="\lambda _0(t)\,\!" alt="\lambda _0(t)\,\!" class="tex"/> varies across <img src="../images/Algorithm_(phm_cox)/math-3b0619e986d2ebf9acd80c494cb421a4.png?v=0" title="\nu\,\!" alt="\nu\,\!" class="tex"/> strata, where the number of individuals in the <i>k</i>th stratum is <img src="../images/Algorithm_(phm_cox)/math-3da18b12eaeaccf089fe39883448b765.png?v=0" title="n_k\,\!" alt="n_k\,\!" class="tex"/>, <i>k = 1,&#160;?, <img src="../images/Algorithm_(phm_cox)/math-3b0619e986d2ebf9acd80c494cb421a4.png?v=0" title="\nu\,\!" alt="\nu\,\!" class="tex"/></i>, with <img src="../images/Algorithm_(phm_cox)/math-ff8c77ee62f8208a4dbab23d6a511dcc.png?v=0" title="n=\sum_{k=1}^\nu n_k" alt="n=\sum_{k=1}^\nu n_k" class="tex"/> , then rather than maximizing (1) to obtain <img src="../images/Algorithm_(phm_cox)/math-950a1c15a15d3e439fc0c39729c41abe.png?v=0" title="\hat \beta\,\!" alt="\hat \beta\,\!" class="tex"/>, the following marginal likelihood is maximized: 
</p>
<table class="formula">

<tr>
<td>
<p><img src="../images/Algorithm_(phm_cox)/math-3423d4e0ec03428876c386cf59a58dfe.png?v=0" title="L=\prod_{k=1}^\nu L_k" alt="L=\prod_{k=1}^\nu L_k" class="tex"/>                
</p>
</td>
<td>
<p>(4)  
</p>
</td></tr></table>
<p>where <img src="../images/Algorithm_(phm_cox)/math-39209f726b762faf7442e04a446ad41f.png?v=0" title="L_k\,\!" alt="L_k\,\!" class="tex"/> is the contribution to likelihood for the <img src="../images/Algorithm_(phm_cox)/math-3da18b12eaeaccf089fe39883448b765.png?v=0" title="n_k\,\!" alt="n_k\,\!" class="tex"/> observations in the <i>k</i>th stratum treated as a single sample in (1). When strata are concluded the covariate coefficients are constant across strata but there is a different base-line hazard function <img src="../images/Algorithm_(phm_cox)/math-8883b73ab26908c75308092259b6d141.png?v=0" title="\lambda _0(t)\,\!" alt="\lambda _0(t)\,\!" class="tex"/>.
</p><p>The base-line survival function associated with a failure time <img src="../images/Algorithm_(phm_cox)/math-659eb06b406d2e114b139d0dd37ba959.png?v=0" title="t_{(i)}\,\!" alt="t_{(i)}\,\!" class="tex"/> , is estimated as 
</p><p><img src="../images/Algorithm_(phm_cox)/math-0b8df9b2daec8e7514a7c2cd894f8faf.png?v=0" title="exp(-\hat H(t_{(i)}))" alt="exp(-\hat H(t_{(i)}))" class="tex"/> , 
</p><p>where <img src="../images/Algorithm_(phm_cox)/math-ca2e935da3c4ec9f78523b3db2309234.png?v=0" title="\hat H(t_{(i)})=\sum_{t(j)\leq t(i)}(\frac{d_i}{\sum_{l\in R(t_{(j)})}\exp (z_l^T\hat \beta +\omega _l)})" alt="\hat H(t_{(i)})=\sum_{t(j)\leq t(i)}(\frac{d_i}{\sum_{l\in R(t_{(j)})}\exp (z_l^T\hat \beta +\omega _l)})" class="tex"/>
</p><p>and <img src="../images/Algorithm_(phm_cox)/math-40b4081d7e04c18f0529a2e70a11e290.png?v=0" title="d_i\,\!" alt="d_i\,\!" class="tex"/> is the number of failures at time <img src="../images/Algorithm_(phm_cox)/math-659eb06b406d2e114b139d0dd37ba959.png?v=0" title="t_{(i)}\,\!" alt="t_{(i)}\,\!" class="tex"/> . The residual of the <i>l</i>th observation is computed as: 
</p><p><img src="../images/Algorithm_(phm_cox)/math-a5cc248e45947fea428f4b34caff7093.png?v=0" title="r(t_l)=\hat H(t_l)\exp (-z_l^T\hat \beta +\omega _l)" alt="r(t_l)=\hat H(t_l)\exp (-z_l^T\hat \beta +\omega _l)" class="tex"/>
</p><p>where <img src="../images/Algorithm_(phm_cox)/math-b77e639a3484da642fbbd419c433f190.png?v=0" title="\hat H(t_l)=\hat H(t_{(i)}),t_{(i)}\leq t_l&lt;t_{(i+1)}" alt="\hat H(t_l)=\hat H(t_{(i)}),t_{(i)}\leq t_l&lt;t_{(i+1)}" class="tex"/> . 
</p><p>The deviance is defined as <img src="../images/Algorithm_(phm_cox)/math-22a372fe7aefbb5295da3f13a354ea31.png?v=0" title="-2^*\,\!" alt="-2^*\,\!" class="tex"/> (logarithm of marginal likelihood). There are two ways to test whether individual covariates are significant: the differences between the deviances of nested models can be compared with appropriate <img src="../images/Algorithm_(phm_cox)/math-c15009ca5cbb034d023f145a4ed23b8d.png?v=0" title="\chi ^2\,\!" alt="\chi ^2\,\!" class="tex"/>-distribution; or, the asymptotic normality of the parameter estimates can be used to form z-test by dividing the estimates by their standard errors or the score function for the model under the null hypothesis can be used to form z-test.
</p>





