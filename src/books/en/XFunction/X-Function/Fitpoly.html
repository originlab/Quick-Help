<h1 class="firstHeading">2.4.8 fitpoly</h1><div id="toc" class="toc"><div id="toctitle"><h2>Contents</h2></div>
<ul>
<li class="toclevel-1 tocsection-1"><a href="#Brief_Information"><span class="tocnumber">1</span> <span class="toctext">Brief Information</span></a></li>
<li class="toclevel-1 tocsection-2"><a href="#Additional_Information"><span class="tocnumber">2</span> <span class="toctext">Additional Information</span></a></li>
<li class="toclevel-1 tocsection-3"><a href="#Command_Line_Usage"><span class="tocnumber">3</span> <span class="toctext">Command Line Usage</span></a></li>
<li class="toclevel-1 tocsection-4"><a href="#X-Function_Execution_Options"><span class="tocnumber">4</span> <span class="toctext">X-Function Execution Options</span></a></li>
<li class="toclevel-1 tocsection-5"><a href="#Variables"><span class="tocnumber">5</span> <span class="toctext">Variables</span></a></li>
<li class="toclevel-1 tocsection-6"><a href="#Description"><span class="tocnumber">6</span> <span class="toctext">Description</span></a></li>
<li class="toclevel-1 tocsection-7"><a href="#Examples"><span class="tocnumber">7</span> <span class="toctext">Examples</span></a></li>
<li class="toclevel-1 tocsection-8"><a href="#Algorithm"><span class="tocnumber">8</span> <span class="toctext">Algorithm</span></a></li>
<li class="toclevel-1 tocsection-9"><a href="#References"><span class="tocnumber">9</span> <span class="toctext">References</span></a></li>
<li class="toclevel-1 tocsection-10"><a href="#Related_X-Functions"><span class="tocnumber">10</span> <span class="toctext">Related X-Functions</span></a></li>
</ul>
</div>

<h2><a name="Brief_Information"></a><span class="mw-headline">Brief Information</span></h2>
<p>Polynomial regression
</p>
<h2><a name="Additional_Information"></a><span class="mw-headline">Additional Information</span></h2>
<p>Minimum Origin Version Required for all features: Origin 9.0
</p>
<h2><a name="Command_Line_Usage"></a><span class="mw-headline">Command Line Usage</span></h2>
<pre>
1. fitpoly iy:=(1,2) polyorder:=2 fixint:=0 intercept:=0 coef:=3 oy:=(4,5);
</pre>
<h2><a name="X-Function_Execution_Options"></a><span class="mw-headline">X-Function Execution Options</span></h2>
<p><a class="external text" href="../../LabTalk/LabTalk/X-Function_Execution_Options.html">Please refer to the page for additional option switches when accessing the x-function from script</a>
</p>
<h2><a name="Variables"></a><span class="mw-headline">Variables</span></h2>
<table class="xfvar">
<tr>
<th width="8%">Display<br />Name
</th>
<th width="8%">Variable<br />Name
</th>
<th width="8%">I/O<br />and<br />Type
</th>
<th width="8%">Default<br />Value
</th>
<th>Description
</th></tr>
<tr>
<td>Input
</td>
<td>iy
</td>
<td>
<p>Input
</p><p>XYRange
</p>
</td>
<td> <center>&lt;active&gt;</center>
</td>
<td> This variable specifies the input data range.
</td></tr>
<tr>
<td>Polynomial Order
</td>
<td>polyorder
</td>
<td>
<p>Input
</p><p>int
</p>
</td>
<td> <center>2</center>
</td>
<td> This variable specifies the order of polynomial to be fit.
</td></tr>

<tr>
<td>Fix Intercept
</td>
<td>fixint
</td>
<td>
<p>Input
</p><p>int
</p>
</td>
<td><center>0</center>
</td>
<td> A value of 1 (checked in dialog) indicates fixed intercept.
</td></tr>

<tr>
<td>Fix Intercept At
</td>
<td>intercept
</td>
<td>
<p>Input
</p><p>double
</p>
</td>
<td><center>0</center>
</td>
<td> Specify the value of fixed intercept. If <i>fixint</i> is 0, this value is ignored.
</td></tr>


<tr>
<td>Polynomial Coefficients
</td>
<td>coef
</td>
<td>
<p>Output
</p><p>vector
</p>
</td>
<td> <center>&lt;optional&gt;</center>
</td>
<td> This specifies the column or dataset variable to receive the polynomial coefficients, e.g. coef:=3, which means to output the polynomial coefficients to column 3.
</td></tr>
<tr>
<td>Output
</td>
<td>oy
</td>
<td>
<p>Output
</p><p>XYRange
</p>
</td>
<td> <center>&lt;optional&gt;</center>
</td>
<td> This specifies the Output range to receive the polynomial fit curve.
</td></tr>
<tr>
<td>Number of Points
</td>
<td>N
</td>
<td>
<p>Output
</p><p>int
</p>
</td>
<td> <center>&lt;unassigned&gt;</center>
</td>
<td> This specifies the variable to receive number of points in the fit.
</td></tr>
<tr>
<td>Adjusted residual sum of squares
</td>
<td>AdjRSq
</td>
<td>
<p>Output
</p><p>double
</p>
</td>
<td> <center>&lt;unassigned&gt;</center>
</td>
<td> This specifies the variable to receive the adjusted coefficient of determination(R^2).
</td></tr>
<tr>
<td>Coefficient of determination (R^2)
</td>
<td>RSqCOD
</td>
<td>
<p>Output
</p><p>double
</p>
</td>
<td> <center>&lt;unassigned&gt;</center>
</td>
<td> This specifies the column or dataset variable to receive the coefficient of determination((R^2).
</td></tr>
<tr>
<td>Polynomial Coefficients Errors
</td>
<td>err
</td>
<td>
<p>Output
</p><p>vector
</p>
</td>
<td> <center>&lt;optional&gt;</center>
</td>
<td> This specifies the column or dataset variable to receive the polynomial coefficients standard errors
</td></tr></table>
<h2><a name="Description"></a><span class="mw-headline">Description</span></h2>
<p>Polynomial regression fits a given data set to the following model:
</p>
<dl><dd><a  class="image"><img alt="FitPolynomial help English files image006.gif" src="../images/Fitpoly/FitPolynomial_help_English_files_image006.gif?v=947" width="271"  /></a>.</dd></dl>
<p>where <i><img src="../images/Fitpoly/math-d2a75ebcf754b11a4af99348833d82b1.png?v=0" title="\gamma_i" alt="\gamma_i" class="tex"/></i> are the coefficients and <i><img src="../images/Fitpoly/math-92e4da341fe8f4cd46192f21b6ff3aa7.png?v=0" title="\epsilon" alt="\epsilon" class="tex"/></i> is the error term. The error term represents the unexpected or unexplained variation in the dependent variable. It is assumed that the mean of the random variable <img src="../images/Fitpoly/math-92e4da341fe8f4cd46192f21b6ff3aa7.png?v=0" title="\epsilon" alt="\epsilon" class="tex"/> is equal to zero.
</p><p>Parameters are estimated using a weighted least-square method. This method minimizes the sum of the squares of the deviations between the theoretical curve and the experimental points for a range of independent variables. After fitting, the model can be evaluated using hypothesis tests and by plotting residuals.
</p><p>It is worth noting that the higher order terms in polynomial equation have the greatest effect on the dependent variable. Consequently, models with high order terms (higher than 4) are extremely sensitive to the precision of coefficient values, where small differences in the coefficient values can result in a larges differences in the computed y value. We mention this because, by default, the polynomial fitting results are rounded to 5 decimal places. If you manually plug these reported worksheet values back into the fitted curve, the slight loss of precision that occurs in rounding will have a marked effect on the higher order terms, possibly leading you to conclude wrongly, that your model is faulty. If you wish to perform manual calculations using your best-fit parameter estimates, make sure that you use full-precision values, not rounded values. Note that while Origin may round reported values to 5 decimal places (or other), these values are only for display purposes. Origin always uses full precision (double(8)) in mathematical calculations unless you have specified otherwise. For more information, see Numbers in Origin.
</p><p>Generally speaking, any continuous function can be fitted to a higher order polynomial model. However, higher order terms may not have much practical significance.
</p>
<h2><a name="Examples"></a><span class="mw-headline">Examples</span></h2>
<ul><li> Code Sample</li></ul>
<pre class="lt" style="font-family:monospace;"><span style="color: #008000;">// This example shows how to use the fitpoly Polynomial Fit function and access the results.</span>
<span style="color: #008000;">// Get some sample data</span>
newbook name<span style="color: #000000;">:</span><span style="color: #000080;">=</span><span style="color: #ff00ff;">&quot;Linear Regression Sample&quot;</span> sheet<span style="color: #000000;">:</span><span style="color: #000080;">=</span><span style="color: #0000dd;">1</span> result<span style="color: #000000;">:</span><span style="color: #000080;">=</span>ResultBook<span style="color: #000080;">$</span>;
impfile fname<span style="color: #000000;">:</span><span style="color: #000080;">=</span>system.<span style="color: #000080;">path</span>.<span style="color: #000080;">program</span><span style="color: #000080;">$</span><span style="color: #000080;">+</span><span style="color: #ff00ff;">&quot;Samples\Curve Fitting\Multiple Gaussians.dat&quot;</span>;
<span style="color: #008000;">// Declare variables for coefficients and Adjusted R^2</span>
dataset ds;	<span style="color: #008000;">// vector argument requires dataset</span>
double  MyR;
<span style="color: #008000;">// Setup table for output</span>
type Dataset\tA0\tA1\tA2\tA3\tAdjR<span style="color: #000080;">^</span><span style="color: #0000dd;">2</span>;
separator <span style="color: #0000dd;">6</span>;

<span style="color: #008000;">// Now loop through all four curves, fit and report</span>
loop<span style="color: #000000;">&#40;</span>ii,<span style="color: #0000dd;">2</span>,<span style="color: #0000dd;">5</span><span style="color: #000000;">&#41;</span> <span style="color: #000000;">&#123;</span>
    fitpoly iy<span style="color: #000000;">:</span><span style="color: #000080;">=</span><span style="color: #000000;">&#40;</span><span style="color: #0000dd;">1</span>,<span style="color: #000080;">$</span><span style="color: #000000;">&#40;</span>ii<span style="color: #000000;">&#41;</span><span style="color: #000000;">&#41;</span> polyorder<span style="color: #000000;">:</span><span style="color: #000080;">=</span><span style="color: #0000dd;">3</span> coef<span style="color: #000000;">:</span><span style="color: #000080;">=</span>ds AdjRSq<span style="color: #000000;">:</span><span style="color: #000080;">=</span>MyR;
    <span style="color: #000080;">%</span>N <span style="color: #000080;">=</span> wks.<span style="color: #000080;">col</span><span style="color: #000080;">$</span><span style="color: #000000;">&#40;</span>ii<span style="color: #000000;">&#41;</span>.<span style="color: #000080;">name</span><span style="color: #000080;">$</span>;
    type <span style="color: #000080;">%</span>N\t<span style="color: #000080;">$</span><span style="color: #000000;">&#40;</span>ds<span style="color: #000000;">&#91;</span><span style="color: #0000dd;">1</span><span style="color: #000000;">&#93;</span>,S<span style="color: #000080;">*</span><span style="color: #0000dd;">6</span><span style="color: #000000;">&#41;</span>\t<span style="color: #000080;">$</span><span style="color: #000000;">&#40;</span>ds<span style="color: #000000;">&#91;</span><span style="color: #0000dd;">2</span><span style="color: #000000;">&#93;</span>,S<span style="color: #000080;">*</span><span style="color: #0000dd;">6</span><span style="color: #000000;">&#41;</span>\t<span style="color: #000080;">$</span><span style="color: #000000;">&#40;</span>ds<span style="color: #000000;">&#91;</span><span style="color: #0000dd;">3</span><span style="color: #000000;">&#93;</span>,S<span style="color: #000080;">*</span><span style="color: #0000dd;">6</span><span style="color: #000000;">&#41;</span>\t<span style="color: #000080;">$</span><span style="color: #000000;">&#40;</span>ds<span style="color: #000000;">&#91;</span><span style="color: #0000dd;">4</span><span style="color: #000000;">&#93;</span>,S<span style="color: #000080;">*</span><span style="color: #0000dd;">6</span><span style="color: #000000;">&#41;</span>\t<span style="color: #000080;">$</span><span style="color: #000000;">&#40;</span>MyR,S<span style="color: #000080;">*</span><span style="color: #0000dd;">6</span><span style="color: #000000;">&#41;</span>;
<span style="color: #000000;">&#125;</span>
separator <span style="color: #0000dd;">6</span>;
separator <span style="color: #0000dd;">6</span>;
<span style="color: #008000;">// Now loop through all four curves, fit and report</span>
loop<span style="color: #000000;">&#40;</span>ii,<span style="color: #0000dd;">2</span>,<span style="color: #0000dd;">5</span><span style="color: #000000;">&#41;</span> <span style="color: #000000;">&#123;</span>
    fitpoly iy<span style="color: #000000;">:</span><span style="color: #000080;">=</span><span style="color: #000000;">&#40;</span><span style="color: #0000dd;">1</span>,<span style="color: #000080;">$</span><span style="color: #000000;">&#40;</span>ii<span style="color: #000000;">&#41;</span><span style="color: #000000;">&#41;</span> polyorder<span style="color: #000000;">:</span><span style="color: #000080;">=</span><span style="color: #0000dd;">3</span> coef<span style="color: #000000;">:</span><span style="color: #000080;">=</span>ds fixint<span style="color: #000000;">:</span><span style="color: #000080;">=</span><span style="color: #0000dd;">1</span> intercept<span style="color: #000000;">:</span><span style="color: #000080;">=</span><span style="color: #0000dd;">0</span> AdjRSq<span style="color: #000000;">:</span><span style="color: #000080;">=</span>MyR;
    <span style="color: #000080;">%</span>N <span style="color: #000080;">=</span> wks.<span style="color: #000080;">col</span><span style="color: #000080;">$</span><span style="color: #000000;">&#40;</span>ii<span style="color: #000000;">&#41;</span>.<span style="color: #000080;">name</span><span style="color: #000080;">$</span>;
    type <span style="color: #000080;">%</span>N\t<span style="color: #000080;">$</span><span style="color: #000000;">&#40;</span>ds<span style="color: #000000;">&#91;</span><span style="color: #0000dd;">1</span><span style="color: #000000;">&#93;</span>,S<span style="color: #000080;">*</span><span style="color: #0000dd;">6</span><span style="color: #000000;">&#41;</span>\t<span style="color: #000080;">$</span><span style="color: #000000;">&#40;</span>ds<span style="color: #000000;">&#91;</span><span style="color: #0000dd;">2</span><span style="color: #000000;">&#93;</span>,S<span style="color: #000080;">*</span><span style="color: #0000dd;">6</span><span style="color: #000000;">&#41;</span>\t<span style="color: #000080;">$</span><span style="color: #000000;">&#40;</span>ds<span style="color: #000000;">&#91;</span><span style="color: #0000dd;">3</span><span style="color: #000000;">&#93;</span>,S<span style="color: #000080;">*</span><span style="color: #0000dd;">6</span><span style="color: #000000;">&#41;</span>\t<span style="color: #000080;">$</span><span style="color: #000000;">&#40;</span>ds<span style="color: #000000;">&#91;</span><span style="color: #0000dd;">4</span><span style="color: #000000;">&#93;</span>,S<span style="color: #000080;">*</span><span style="color: #0000dd;">6</span><span style="color: #000000;">&#41;</span>\t<span style="color: #000080;">$</span><span style="color: #000000;">&#40;</span>MyR,S<span style="color: #000080;">*</span><span style="color: #0000dd;">6</span><span style="color: #000000;">&#41;</span>;
<span style="color: #000000;">&#125;</span></pre>
<h2><a name="Algorithm"></a><span class="mw-headline">Algorithm</span></h2>
<p><b>Regression model:</b>
</p><p>For a given dataset (<i>xi</i> , <i>yi</i> ), <i>i</i> = 1,2,...<i>n</i>, where <i>X</i> is the independent variable and <i>Y</i> is the dependent variable, a polynomial regression fits data to a model of the following form:
</p>
<dl><dd><a  class="image"><img alt="FitPolynomial help English files image008.gif" src="../images/Fitpoly/FitPolynomial_help_English_files_image008.gif?v=948" width="263"  /></a></dd></dl>
<p>where <i>k</i> is the degree and, in Origin, it is a positive number that is less than 10. The error term <i><img src="../images/Fitpoly/math-92e4da341fe8f4cd46192f21b6ff3aa7.png?v=0" title="\epsilon" alt="\epsilon" class="tex"/></i> is assumed to be independent and normally distributed <i>N</i>(0, <i><img src="../images/Fitpoly/math-e82447b9e6f5407cb74c9bed7ddfe575.png?v=0" title="\sigma^2 " alt="\sigma^2 " class="tex"/></i>).
</p><p>To fit the model, assume that the residuals:
</p>
<dl><dd><a  class="image"><img alt="FitPolynomial help English files image010.gif" src="../images/Fitpoly/FitPolynomial_help_English_files_image010.gif?v=949" width="268"  /></a></dd></dl>
<p>Are normally distributed with the mean equal to 0 and the variance equal to <i><img src="../images/Fitpoly/math-e7b280f5341732e6e165c9706330b4cd.png?v=0" title="\sigma_i^2 " alt="\sigma_i^2 " class="tex"/></i>. Then the maximum likelihood estimates for the parameters <i><img src="../images/Fitpoly/math-b2b91e24b666373d478b4cd7cbe66060.png?v=0" title="\beta_i " alt="\beta_i " class="tex"/></i>can be obtained by minimizing the Chi-square, which is defined as:
</p><p>If the error is treated as weight, the Chi-square minimizing equation can be written as:
</p>
<dl><dd><a  class="image"><img alt="FitPolynomial help English files image012.gif" src="../images/Fitpoly/FitPolynomial_help_English_files_image012.gif?v=950" width="120"  /></a></dd></dl>
<p>and:
</p>
<dl><dd><a  class="image"><img alt="FitPolynomial help English files image002.gif" src="../images/Fitpoly/FitPolynomial_help_English_files_image002.gif?v=945" width="133"  /></a></dd></dl>
<p>where <i><img src="../images/Fitpoly/math-6ed64edbb67d44ddf47dd0a56b85c837.png?v=0" title="\sigma_i " alt="\sigma_i " class="tex"/></i>are the measurement errors. If they are unknown, they should all be set to 1.
</p><p><b>Coefficient estimation by matrix calculation:</b>
</p><p>The calculation of the estimated coefficients is a procedure of matrix calculation. First, we can rewrite the regression model in the matrix form
</p>
<dl><dd><a  class="image"><img alt="FitPolynomial help English files image015.gif" src="../images/Fitpoly/FitPolynomial_help_English_files_image015.gif?v=951" width="56"  /></a></dd></dl>
<p>where:
</p>
<dl><dd><a  class="image"><img alt="FitPolynomial help English files image017.gif" src="../images/Fitpoly/FitPolynomial_help_English_files_image017.gif?v=952" width="77"  /></a></dd></dl>
<p>The estimate of the vector <i>B</i> is the solution to the linear equations, and can be expressed as:
</p>
<dl><dd><a  class="image"><img alt="FitPolynomial help English files image019.gif" src="../images/Fitpoly/FitPolynomial_help_English_files_image019.gif?v=953" width="67"  /></a> <a  class="image"><img alt="FitPolynomial help English files image021.gif" src="../images/Fitpoly/FitPolynomial_help_English_files_image021.gif?v=954" width="200"  /></a> <a  class="image"><img alt="FitPolynomial help English files image023.gif" src="../images/Fitpoly/FitPolynomial_help_English_files_image023.gif?v=955" width="63"  /></a> <a  class="image"><img alt="FitPolynomial help English files image025.gif" src="../images/Fitpoly/FitPolynomial_help_English_files_image025.gif?v=956" width="61"  /></a></dd></dl>
<p>where <i><img src="../images/Fitpoly/math-c164e630313c7e71508c5c046f83c6f5.png?v=0" title="X&#39;" alt="X&#39;" class="tex"/></i>is the transpose of <i>X</i>.
</p>
<dl><dd><a  class="image"><img alt="FitPolynomial help English files image027.gif" src="../images/Fitpoly/FitPolynomial_help_English_files_image027.gif?v=957" width="168"  /></a></dd></dl>
<p><b>Inference in polynomial regression:</b>
</p><p>The ANOVA for the polynomial regression is summarized in the following table:
</p>
<table class="TableGrid" style="; border-spacing: 0px;background: #EFEFEF" border="1" width="80%">

<tr>
<td>
</td>
<td>
<center><b>df</b></center>
</td>
<td>
<center><b>Sum of Squares</b></center>
</td>
<td>
<center><b>Mean Square</b></center>
</td>
<td>
<center><b>F Value</b></center>
</td>
<td>
<center><b>Prob&gt; F</b></center>
</td></tr>
<tr>
<td>
<center><b>Model</b></center>
</td>
<td>
<center><i>k</i></center>
</td>
<td>
<center><i>SSreg</i> = <i>TSS</i> - <i>RSS</i></center>
</td>
<td>
<center><i>MSreg</i> = <i>SSreg</i> / <i>k</i></center>
</td>
<td>
<center><i>MSreg</i>/ <i>MSE</i></center>
</td>
<td>
<center><i>p-value</i></center>
</td></tr>
<tr>
<td>
<center><b>Error</b></center>
</td>
<td>
<center><i>n</i>* - <i>k</i></center>
</td>
<td>
<center><i>RSS</i></center>
</td>
<td>
<center><i>MSE</i> = <i>RSS</i> / (<i>n</i>*-<i>k</i>)</center>
</td>
<td>
</td>
<td>
</td></tr>
<tr>
<td>
<center><b>Total</b></center>
</td>
<td>
<center><i>n</i>*</center>
</td>
<td>
<center><i>TSS</i></center>
</td>
<td>
</td>
<td>
</td>
<td>
</td></tr></table>
<p><br />
(Note: If intercept is included in the model, <i>n</i>*=<i>n</i>-1. Otherwise, <i>n</i>*=<i>n</i> and the total sum of square is uncorrected.)
</p><p>Where the total sum of square, <i>TSS</i>, is
</p><p><a  class="image"><img alt="FitPolynomial help English files image029.gif" src="../images/Fitpoly/FitPolynomial_help_English_files_image029.gif?v=958" width="121"  /></a> (for corrected model)
</p><p><a  class="image"><img alt="FitPolynomial help English files image031.gif" src="../images/Fitpoly/FitPolynomial_help_English_files_image031.gif?v=959" width="81"  /></a> (for uncorrected model)
</p><p>And the residual sum of square (<i>RSS</i>) or sum of square error (<i>SSE</i>), which is actually the sum of the squares of the vertical deviations from each data point to the fitted line. It can be computed as:
</p>
<dl><dd><a  class="image"><img alt="FitPolynomial help English files image033.gif" src="../images/Fitpoly/FitPolynomial_help_English_files_image033.gif?v=960" width="189"  /></a></dd></dl>
<p>The result of the <i>F</i>-test is presented in the ANOVA table. The null hypothesis of the <i>F</i> test is that all of the partial coefficients are equal to zero, i.e.
</p>
<center><i><img src="../images/Fitpoly/math-e65765bedcabe42c66ec93228769e82a.png?v=0" title="H_0" alt="H_0" class="tex"/></i>: <i><img src="../images/Fitpoly/math-5160c2af0db1de4608e7c48fc9d53421.png?v=0" title="\beta_0 " alt="\beta_0 " class="tex"/></i> = <i><img src="../images/Fitpoly/math-92a4d79db86f5db78d6e0e3a945a0332.png?v=0" title="\beta_1 " alt="\beta_1 " class="tex"/></i> = <i><img src="../images/Fitpoly/math-053d340680b3860e73cd84bd51509313.png?v=0" title="\beta_2 " alt="\beta_2 " class="tex"/></i> = ... = <img src="../images/Fitpoly/math-1f03c43ad8cd837ab3fa6ac9c7054589.png?v=0" title="\beta_k " alt="\beta_k " class="tex"/><i>= 0</center></i>
<p>Thus, the alternative hypothesis is:
</p>
<center>'<i><img src="../images/Fitpoly/math-3aa114ccf60c1b8352801a6d33bcbdee.png?v=0" title="H_\alpha" alt="H_\alpha" class="tex"/>': </i>At least one <img src="../images/Fitpoly/math-2c86c1e431d120d165fdab80f8ba7282.png?v=0" title="\beta_j \ne " alt="\beta_j \ne " class="tex"/><i>0</i></center>
<p>With the computed <i>F</i>-value, we can decide whether or not to reject the null hypothesis. Usually, for a given confidence level <i><img src="../images/Fitpoly/math-7b7f9dbfea05c83784f8b85149852f08.png?v=0" title="\alpha" alt="\alpha" class="tex"/></i>, we can reject <i><img src="../images/Fitpoly/math-e65765bedcabe42c66ec93228769e82a.png?v=0" title="H_0" alt="H_0" class="tex"/></i> when <i>F</i> &gt; <i><img src="../images/Fitpoly/math-61ee10cfeb9c8fea41d940edebb82588.png?v=0" title="F_\alpha" alt="F_\alpha" class="tex"/></i>, or the significance of <i>F</i> (the computed <i>p</i>-value) is less than <i><img src="../images/Fitpoly/math-7b7f9dbfea05c83784f8b85149852f08.png?v=0" title="\alpha" alt="\alpha" class="tex"/></i>.
</p><p>For the inference, we need to know the standard error of partial slopes, which may be computed as:
</p>
<center><a  class="image"><img alt="FitPolynomial help English files image035.gif" src="../images/Fitpoly/FitPolynomial_help_English_files_image035.gif?v=961" width="85"  /></a></center>
<p>where <img src="../images/Fitpoly/math-94b29f880f39828a42071d3618da55cc.png?v=0" title="c_{jj}" alt="c_{jj}" class="tex"/> is the <i>j</i>th diagonal element of (<i>X'X</i>)<sup>-1</sup>. And <img src="../images/Fitpoly/math-2d61536a1699ed55d34274ab6fa3c0e6.png?v=0" title="s_\epsilon" alt="s_\epsilon" class="tex"/> is the residual standard deviation (also called td dev, tandard error of estimate, or oot MSE) computed as:
</p>
<dl><dd><a  class="image"><img alt="FitPolynomial help English files image037.gif" src="../images/Fitpoly/FitPolynomial_help_English_files_image037.gif?v=962" width="155"  /></a></dd></dl>
<p>If the regression assumptions hold, we can perform the <i>t</i>-tests for the regression coefficients with the null hypotheses and the alternative hypotheses:
</p>
<center><i><img src="../images/Fitpoly/math-e65765bedcabe42c66ec93228769e82a.png?v=0" title="H_0" alt="H_0" class="tex"/></i>: <i><img src="../images/Fitpoly/math-35e985d710477a356d19570d41e41111.png?v=0" title="\beta_j" alt="\beta_j" class="tex"/></i> = 0,</center>
<center><i><img src="../images/Fitpoly/math-3aa114ccf60c1b8352801a6d33bcbdee.png?v=0" title="H_\alpha" alt="H_\alpha" class="tex"/></i>: <i><img src="../images/Fitpoly/math-ae9f72a9d7a511e1ca7bf301dcbd9b7d.png?v=0" title="\beta_j \ne" alt="\beta_j \ne" class="tex"/></i> 0,</center>
<p>The <i>t</i>-value can be computed as:
</p>
<center><a  class="image"><img alt="FitPolynomial help English files image039.gif" src="../images/Fitpoly/FitPolynomial_help_English_files_image039.gif?v=963" width="67"  /></a></center>
<p>With the <i>t</i>-values, we can decide whether or not to reject the null hypotheses. Usually, for a given confidence level <i><img src="../images/Fitpoly/math-7b7f9dbfea05c83784f8b85149852f08.png?v=0" title="\alpha" alt="\alpha" class="tex"/></i>, we can reject <i><img src="../images/Fitpoly/math-e65765bedcabe42c66ec93228769e82a.png?v=0" title="H_0" alt="H_0" class="tex"/></i> when |<i>t</i>| &gt; <img src="../images/Fitpoly/math-9062e1cfc8edd113cb771123f71901e3.png?v=0" title="t{\alpha/2}" alt="t{\alpha/2}" class="tex"/>, or when the significant <i>p</i>-value less than <i><img src="../images/Fitpoly/math-7b7f9dbfea05c83784f8b85149852f08.png?v=0" title="\alpha" alt="\alpha" class="tex"/></i>.
</p><p><b>Confidence and Prediction interval:</b>
</p><p>For a particular value <i>xp</i>, the 100(1-<i><img src="../images/Fitpoly/math-7b7f9dbfea05c83784f8b85149852f08.png?v=0" title="\alpha" alt="\alpha" class="tex"/></i>)% confidence interval for the mean value of <i>y</i> at <i>x</i>=<i>xp</i> is:
</p>
<dl><dd><a  class="image"><img alt="FitPolynomial help English files image041.gif" src="../images/Fitpoly/FitPolynomial_help_English_files_image041.gif?v=964" width="191"  /></a></dd></dl>
<p>And the 100(1-<i><img src="../images/Fitpoly/math-7b7f9dbfea05c83784f8b85149852f08.png?v=0" title="\alpha" alt="\alpha" class="tex"/></i>)% prediction interval for the mean value of <i>y</i> at <i>x</i>=<i>xp</i> is:
</p>
<dl><dd><a  class="image"><img alt="FitPolynomial help English files image043.gif" src="../images/Fitpoly/FitPolynomial_help_English_files_image043.gif?v=965" width="211"  /></a></dd></dl>
<p><b>Coefficient of Determination:</b>
</p><p>The goodness of fit can be evaluated by coefficient of determination, <i>R</i><sup>2</sup>, which is given by:
</p>
<dl><dd><a  class="image"><img alt="FitPolynomial help English files image045.gif" src="../images/Fitpoly/FitPolynomial_help_English_files_image045.gif?v=966" width="236"  /></a></dd></dl>
<p>The adjusted <i>R</i><sup>2</sup> is used to adjust the <i>R</i><sup>2</sup> value for the degree of freedom. It can be computed as:
</p>
<dl><dd><a  class="image"><img alt="FitPolynomial help English files image047.gif" src="../images/Fitpoly/FitPolynomial_help_English_files_image047.gif?v=967" width="135"  /></a></dd></dl>
<p>Then we can compute the <i>R</i>-value, which is simply the square root of <i>R</i><sup>2</sup>:
</p>
<center><a  class="image"><img alt="FitPolynomial help English files image049.gif" src="../images/Fitpoly/FitPolynomial_help_English_files_image049.gif?v=968" width="64"  /></a></center>
<p><b>Covariance and Correlation matrix:</b>
</p><p>The covariance matrix of the polynomial regression can be calculated as:
</p>
<dl><dd><a  class="image"><img alt="FitPolynomial help English files image051.gif" src="../images/Fitpoly/FitPolynomial_help_English_files_image051.gif?v=969" width="173"  /></a></dd></dl>
<p>And the correlation between any two parameters is:
</p>
<dl><dd><a  class="image"><img alt="FitPolynomial help English files image053.gif" src="../images/Fitpoly/FitPolynomial_help_English_files_image053.gif?v=970" width="261"  /></a></dd></dl>
<p><br />
</p>
<h2><a name="References"></a><span class="mw-headline">References</span></h2>
<p>1.  Bruce Bowerman, Richard T. O'Connell. 1997. <i>Applied Statistics: Improving Business Processes</i>. The McGraw-Hill Companies, Inc.
</p><p>2.  Sanford Weisberg. 2005. <i>Applied Linear Regression</i>, 2<sup>nd</sup> ed. John Wiley &amp; Son, Inc., Hoboken, New Jersey.
</p><p>3.  William H. Press.; et al. 2002. <i>Numerical Recipes in C++</i>, 2<sup>nd</sup> ed. Cambridge University Press: New York.
</p>
<h2><a name="Related_X-Functions"></a><span class="mw-headline">Related X-Functions</span></h2>
<p><a href="../../XFunction/X-Function/FitLR.html" title="X-Function:FitLR">fitLR</a>, <a href="../../XFunction/X-Function/Nlfit.html" title="X-Function:Nlfit">nlfit</a>
</p>
<hr class='keywordshr'><p><span class='keywords'>Keywords:</span><span class='keywordsInput'>curve fitting</span></p>






