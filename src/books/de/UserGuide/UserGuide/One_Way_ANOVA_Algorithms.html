<h1 class="firstHeading">Algorithmen der einfachen ANOVA</h1>

  <p>&#160;</p>

  <table id="toc" class="toc" summary="Contents">
    <tr>
      <td>
        <div id="toctitle">
          <h2>Contents</h2>
        </div>

        <ul>
          <li class="toclevel-1"><a href="#Theory_of_One-Way_ANOVA"><span class="tocnumber">1</span> <span class="toctext">Theorie der einfachen ANOVA</span></a></li>

          <li class="toclevel-1"><a href="#Homogeneity_of_Variance"><span class="tocnumber">2</span> <span class="toctext">Homogenität der Varianzen</span></a></li>

          <li class="toclevel-1"><a href="#Multiple_Means_Comparisons"><span class="tocnumber">3</span> <span class="toctext">Mehrfache Mittelwertevergleiche</span></a></li>

          <li class="toclevel-1"><a href="#Power_Analysis"><span class="tocnumber">4</span> <span class="toctext">Trennschärfeanalyse</span></a></li>
        </ul>
      </td>
    </tr>
  </table><a name="Theory_of_One-Way_ANOVA"></a>

  <h2><span class="mw-headline">Theorie der einfachen ANOVA</span></h2>

  <p>Angenommen wir haben in k Faktorstufen Antwortdaten gemessen, wobei <img class="tex" alt="y_{ij}\,\!" src="../images/math/1/2/1/1211ecdef426186811490fd85315ed33.png"> den Wert der <i>i</i>-ten Beobachtung (<i>i</i> = 1, 2, ...<span class="texhtml"><i>n</i><sub><i>j</i></sub></span>) der <i>j</i>-ten Faktorstufe (<i>j</i> = 1, 2, ..., k) repräsentiert. Wir könnten das Modell der einfachen ANOVA wie folgt schreiben:</p>

  <p><img class="tex" alt="y_{ij}=u+t_j+\varepsilon _{ij}" src="../images/math/7/4/3/7439b0984cc48af44a50c041aa0b9fd6.png">,<i>j</i> = 1, 2, ..., <i>k</i>; <i>i</i> = 1, 2, ...<span class="texhtml"><i>n</i><sub><i>j</i></sub></span></p>

  <p>Da die ANOVA testet, ob der Mittelwert von zwei oder mehreren Grundgesamtheiten (Stufen) gleich ist. Daher ist die Nullhypothese, dass die Mittelwerte der verschiedenen Grundgesamtheiten gleich sind, und die Alternativhypothese lautet, dass mindestens ein Mittelwert der Grundgesamtheiten anders als die anderen Mittelwerte ist. Mathematisch wird dies wie folgt ausgedrückt:</p>

  <p>H0:<img class="tex" alt="\mu =\mu _1=\mu _2=\cdots =\mu _k" src="../images/math/7/9/8/798b01fca5434448613709d3ec9fceca.png"></p>

  <p>H1:<img class="tex" alt="\mu _p\neq \mu _q" src="../images/math/b/e/5/be5e613f09abe6c3f848f53ca2a3eb22.png"> for some <i>p</i> and <i>q</i>, <img class="tex" alt="1 \leq p" src="../images/math/c/2/1/c21e1d6694ba6077c98b36bd99be8771.png">, <img class="tex" alt="q \geq k" src="../images/math/e/4/d/e4d07a1acc3ad43eccc97ec9ff802695.png">.</p>

  <p>wobei <img class="tex" alt="\mu _i\,\!" src="../images/math/1/3/0/13048276bbb31aae43ac0a3dc5c0b5f1.png"> der j-te Stichprobenmittelwert ist. Um die Hypothese zu testen, muss die gesamte Stichprobenvariation in die Variation zwischen Gruppen und die Variation innerhalb der Gruppen geteilt werden. Anschließend wird der F-Test verwendet, um zu testen, ob diese beiden Variationen unterschiedlich sind.</p>

  <p>Algebraisch können wir das entsprechende Mittel der Quadrate jeden Abschnitts verwenden, um die Streuung zu schätzen:</p>

  <p><img class="tex" alt="\sum_{j=1}^k\sum_{i=1}^{n_1}(y_{ij}-\bar y)^2=\sum_{j=1}^kn_j(\bar y_j-\bar y)^2+\sum_{j=1}^k\sum_{i=1}^{n_1}(y_{ij}-\bar y_j)^2" src="../images/math/d/9/f/d9f1eb819f70ce9bc04418271c33a6b9.png"></p>

  <p>wobei der linke Term die "Totale Summe der Quadrate" und der zweite Term die "Summe der Quadrate der Behandlungen" ist, welche die Streuung zwischen Gruppen repräsentiert. Der dritte Term ist die "Summe der Quadrate der Fehler", welche die Streuung innerhalb von Gruppen repräsentiert. Die Gleichung wird gewöhnlich wie folgt gekürzt:</p>

  <p><img class="tex" alt="SS_{Total}=SS_{Treatment}+SS_{Error}\,\!" src="../images/math/5/0/d/50d76fab615ac14ea906ed82839a767a.png"></p>

  <p>Wenn <img class="tex" alt="H_0\,\!" src="../images/math/4/9/8/498660a51664435e5460f06ce348e36a.png"> wahr ist, werden die Musterdaten der <i>k</i>-Level normal und unabhängig verteilt, wobei der Mittelwert <img class="tex" alt="\mu\,\!" src="../images/math/7/4/b/74b8eddf4b37de80c7c8eed1b64e46fc.png"> und die Varianz <img class="tex" alt="\sigma ^2\,\!" src="../images/math/8/5/0/850707adf2adeba94c688b9c1a02494c.png"> ist. Daher folgt die Statistik</p>

  <p><img class="tex" alt="F=\frac{MS_{Treatment}}{MS_{Error}}=\frac{ss_{Treatment}/(k-1)}{ss_{Error}/(n-k)}" src="../images/math/0/6/4/06496cae87b19bed9d99fe76c6fb9c67.png"></p>

  <p>einer <i>F</i> -Verteilung <img class="tex" alt="F_{(k-1, n-k)}\,\!" src="../images/math/0/9/8/098f8244554ec5c28d1bd828cf2eed37.png"> , wobei <span class="texhtml"><i>M</i>S<sub><i>T</i><i>r</i><i>e</i><i>a</i><i>t</i><i>m</i><i>e</i><i>n</i><i>t</i></sub></span> das Mittel der Quadrate für Treatments und <span class="texhtml"><i>M</i><i>S</i><sub><i>E</i><i>r</i><i>r</i><i>o</i><i>r</i></sub></span> das Mittel der Quadrate für Fehler ist. Beide werden durch das Teilen der Summe der Quadrate durch die entsprechenden Freiheitsgrade gebildet. Bei einem gegebenen bestimmten Signifikanzniveau <img class="tex" alt="\alpha\,\!" src="../images/math/4/b/c/4bc6c42bbabe567d1f2516326e52b775.png"> sollte die Nullhypothese zurückgewiesen werden, wenn die <i>F-</i>Statistik den kritischen Wert <img class="tex" alt="F_{(k-1,n-k,\alpha)}\,\!" src="../images/math/1/0/9/1097483c56b59bdc76a2383c8ce72cd3.png">, d.h. den Tabellenwert der <i>F</i>-Verteilung mit <i>k-1</i> und <i>n-k</i> Freiheitsgraden bei Niveau <img class="tex" alt="\alpha\,\!" src="../images/math/4/b/c/4bc6c42bbabe567d1f2516326e52b775.png">, überschreitet oder der gefolgte <i>P</i>-Wert ist geringer als das Signifikanzniveau.</p>

  <p>Im Allgemeinen werden die Ergebnisse einer Varianzanalyse in einer ANOVA-Tabelle präsentiert:</p>

  <table class="simple">
    <tr>
      <th>Quelle der Variation</th>

      <th>Freiheitsgrade (DF)</th>

      <th>Summe der Quadrate (SS)</th>

      <th>Mittel der Quadrate (MS)</th>

      <th><i>F</i> -Wert</th>

      <th><i>Wahrsch. &gt;</i> F</th>
    </tr>

    <tr>
      <th>Modell (Faktor)</th>

      <td><i>k</i>-1</td>

      <td><span class="texhtml"><i>S</i><i>S</i><sub><i>T</i><i>r</i><i>e</i><i>a</i><i>t</i><i>m</i><i>e</i></sub></span></td>

      <td><span class="texhtml"><i>M</i>S</span><sub><i>T</i><i>r</i><i>e</i><i>a</i><i>t</i><i>m</i><i>e</i><i>n</i><i>t</i></sub></td>

      <td><span class="texhtml"><i>M</i><i>S</i><sub><i>T</i><i>r</i><i>e</i><i>a</i><i>t</i><i>m</i><i>e</i><i>n</i><i>t</i></sub></span> / <span class="texhtml"><i>M</i><i>S</i><sub><i>E</i><i>r</i><i>r</i><i>o</i><i>r</i></sub></span></td>

      <td><img class="tex" alt="P\{F\geq F_{(k-1,n-k,\alpha )}\}" src="../images/math/9/c/2/9c2c55b76eaba5b6b5d4a46721b5eaab.png"></td>
    </tr>

    <tr>
      <th>Fehler</th>

      <td><i>n-k</i></td>

      <td><span class="texhtml"><i>S</i>S</span><sub><i>F</i><i>e</i><i>h</i><i>l</i><i>er</i></sub></td>

      <td><span class="texhtml"><i>M</i><i>S</i><sub><i>E</i><i>r</i><i>r</i><i>o</i><i>r</i></sub></span></td>

      <td></td>

      <td></td>
    </tr>

    <tr>
      <th>Gesamtsumme</th>

      <td><i>n</i>-1</td>

      <td></td>

      <td></td>

      <td></td>

      <td></td>
    </tr>
  </table><a name="Homogeneity_of_Variance"></a>

  <h2><span class="mw-headline">Homogenität der Varianzen</span></h2>

  <p>In der Varianzanalyse wird angenommen, dass verschiedene Stichproben gleiche Varianzen haben. Dies wird gewöhnlich Homogenität der Varianzen genannt. Der Levene-Test und der Brown-Forsythe-Test können zum Bestätigen der Annahme verwendet werden. Angenommen wir haben <i>k</i> Stichproben von Antwortdaten, wobei <img class="tex" alt="y_{ij}\,\!" src="../images/math/1/2/1/1211ecdef426186811490fd85315ed33.png"> den Wert der i-ten Beobachtung (i = 1, 2, ...<span class="texhtml"><i>n</i><sub><i>j</i></sub></span>) der <i>j</i>-ten Faktorstufe (<i>j</i> = 1, 2, ..., <i>k</i>) repräsentiert. Die Hypothesen der beiden Tests (Levene und Brown-Forsythe) können wie folgt ausgedrückt werden:</p>

  <p><span class="texhtml"><i>H</i><sub>0</sub></span>:<img class="tex" alt="\sigma _1=\sigma _2=\cdots =\sigma _k" src="../images/math/f/4/d/f4d9aa94797471b6b26b89540ad52083.png"></p>

  <p><span class="texhtml"><i>H</i>1</span><sub>:<img class="tex" alt="\sigma _p\neq \sigma _q" src="../images/math/9/a/b/9abda7a45c0df2024f0f2944b31703a9.png"></sub> , für mindestens ein Paar (<i>p</i>, <i>q</i>), <img class="tex" alt="1\leq p,q\leq k" src="../images/math/f/3/b/f3befe30a4a0d18509558e6012408028.png"></p>

  <p>Definiert <img class="tex" alt="Z_{ij}\,\!" src="../images/math/6/2/d/62d6adc543028c95813c4e3f7c4cceed.png"> als die folgenden drei Definitionen bezüglich verschiedener Tests,</p>

  <ol>
    <li>Absoluter Levene-Test:<img class="tex" alt="Z_{ij}=|y_{ij}-\bar y_j|" src="../images/math/1/c/e/1ce8b5344304fda3de5168c609deadc2.png"></li>

    <li>Quadratischer Levene-Test:<img class="tex" alt="Z_{ij}^2=(y_{ij}-\bar y_j)^2" src="../images/math/8/3/8/838e3d8ab4064769fbbde32693e6eac4.png"></li>

    <li>Brown-Forsythe-Test:<img class="tex" alt="Z_{ij}=|y_{ij}-m_j|\,\!" src="../images/math/6/b/7/6b7bafcb75a6ad034cb4a29fba2a369f.png"></li>
  </ol>

  <p>Wenn <span class="texhtml"><i>H</i><sub>0</sub></span> gilt, folgt die Teststatistik</p>

  <p><img class="tex" alt="F=\frac{\sum_{j=1}^kn_j(\bar Z_j-\bar Z)^2/(k-1)}{\sum_{j=1}^k\sum_{i=1}^{n_1}(Z_{ij}-\bar Z_j)^2/(n-k)}" src="../images/math/7/2/6/72622068fa64f958c205b4e275c33152.png"></p>

  <p>(nahezu) einer <i>F</i>-Verteilung <img class="tex" alt="F_{(k-1, n-k)}\,\!" src="../images/math/0/9/8/098f8244554ec5c28d1bd828cf2eed37.png">, wobei <img class="tex" alt="\overline{Z_j}" src="../images/math/5/4/8/548d6d6ccfaa345302efd90822a203bf.png"> und <img class="tex" alt="\overline{Z}" src="../images/math/2/5/f/25fc1fa229937b5b7b3bf847fa8932b6.png"> der Gruppenmittelwert bzw. der Gesamtmittelwert des <img class="tex" alt="Z_{ij}\,\!" src="../images/math/6/2/d/62d6adc543028c95813c4e3f7c4cceed.png"> ist.</p><a name="Multiple_Means_Comparisons"></a>

  <h2><span class="mw-headline">Mehrfache Mittelwertevergleiche</span></h2>

  <p>Nimmt man an, dass durch eine ANOVA festgestellt wurde, dass mindestens einer der Mittelwerte der Grundgesamtheiten statistisch unterschiedlich ist, so vergleicht ein Mittelwertvergleich alle möglichen Paare von Faktorstufenmittelwerten, um herausfinden, welcher Mittelwert (oder welche Mittelwerte) signifikant verschieden ist (sind). Es gibt verschiedene Methoden des Mittelwertvergleichs in Origin. Wir verwenden die <a href="http://www.originlab.com/pdfs/nagcl09/manual/pdf/g04/g04dbc.pdf" class="external text" title="http://www.originlab.com/pdfs/nagcl09/manual/pdf/g04/g04dbc.pdf" rel="nofollow"><b>NAG-Funktion nag_anova_confid_interval (g04dbc)</b></a>, um Mittelwertvergleiche durchzuführen.</p>

  <p>In Origin sind zwei Typen des mehrfachen Mittelwertvergleichs enthalten:</p>

  <ol>
    <li>Einzelschrittmethode Sie erstellt simultane Konfidenzintervalle, um zu zeigen, wie sich die Mittelwerte unterscheiden. Dazu gehören Tukey-Kramer, Bonferroni, Dunn-Sidak, Fisher’s LSD und Scheffé).</li>

    <li>Schrittweise Methode Führt nacheinander die Hypothesentests aus. Dazu gehören Holm-Bonferroni- und Holm-Sidak-Test.</li>
  </ol>

  <p>Weitere Informationen finden Sie in der NAG-Hilfe.</p><a name="Power_Analysis"></a>

  <h2><span class="mw-headline">Analyse der Trennschärfe</span></h2>

  <p>Die Analyse der Trennschärfe berechnet die Ist-Trennschärfe für die Stichprobendaten als auch die hypothetische Trennschärfe, falls zusätzliche Stichprobenumfänge angegeben sind.</p>

  <p>Die Trennschärfe einer einfachen Varianzanalyse ist ein Maß für ihre Sensibilität. Die Trennschärfe ist die Wahrscheinlichkeit, dass die einfache ANOVA Unterschiede in den Stichprobenmittelwerten aufdeckt, wenn tatsächlich Unterschiede existieren. Drückt man dies mit den Begriffen der Null- und Alternativhypothese aus, so ist die Trennschärfe die Wahrscheinlichkeit dafür, dass die Teststatistik <i>F</i> stark genug ist, um die Nullhypothese zu verwerfen, wenn sie tatsächlich verworfen werden sollte (d.h. die Nullhypothese ist nicht wahr).</p>

  <p>Die Trennschärfe wird durch folgende Gleichung definiert:</p>

  <p><img class="tex" alt="power=1-probf(f,dfa,dfe,nc)\,\!" src="../images/math/9/9/4/994e2581ef30349da587e03faa17ce2b.png"></p>

  <p><i>wobei</i> <i>f</i> die Abweichung der nichtzentralen <i>F</i>-Verteilung ist mit <i>dfa</i> und dfe als Modell- bzw. Fehler-Freiheitsgrade. Und <i>nc</i> = <i>SST</i>/<i>MSE</i>, wobei SST die Summe der Quadrate des Modells und MSE der quadratische Mittelwert der Fehler ist. Der Wert von <i>probf</i>() wird durch die NAG-Funktion <a href="http://www.originlab.com/pdfs/nagcl09/manual/pdf/g01/g01gdc.pdf" class="external text" title="http://www.originlab.com/pdfs/nagcl09/manual/pdf/g01/g01gdc.pdf" rel="nofollow"><b>nag_prob_non_central_f_dist (g01gdc)</b></a> ermittelt. Beachten Sie bitte die NAG-Dokumentation für weitere Hintergrundinformationen.</p>

  <p>Die obige Beschreibung ist eine kurze Übersicht über den Algorithmus der einfachen ANOVA. Weitere Informationen über die Einzelheiten der mathematischen Deduktion finden Sie im entsprechenden Teil des Anwenderhandbuchs und der NAG-Dokumentation.</p>

  <p>&#160;</p>
