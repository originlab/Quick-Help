<h1 class="firstHeading">Algorithmus (Hauptkomponentenanalyse)</h1>

  <table id="toc" class="toc" summary="Contents">
    <tr>
      <td>
        <div id="toctitle">
          <h2>Inhalt</h2>
        </div>

        <ul>
          <li class="toclevel-1">
            <a href="#Listwise_Exclusion_of_Missing_Values"><span class="tocnumber">1</span> <span class="toctext">Listenweiser Ausschluss von fehlenden Werten</span></a>

            <ul>
              <li class="toclevel-2"><a href="#Matrix_Type_for_Analysis"><span class="tocnumber">1.1</span> <span class="toctext">Matrixtyp für Analyse</span></a></li>

              <li class="toclevel-2"><a href="#Quantities_to_Compute"><span class="tocnumber">1.2</span> <span class="toctext">Zu berechnende Eigenschaften</span></a></li>
            </ul>
          </li>

          <li class="toclevel-1"><a href="#Pairwise_Exclusion_of_Missing_Values"><span class="tocnumber">2</span> <span class="toctext">Paarweiser Ausschluss von fehlenden Werten</span></a></li>

          <li class="toclevel-1"><a href="#Bartlett.27s_Test"><span class="tocnumber">3</span> <span class="toctext">Bartletts Test</span></a></li>
        </ul>
      </td>
    </tr>
  </table>

  <p><br>
  Die <b>Hauptkomponentenanalyse</b> untersucht die Beziehungen zwischen den Variablen. Sie kann verwendet werden, um die Anzahl der Variablen in Regression, Clustering usw. zu reduzieren.</p>

  <p>Jede Hauptkomponente in der <b>Hauptkomponentenanalyse</b> ist die lineare Kombination der Variable und ergibt eine maximierte Varianz. <i>X</i> sein eine Matrix für <i>n</i> Beobachtungen nach <i>p</i> Variablen, und die Kovarianzmatrix sei <i>S</i>. Für eine lineare Kombination der Variablen</p>

  <dl>
    <dd><img class="tex" alt="z_1=\sum_{i=1}^p a_{1i}x_i" src="../images/math/c/5/c/c5cf81352f8e1f9e1c65c93d7e2de749.png"></dd>
  </dl>

  <p>, wobei <img class="tex" alt="x_i\ " src="../images/math/0/4/2/0424ddf948e53cc231b908a0c1031a04.png"> die <i>i</i>-te Variable ist, sind <img class="tex" alt="a_{1i} \ i=1,2,...,p" src="../images/math/d/3/d/d3d2aab487453b0c5ecd2b0381e83fac.png"> die linearen Kombinationskoeffizienten für <img class="tex" alt="z_1\ " src="../images/math/9/6/3/963da76387c1a28274287fa241150797.png">. Sie können die durch einen Spaltenvektor <img class="tex" alt="a_1\ " src="../images/math/d/0/b/d0b9e9cd701348bf9fae627dad5c030b.png"> gekennzeichnet und durch <img class="tex" alt="a_1^Ta_1=1" src="../images/math/d/f/3/df384a1f9efde8ad7ee07f06f3f5d77a.png"> normiert werden. Die Varianz von <img class="tex" alt="z_1\ " src="../images/math/9/6/3/963da76387c1a28274287fa241150797.png"> ist <img class="tex" alt="a_1^TSa_1" src="../images/math/b/b/f/bbf0b6e346c8589ea92d4545a74c51b3.png">.</p>

  <p>Der Vektor <img class="tex" alt="a_1\ " src="../images/math/d/0/b/d0b9e9cd701348bf9fae627dad5c030b.png"> wird durch Maximieren der Varianz gefunden. Und <img class="tex" alt="z_1\ " src="../images/math/9/6/3/963da76387c1a28274287fa241150797.png"> wird als erste Hauptkomponente bezeichnet. Die zweite Hauptkomponente kann auf die gleiche Weise durch Maximieren gefunden werden:</p>

  <dl>
    <dd><img class="tex" alt="a_2^TSa_2" src="../images/math/9/a/b/9ab8d85088d8bfe970b2dca7c4910a9f.png"> unterliegt den Nebenbedingungen <img class="tex" alt="a_2^Ta_2=1" src="../images/math/f/b/2/fb26d098a6069738689a4c030bbe7fad.png"> und <img class="tex" alt="a_2^Ta_1=0" src="../images/math/a/3/6/a363b4abea250cf1db804fc7009f15be.png"></dd>
  </dl>

  <p>Es ergibt die zweite Hauptkomponente, die wie die erste orthogonal ist. Die verbleibenden Hauptkomponenten können auf ähnliche Weise abgeleitet werden. Tatsächlich können Koeffizienten <img class="tex" alt="a_1, a_2, ..., a_p\ " src="../images/math/2/c/7/2c734e952c32401afe917e1a8c45322a.png"> aus den Eigenvektoren der Matrix <i>S</i> berechnet werden. Origin verwendet verschiedene Methoden je nach der Art und Weise, wie fehlende Werte ausgeschlossen werden.</p><a name="Listwise_Exclusion_of_Missing_Values"></a>

  <h2><span class="mw-headline">Listenweiser Ausschluss von fehlenden Werten</span></h2>

  <p>Eine Beobachtung, die einen oder mehrere fehlende Werte enthält, wird aus der Analyse ausgeschlossen. Eine Matrix <img class="tex" alt="X_s\ " src="../images/math/e/e/a/eeaf9fc0da2fbf0690055be36ec7fe36.png"> für <b>SVD</b> kann von <i>X</i> abgeleitet werden, abhängig von dem Matrixtyp für die Analyse.</p><a name="Matrix_Type_for_Analysis"></a>

  <h3><span class="mw-headline">Matrixtyp für Analyse</span></h3>

  <ul>
    <li>Kovarianzmatrix</li>
  </ul>

  <dl>
    <dd>
      <dl>
        <dd><img class="tex" alt="X_s\ " src="../images/math/e/e/a/eeaf9fc0da2fbf0690055be36ec7fe36.png"> sei die Matrix <i>X</i>, bei der von jeder Variable der Mittelwert jeder Spalte subtrahiert wird und jede Spalte nach <img class="tex" alt="\frac{1}{\sqrt{n-1}}" src="../images/math/f/2/3/f23c7046fa5f61ce1c3ba75281fd4e2b.png"> skaliert wird.</dd>
      </dl>
    </dd>
  </dl>

  <ul>
    <li>Korrelationsmatrix</li>
  </ul>

  <dl>
    <dd>
      <dl>
        <dd><img class="tex" alt="X_s\ " src="../images/math/e/e/a/eeaf9fc0da2fbf0690055be36ec7fe36.png"> sei die Matrix <i>X</i>, bei der der Mittelwert jeder Spalte von jeder Variable subtrahiert wird und jede Spalte durch <img class="tex" alt="\frac{1}{\sqrt{n-1}\sigma_i}" src="../images/math/1/9/c/19c9bc5a34f797f2cb3c75f03e4dea5b.png"> skaliert wird, wobei <img class="tex" alt="\sigma_i\ " src="../images/math/4/2/d/42d189bd8ec8e51209350c271a47ba20.png"> die Standardabweichung der <i>i</i>-ten Variable ist.</dd>
      </dl>
    </dd>
  </dl><a name="Quantities_to_Compute"></a>

  <h3><span class="mw-headline">Zu berechnende Eigenschaften</span></h3>

  <p><b>SVD</b> wird durchgeführt für <img class="tex" alt="X_s\ " src="../images/math/e/e/a/eeaf9fc0da2fbf0690055be36ec7fe36.png">.</p>

  <dl>
    <dd><img class="tex" alt="X_s=V\Lambda P^T\ " src="../images/math/1/4/0/140590108cbb5e7d6b1eee00bc05f345.png"></dd>
  </dl>

  <p>wobei <i>V</i> eine <i>n</i> x <i>p-</i>Matrix mit <img class="tex" alt="V^TV=I\ " src="../images/math/f/c/f/fcf09ce3092c668f7968c7780399804e.png">, <i>P</i> eine <i>p</i> x <i>p</i>-Matrix und eine diagonale Matrix mit diagonalen Elementen <img class="tex" alt="s_i \ i=1, 2, ..., p" src="../images/math/3/6/e/36e78f43cc63f63f0443448b9993a2f7.png"> ist.</p>

  <ul>
    <li>Eigenwerte</li>
  </ul>

  <dl>
    <dd>
      <dl>
        <dd><img class="tex" alt="\lambda_i=s_i^2" src="../images/math/5/e/2/5e27d4ab81c57906ff6caf9d0a517eca.png"></dd>
      </dl>
    </dd>
  </dl>

  <dl>
    <dd>Eigenwerte sind in absteigender Ordnung sortiert. Der Anteil der Varianz erklärt durch die <i>i</i>-te Hauptkomponente lautet <img class="tex" alt="\lambda_i/\sum_{k=1}^p \lambda_k" src="../images/math/4/e/1/4e151b51de76c606322dbee6e3ec7775.png">.</dd>
  </dl>

  <ul>
    <li>Eigenvektoren</li>
  </ul>

  <dl>
    <dd>Eigenvektoren sind auch bekannt als Ladungen oder Koeffizienten für Hauptkomponenten. Jede Spalte in <i>P</i> ist der Eigenvektor, der dem Eigenwert oder der Hauptkomponente entspricht.</dd>
  </dl>

  <dl>
    <dd><b>Beachten Sie,</b> dass das Vorzeichen des Eigenvektors für <b>SVD</b> nicht einzigartig ist. Origin normiert die Vorzeichen, indem es die Summe jeder Spalte positiv macht.</dd>
  </dl>

  <ul>
    <li>Scores</li>
  </ul>

  <dl>
    <dd>Jede Spalte in <img class="tex" alt="\sqrt{n-1}V\Lambda" src="../images/math/c/b/a/cbab37bece4796d7207df062587e641c.png"> entspricht den Scores je nach Hauptkomponente. Scores sind die fehlenden Werte entsprechend einer Beobachtung, die fehlende Werte enthält.</dd>
  </dl>

  <dl>
    <dd>
      <b>Beachten Sie,</b> dass die Varianz der Scores für jede Hauptkomponente gleich dem entsprechenden Eigenwert für diese Methode ist.

      <ul>
        <li>Standardisierte Scores</li>
      </ul>

      <dl>
        <dd>Scores für jede Hauptkomponente werden standardisiert, so dass sie über Varianz bezüglich der Einheiten verfügen.</dd>
      </dl>
    </dd>
  </dl><a name="Pairwise_Exclusion_of_Missing_Values"></a>

  <h2><span class="mw-headline">Paarweiser Ausschluss von fehlenden Werten</span></h2>

  <p>Eine Beobachtung wird aus der Berechnung der Kovarianz oder Korrelation zwischen zwei Variablen nur ausgeschlossen, wenn fehlende Werte in einer der zwei Variablen für die Beobachtung existieren.</p>

  <p>Eigenwerte und Eigenvektoren werden aus der Kovarianz- oder Korrelationsmatrix <i>S</i> berechnet.</p>

  <dl>
    <dd><img class="tex" alt="SP=PD\ " src="../images/math/1/e/b/1eb525b55da5f5a7b146d626ef443681.png"></dd>
  </dl>

  <p>, wobei <i>P</i> eine <i>p</i> x <i>p</i> -Matrix und <i>D</i> eine Diagonalmatrix mit diagonalen Elementen <img class="tex" alt="\lambda_i \ i=1, 2, ..., p" src="../images/math/4/b/1/4b1e7e9cf18bcfd3c3b61db7d01c85c2.png"> ist.</p>

  <ul>
    <li>Eigenwerte</li>
  </ul>

  <dl>
    <dd><img class="tex" alt="\lambda_i\ " src="../images/math/5/a/d/5ad7f730afc14fc0cf55a0e02bfee867.png"> ist der <i>i</i>-te Eigenwert für die <i>i</i>-te Hauptkomponente. Und Eigenwerte werden in absteigender Reihenfolge sortiert.</dd>

    <dd><b>Beachten Sie,</b> dass Eigenwerte für fehlende Werte, die paarweise ausgeschlossen wurden, negativ sein können, was für Hauptkomponenten keinen Sinn macht. Origin setzt die Ladung und Scores für einen negativen Eigenwert auf Null.</dd>
  </dl>

  <ul>
    <li>Eigenvektoren</li>
  </ul>

  <dl>
    <dd>Jede Spalte in <i>P</i> ist der Eigenvektor, der dem Eigenwert oder der Hauptkomponente entspricht.</dd>

    <dd><b>Beachten Sie,</b> dass das Vorzeichen des Eigenvektors nicht einzigartig ist. Origin normiert die Vorzeichen, indem es die Summe jeder Spalte positiv macht.</dd>
  </dl>

  <ul>
    <li>Scores</li>
  </ul>

  <dl>
    <dd>
      <dl>
        <dd><img class="tex" alt="V=X_0P\ " src="../images/math/0/a/3/0a306ebce0afd135e9a2666673bba8d3.png"></dd>
      </dl>
    </dd>

    <dd>wobei <img class="tex" alt="X_0\ " src="../images/math/5/4/8/54858df42806a04a2a48001780f3b8cc.png"> die Matrix X ist, bei der der Mittelwert von jeder Spalte von jeder Variablen subtrahiert wurde.</dd>

    <dd>Scores sind die fehlenden Werte entsprechend einer Beobachtung, die fehlende Werte enthält.</dd>

    <dd>Beachten Sie, dass die Varianz der Scores für jede Hauptkomponente gleich dem entsprechenden Eigenwert für diese Methode ist.</dd>
  </dl>

  <dl>
    <dd>
      <ul>
        <li>Standardisierte Scores</li>
      </ul>

      <dl>
        <dd>Scores für jede Hauptkomponente werden nach der Quadratwurzel ihres Eigenwerts skaliert.</dd>
      </dl>
    </dd>
  </dl><a name="Bartlett.27s_Test"></a>

  <h2><span class="mw-headline">Bartletts Test</span></h2>

  <p><b>Bartletts Test</b> testet die Gleichheit der verbleibenden <i>p-k</i> Eigenwerte. Er ist nur verfügbar, wenn die Analysematrix eine Kovarianzmatrix ist.</p>

  <dl>
    <dd><img class="tex" alt="H_0:\lambda_{k+1}=\lambda_{k+2}=...=\lambda_{p} k=0, 1, ..., p-2\ " src="../images/math/8/a/9/8a9e87e290206cd3d002a18d8f73f16e.png"></dd>
  </dl>

  <p>Es nähert sich einer <img class="tex" alt="\chi_2\ " src="../images/math/0/1/4/014bc33c7544184a9c4d0a485aab0cb9.png"> Verteilung an mit <img class="tex" alt="\frac{1}{2}(p-k-1)(p-k+2)" src="../images/math/1/9/1/191b4428ee1bed9ea325e424fae6528c.png"> Freiheitsgraden.</p>

  <dl>
    <dd><img class="tex" alt="(n-1-(2p+5)/6)\Big\{-\sum_{i=k+1}^p \mathrm{log}(\lambda_i)+(p-k)\mathrm{log}(\sum_{i=k+1}^p \lambda_i/(p-k))\Big\}" src="../images/math/5/0/c/50c6acba14aca5f1b18e1792f9936da3.png"></dd>
  </dl>
