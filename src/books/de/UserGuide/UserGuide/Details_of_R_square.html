<h1 class="firstHeading">Zusätzliche Informationen zu R-Quadrat</h1>

  <p class='urlname' style='display: none'>Details_of_R_square</p>

  <p>Wie gut ist die Anpassung? Eine nahe liegende Metrik ist die Nähe der angepassten Kurve zu den tatsächlichen Datenpunkten. Vom vorhergehenden <a href="../../UserGuide/Category/Interpreting_Regression_Results.html#Illustration_of_the_Least-Squares_Method" title="Category:Interpreting Regression Results">Abschnitt</a> wissen wir, dass die Residuensumme der Quadrate (<i>RSS</i>) oder der reduzierte Chi-Quadrat-Wert ein quantitativer Wert ist, der zum Bewerten dieser Abstandsart verwendet werden kann. Der Wert der Summe der Fehlerquadrate (<i>RSS</i>) variiert von Datensatz zu Datensatz, so dass es notwendig ist, diesen Wert in einen einheitlichen Bereich neu zu skalieren. Andererseits wird der Mittelwert des Y-Werts zum Beschreiben des Datenmerkmals möglicherweise bevorzugt. In diesem Fall ist die angepasste Kurve eine horizontale Linie <img src="../images/Details_of_R_square/math-70816b25c4d584534e7df04fc17bf02f.png" title="y=\overline{y}" alt="y=\overline{y}" class="tex"> und der Prädiktor X kann den Y-Wert nicht linear vorhersagen. Um dies zu prüfen, berechnen wir zunächst die Abweichung zwischen Datenpunkten und dem Mittelwert:</p>

  <p><img src="../images/Details_of_R_square/math-d13055e359b42226d0b8ae6ba915df63.png" title="TSS=\sum_{i=1}^n(y_i-\overline{y})^2 \,\!" alt="TSS=\sum_{i=1}^n(y_i-\overline{y})^2 \,\!" class="tex"></p>

  <p>Bei der Methode der kleinsten Quadrate kann der <i>TSS</i> in zwei Teile geteilt werden: die durch Regression erklärte Abweichung und der ungeklärte Teil:</p>

  <table class="simple">
    <tr>
      <td>
        <ul>
          <li>Die Quadratsumme der Regression <i>SSreg</i> ist der Teil der Abweichung, der durch das Regressionsmodell erklärt wird.</li>
        </ul>
      </td>

      <td>
        <p><img src="../images/Details_of_R_square/math-f4247da7269e1f6bd96b1cb786a8daa7.png" title="SSreg=\sum_{i=1}^n(\widehat{y_i}-\overline{y})^2 \,\!" alt="SSreg=\sum_{i=1}^n(\widehat{y_i}-\overline{y})^2 \,\!" class="tex"></p>
      </td>
    </tr>

    <tr>
      <td>
        <ul>
          <li>Die Residuensumme der Quadrate <i>RSS</i> ist der Teil der Abweichung, der durch das Regressionsmodell nicht erklärt wird.</li>
        </ul>
      </td>

      <td>
        <p><img src="../images/Details_of_R_square/math-634bbb984efc22841c46916fdb141a1e.png" title="RSS=\sum_{i=1}^n(y_i-\widehat{y_i})^2 \,\!" alt="RSS=\sum_{i=1}^n(y_i-\widehat{y_i})^2 \,\!" class="tex"></p>
      </td>
    </tr>
  </table>

  <p>Je näher die angepasste Kurve an den Datenpunkten liegt, desto kleiner ist die <i>RSS</i> und desto größer ist der Anteil der Gesamtabweichung, die durch das <i>SSreg</i> dargestellt wird. Folglich kann das Verhältnis von <i>SSreg</i> zu <i>TSS</i> als ein Maß der Qualität des Regressionsmodells verwendet werden. Diese Menge -- bezeichnet als der <b>Determinationskoeffizient</b> -- wird wie folgt berechnet:</p>

  <p><img src="../images/Details_of_R_square/math-c816efca2c109e12f1095236ff58d882.png" title="R^2=\frac{SSreg}{TSS}=1-\frac{RSS}{TSS} \,\!" alt="R^2=\frac{SSreg}{TSS}=1-\frac{RSS}{TSS} \,\!" class="tex"></p>

  <p>In der obigen Gleichung können Sie sehen, dass bei der Verwendung eines guten Anpassungsmodells <img src="../images/Details_of_R_square/math-e31b458b48dd58470b662e66b9742071.png" title="R^2" alt="R^2" class="tex"> zwischen 0 und 1 variieren sollte. Ein Wert, der nahe an 1 liegt, weist darauf hin, dass die Anpassung gut ist.</p>

  <p>Mathematisch gesprochen beeinflusst der Freiheitsgrad <img src="../images/Details_of_R_square/math-e31b458b48dd58470b662e66b9742071.png" title="R^2" alt="R^2" class="tex">. Das heißt, durch Hinzufügen von Variablen zum Modell steigt <img src="../images/Details_of_R_square/math-e31b458b48dd58470b662e66b9742071.png" title="R^2" alt="R^2" class="tex">. Dies bedeutet nicht, dass die Anpassung besser wird. Um diesen Effekt zu vermeiden, können wir das korrigierte <img src="../images/Details_of_R_square/math-e31b458b48dd58470b662e66b9742071.png" title="R^2" alt="R^2" class="tex"> betrachten.</p>

  <p><img src="../images/Details_of_R_square/math-56ed207e01d9d11e34c2fa201b98e00b.png" title="\overline{R}^2=1-\frac{RSS/df_{Error}}{TSS/df_{Total}} \,\!" alt="\overline{R}^2=1-\frac{RSS/df_{Error}}{TSS/df_{Total}} \,\!" class="tex"></p>

  <p>In der Gleichung können wir sehen, dass das korrigierte <img src="../images/Details_of_R_square/math-e31b458b48dd58470b662e66b9742071.png" title="R^2" alt="R^2" class="tex"> die Steigung von <img src="../images/Details_of_R_square/math-e31b458b48dd58470b662e66b9742071.png" title="R^2" alt="R^2" class="tex"> ausgleicht, insbesondere beim Anpassen einer kleinen Stichprobengröße <i>(n)</i> durch ein Modell mit mehreren Prädiktorvariablen (k). Obwohl wir den Determinationskoeffizienten als "<i>R</i> -Quadrat” bezeichnen, ist er eigentlich kein "Quadrat"-Wert von <i>R</i>. In den meisten Fällen liegt der Wert zwischen 0 und 1. Sie können aber auch negative R-Quadratwerte erhalten, wenn die Anpassung schlecht ist. Dies liegt daran, dass die Gleichung zum Berechnen von <img src="../images/Details_of_R_square/math-e31b458b48dd58470b662e66b9742071.png" title="R^2" alt="R^2" class="tex"> ist <img src="../images/Details_of_R_square/math-fe4da21819f56a1c315ec606c5fd159f.png" title="R^2 = 1 - RSS / TSS" alt="R^2 = 1 - RSS / TSS" class="tex">. Der zweite Term wird größer als 1, wenn ein schlechtes Modell verwendet wird.</p>

  <p>Dennoch ist die Verwendung von <img src="../images/Details_of_R_square/math-e31b458b48dd58470b662e66b9742071.png" title="R^2" alt="R^2" class="tex"> oder dem korrigierten <img src="../images/Details_of_R_square/math-e31b458b48dd58470b662e66b9742071.png" title="R^2" alt="R^2" class="tex"> nicht ausreichend. Im folgenden Diagramm zum Beispiel mag die angepasste Kurve in den Zeichnungen B-D zwar einen hohen <img src="../images/Details_of_R_square/math-e31b458b48dd58470b662e66b9742071.png" title="R^2" alt="R^2" class="tex">-Wert besitzen, die Modelle sind aber offenbar falsch. Daher ist es nötig, das Regressionsergebnis durch die Residuenanalyse zu prüfen.</p>

  <dl>
    <dd><a class="image"><img alt="Goodness of Fit.jpg" src="../images/Details_of_R_square/Goodness_of_Fit.jpg" width="468" height="341"></a></dd>
  </dl>

  <h2><a name="R-Sqaure_in_Linear_Fit"></a><span class="mw-headline">R-Quadrat in linearer Anpassung</span></h2>

  <h3><a name="Linear_Fit_for_Intercept_Included"></a><span class="mw-headline">Lineare Anpassung für Schnittpunkt mit der Y-Achse eingeschlossen</span></h3>

  <p>Wenn der Schnittpunkt mit der Y-Achse in den linearen Fit eingeschlossen ist, gilt die Beziehung:</p>

  <dl>
    <dd><img src="../images/Details_of_R_square/math-f27785e30b46e8d63fc44e61bc5097d7.png" title="\sum_{i=1}^n (y_i-\bar{y})^2 = \sum_{i=1}^n (y_i-f(x_i))^2 + \sum_{i=1}^n (f(x_i)-\bar{y})^2" alt="\sum_{i=1}^n (y_i-\bar{y})^2 = \sum_{i=1}^n (y_i-f(x_i))^2 + \sum_{i=1}^n (f(x_i)-\bar{y})^2" class="tex"></dd>
  </dl>

  <p>wobei <img src="../images/Details_of_R_square/math-d50c99fc89a5682178a3b7e60966f560.png" title="(x_i, y_i) \; i=1..n \;" alt="(x_i, y_i) \; i=1..n \;" class="tex"> Anpassungsdaten sind, <img src="../images/Details_of_R_square/math-bacfc7141fdfd692244b6c50891d1f7b.png" title="\bar{y}" alt="\bar{y}" class="tex"> den Mittelwert der abhängigen Variablen bezeichnet und <img src="../images/Details_of_R_square/math-2545f6aff9e599f7b0731247906b6b00.png" title="f(x_i) \;" alt="f(x_i) \;" class="tex"> der angepasste Wert ist.</p>

  <p>Die linke Seite in der oben stehenden Gleichung ist die Gesamtsumme der Quadrate, d.h.</p>

  <dl>
    <dd><img src="../images/Details_of_R_square/math-65662ccc390f7d7235cfde7790068791.png" title="TSS = \sum_{i=1}^n (y_i-\bar{y})^2" alt="TSS = \sum_{i=1}^n (y_i-\bar{y})^2" class="tex"></dd>
  </dl>

  <p>Der erste Term rechts ist die Summe der Fehlerquadrate, d.h.</p>

  <dl>
    <dd><img src="../images/Details_of_R_square/math-5b6fe5a5e38d5b1e0c1295c200aef14f.png" title="RSS = \sum_{i=1}^n (y_i-f(x_i))^2" alt="RSS = \sum_{i=1}^n (y_i-f(x_i))^2" class="tex"></dd>
  </dl>

  <p>Der zweite Term rechts ist die Summe der Quadrate, die auf die Regression zurückzuführen ist, d.h.</p>

  <dl>
    <dd><img src="../images/Details_of_R_square/math-98c4dfa1b52ea241deb3e3f72a8ede46.png" title="SSR = \sum_{i=1}^n (f(x_i)-\bar{y})^2" alt="SSR = \sum_{i=1}^n (f(x_i)-\bar{y})^2" class="tex"></dd>
  </dl>

  <p>Daher <i><b>TSS = RSS + SSR</b></i>.</p>

  <p>Der Koeffizient der Determination (<b>R-Quadrat</b>) wird definiert durch das Verhältnis von SSR zu TSS:</p>

  <dl>
    <dd><img src="../images/Details_of_R_square/math-87012079a131e26d822f0af602776401.png" title="R^2=\frac{SSR}{TSS}=1-\frac{RSS}{TSS}=1-\frac{\sum_{i=1}^n (y_i-f(x_i))^2}{\sum_{i=1}^n (y_i-\bar{y})^2}" alt="R^2=\frac{SSR}{TSS}=1-\frac{RSS}{TSS}=1-\frac{\sum_{i=1}^n (y_i-f(x_i))^2}{\sum_{i=1}^n (y_i-\bar{y})^2}" class="tex"></dd>
  </dl>

  <p>Deswegen misst <b>R-Quadrat</b> den Anteil der Variation der abhängigen Variablen über den Mittelwert, der durch die Anpassung erklärt wird, wenn der Schnittpunkt mit der Y-Achse eingeschlossen ist.</p>

  <h3><a name="Linear_Fit_for_Fixed_Intercept"></a><span class="mw-headline">Lineare Anpassung für festen Schnittpunkt mit der Y-Achse</span></h3>

  <p>Wenn der Schnittpunkt mit der Y-Achse jedoch in der linearen Anpassung festgelegt ist, wird das obenstehende Verhältnis unter <a href="#Linear_Fit_for_Intercept_Included">Lineare Anpassung für Schnittpunkt mit der Y-Achse eingeschlossen</a> nicht erfüllt. Für eine schlechte Anpassung kann sich ein negativer Wert für <b>R-Quadrat</b> ergeben, wenn die Definition unter <a href="#Linear_Fit_for_Intercept_Included">Lineare Anpassung für Schnittpunkt mit der Y-Achse eingeschlossen</a> verwendet wird. Dies macht keinen Sinn.</p>

  <p>Wenn der Schnittpunkt mit der Y-Achse in die linearen Anpassung eingeschlossen ist, gilt das Verhältnis:</p>

  <dl>
    <dd><img src="../images/Details_of_R_square/math-4bb63ecc585d86a8829dec4019fe998f.png" title="\sum_{i=1}^n y_i^2 = \sum_{i=1}^n (y_i-f(x_i))^2 + \sum_{i=1}^n (f(x_i))^2" alt="\sum_{i=1}^n y_i^2 = \sum_{i=1}^n (y_i-f(x_i))^2 + \sum_{i=1}^n (f(x_i))^2" class="tex"></dd>
  </dl>

  <p><b>TSS</b> und <b>SSR</b> müssen dann neu definiert werden. <b>RSS</b> bleibt unverändert.</p>

  <dl>
    <dd><img src="../images/Details_of_R_square/math-898716dfe4c0756a5032aff8d5101712.png" title="TSS = \sum_{i=1}^n y_i^2" alt="TSS = \sum_{i=1}^n y_i^2" class="tex"></dd>
  </dl>

  <dl>
    <dd><img src="../images/Details_of_R_square/math-120a95f050e837d97b73fecc20722464.png" title="SSR = \sum_{i=1}^n (f(x_i))^2" alt="SSR = \sum_{i=1}^n (f(x_i))^2" class="tex"></dd>
  </dl>

  <p>Der Koeffizient der Determination (<b>R-Quadrat</b>) wird folgendermaßen neu definiert:</p>

  <dl>
    <dd><img src="../images/Details_of_R_square/math-5b936b2331157d838945fac4f2fa4bda.png" title="R^2=\frac{SSR}{TSS}=1-\frac{RSS}{TSS}=1-\frac{\sum_{i=1}^n (y_i-f(x_i))^2}{\sum_{i=1}^n y_i^2}" alt="R^2=\frac{SSR}{TSS}=1-\frac{RSS}{TSS}=1-\frac{\sum_{i=1}^n (y_i-f(x_i))^2}{\sum_{i=1}^n y_i^2}" class="tex"></dd>
  </dl>

  <p>Auf diese Weise ist der Wert von <b>R-Quadrat</b> immer nicht negativ. Das <b>R-Quadrat</b> misst den Anteil der Variation der abhängigen Variable um den Wert Null wie von der Anpassung erklärt, wenn der Schnittpunkt mit der Y-Achse festgelegt ist.</p>
