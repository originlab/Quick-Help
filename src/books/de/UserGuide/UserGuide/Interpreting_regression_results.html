<h1 class="firstHeading">Ergebnisse der Regression interpretieren</h1>

  <p class='urlname' style='display: none'>Regression_Results</p>

  <p>Die Regression wird häufig verwendet, um die Linie mit der besten Anpassung zu berechnen. Wenn Sie eine Regressionsanalyse durchführen, erzeugen Sie ein Analyseberichtsblatt, das die Regressionsergebnisse des Modells beinhaltet. In diesem Artikel wird erläutert, wie die wichtigen Ergebnisse der Regression schnell und einfach interpretiert werden können.</p>

  <div id="toc" class="toc">
    <div id="toctitle">
      <h2>Inhalt</h2>
    </div>

    <ul>
      <li class="toclevel-1 tocsection-1">
        <a href="#In_Parameters_Table"><span class="tocnumber">1</span> <span class="toctext">Parametertabelle</span></a>

        <ul>
          <li class="toclevel-2 tocsection-2"><a href="#t-Value"><span class="tocnumber">1.1</span> <span class="toctext">t-Wert</span></a></li>

          <li class="toclevel-2 tocsection-3"><a href="#Prob.3E.7Ct.7C"><span class="tocnumber">1.2</span> <span class="toctext">Wahrsch.&gt;|t|</span></a></li>

          <li class="toclevel-2 tocsection-4"><a href="#LCL_and_UCL"><span class="tocnumber">1.3</span> <span class="toctext">UEG und OEG</span></a></li>

          <li class="toclevel-2 tocsection-5"><a href="#Dependency"><span class="tocnumber">1.4</span> <span class="toctext">Abhängigkeit</span></a></li>
        </ul>
      </li>

      <li class="toclevel-1 tocsection-6">
        <a href="#In_Statistics_Table"><span class="tocnumber">2</span> <span class="toctext">Statistiktabelle</span></a>

        <ul>
          <li class="toclevel-2 tocsection-7"><a href="#Residual_Sum_of_Squares"><span class="tocnumber">2.1</span> <span class="toctext">Residuensumme der Quadrate</span></a></li>

          <li class="toclevel-2 tocsection-8"><a href="#Scale_Error_with_sqrt.28Reduced_Chi-Sqr.29"><span class="tocnumber">2.2</span> <span class="toctext">Skalierungsfehler mit Quadrat (Reduziertes Chi-Qdr.)</span></a></li>

          <li class="toclevel-2 tocsection-9"><a href="#Pearson.27s_r"><span class="tocnumber">2.3</span> <span class="toctext">Pearsons r</span></a></li>

          <li class="toclevel-2 tocsection-10"><a href="#R-Square_.28COD.29"><span class="tocnumber">2.4</span> <span class="toctext">R-Quadrat (COD)</span></a></li>

          <li class="toclevel-2 tocsection-11"><a href="#Adj._R-Square"><span class="tocnumber">2.5</span> <span class="toctext">Korr. R-Quadrat</span></a></li>
        </ul>
      </li>

      <li class="toclevel-1 tocsection-12">
        <a href="#In_ANOVA_Table"><span class="tocnumber">3</span> <span class="toctext">ANOVA-Tabelle</span></a>

        <ul>
          <li class="toclevel-2 tocsection-13"><a href="#F_Value"><span class="tocnumber">3.1</span> <span class="toctext">F-Wert</span></a></li>

          <li class="toclevel-2 tocsection-14"><a href="#Prob.3EF"><span class="tocnumber">3.2</span> <span class="toctext">Wahrsch.&gt;F</span></a></li>
        </ul>
      </li>

      <li class="toclevel-1 tocsection-15">
        <a href="#In_Covariance_and_Correlation_Table"><span class="tocnumber">4</span> <span class="toctext">Kovarianz- und Korrelationstabelle</span></a>

        <ul>
          <li class="toclevel-2 tocsection-16"><a href="#Covariance"><span class="tocnumber">4.1</span> <span class="toctext">Kovarianz</span></a></li>

          <li class="toclevel-2 tocsection-17"><a href="#Correlation"><span class="tocnumber">4.2</span> <span class="toctext">Korrelation</span></a></li>
        </ul>
      </li>

      <li class="toclevel-1 tocsection-18"><a href="#In_Fitted_Curves_Plot"><span class="tocnumber">5</span> <span class="toctext">Angepasstes Kurvendiagramm</span></a></li>

      <li class="toclevel-1 tocsection-19"><a href="#In_Residual_Plot"><span class="tocnumber">6</span> <span class="toctext">Residuendiagramm</span></a></li>
    </ul>
  </div>

  <h2><a name="In_Parameters_Table"></a><span class="mw-headline">Parametertabelle</span></h2>

  <p>Die angepassten Werte werden in der Tabelle <b>Parameter</b> aufgeführt, wie unten zu sehen:</p>

  <dl>
    <dd><a class="image"><img alt="Interpret Linear Regression Results 1.png" src="../images/Interpreting_regression_results/Interpret_Linear_Regression_Results_1.png" width="641" height="73"></a></dd>
  </dl>

  <h3><a name="t-Value"></a><span class="mw-headline">t-Wert</span></h3>

  <p>Der t-Wert ist eine Teststatistik für den <a href="../../UserGuide/UserGuide/Significance_of_Parameters.html" title="UserGuide:Significance of Parameters">t-Test</a>, der untersucht, ob der angepasste Wert sich signifikant von Null unterscheidet. Beachten Sie, dass der t-Wert = Angepasster Wert/Standardfehler, zum Beispiel ist der t-Wert für y0 5,34198/0,58341 = 9,15655.<br>
  Ein größerer t-Wert lässt vermuten, dass es in der linearen Regression eine signifikante Differenz zwischen dem angepassten Wert und Null gibt. Für diesen statistischen t-Wert wird üblicherweise ein Vergleich mit einem kritischen t-Wert eines gegebenen Konfidenzniveaus <img src="../images/Interpreting_regression_results/math-06f7895cd704b1cb0921cf98aec71926.png" title="\alpha\,\!" alt="\alpha\,\!" class="tex"> (normalerweise 5%) herangezogen. Wenn der t-Wert größer als der kritische t-Wert ist (<img src="../images/Interpreting_regression_results/math-9d38e8e7363d66af41530c3fbdf494f5.png" title="|t|&gt;t_{\frac \alpha 2}" alt="|t|&gt;t_{\frac \alpha 2}" class="tex"> ), kann man sagen, dass es eine signifikante Differenz gibt. Anders ausgedrückt, bedeutet dies, dass es unwahrscheinlich ist, dass der Anpassungswert gleich Null ist. Für die lineare Regression kann vermutet werden, dass die Anpassungslinie wahrscheinlich nicht durch den Ursprung verläuft bzw. wahrscheinlich nicht flach sein wird.</p>

  <h3><a name="Prob.3E.7Ct.7C"></a><span class="mw-headline">Wahrsch.&gt;|t|</span></h3>

  <p>Wahrsch.&gt;|t| ist ein p-Wert für den t-Test, das heißt eine Wahrscheinlichkeit mit einem Wert zwischen Null und Eins. Oben wird erwähnt, dass man vermuten kann, dass eine signifikante Differenz besteht, wenn der t-Wert größer als der kritische t-Wert eines gegebenen Konfidenzniveaus <img src="../images/Interpreting_regression_results/math-06f7895cd704b1cb0921cf98aec71926.png" title="\alpha\,\!" alt="\alpha\,\!" class="tex"> ist. Für Wahrsch.&gt;|t| kann invers berechnet werden, was α für den statistischen t-Wert des angepassten Werts ist. Wenn Wahrsch.&gt;|t| &lt; <img src="../images/Interpreting_regression_results/math-06f7895cd704b1cb0921cf98aec71926.png" title="\alpha\,\!" alt="\alpha\,\!" class="tex"> (normalerweise 5%), kann ebenfalls vermutet werden, dass es eine statistisch signifikante Differenz von Null gibt. Je kleiner Wahrsch.&gt;|t|, desto unwahrscheinlicher ist es, dass der angepasste Wert gleich Null ist.</p>

  <h3><a name="LCL_and_UCL"></a><span class="mw-headline">UEG und OEG</span></h3>

  <p>UEG und OEG sind die Kurzformen für die obere Konfidenzgrenze bzw. die untere Konfidenzgrenze. Für ein gegebenes Konfidenzniveaus <img src="../images/Interpreting_regression_results/math-06f7895cd704b1cb0921cf98aec71926.png" title="\alpha\,\!" alt="\alpha\,\!" class="tex"> (normalerweise 5%) kann das Konfidenzintervall <img src="../images/Interpreting_regression_results/math-69416b2f57e0930b3c8547402ecceef4.png" title="(1-\alpha) \times 100\%" alt="(1-\alpha) \times 100\%" class="tex"> für den angepassten Wert aus dem t-Wert berechnet werden. Für das Intervall (UEG, OEG) kann rückgeschlossen werden, dass man mit einer Konfidenz von <img src="../images/Interpreting_regression_results/math-69416b2f57e0930b3c8547402ecceef4.png" title="(1-\alpha) \times 100\%" alt="(1-\alpha) \times 100\%" class="tex"> sagen kann, dass der am besten angepasste Wert in dieses Intervall fällt.</p>

  <h3><a name="Dependency"></a><span class="mw-headline">Abhängigkeit</span></h3>

  <p>Der Abhängigkeitswert, der aus der Varianz-Kovarianz-Matrix berechnet wird, verweist typischerweise auf die Signifikanz des Parameters in Ihrem Modell. Wenn einige Abhängigkeitswerte zum Beispiel nah bei 1 liegen, könnte dies bedeuten, dass es eine gegenseitige Abhängigkeit zwischen diesen Parametern gibt. Anders ausgedrückt ist die Funktion überparameterisiert und der Parameter ist womöglich redundant. Beachten Sie, dass Sie Beschränkungen vornehmen sollten, um sicherzustellen, dass das Anpassungsmodell bedeutungsvoll ist. Informationen hierzu finden Sie in <a href="../../UserGuide/UserGuide/Model_Diagnosis_Using_Dependency_Values.html" title="UserGuide:Model Diagnosis Using Dependency Values">diesem Abschnitt</a>.</p>

  <h2><a name="In_Statistics_Table"></a><span class="mw-headline">Statistiktabelle</span></h2>

  <p>Die statistischen Schlüsselwerte der linearen Anpassung werden in der Tabelle <b>Statistik</b> aufgeführt, wie unten zu sehen:</p>

  <dl>
    <dd><a class="image"><img alt="Interpret Linear Regression Results 2.png" src="../images/Interpreting_regression_results/Interpret_Linear_Regression_Results_2.png" width="225" height="201"></a></dd>
  </dl>

  <h3><a name="Residual_Sum_of_Squares"></a><span class="mw-headline">Summe der Fehlerquadrate</span></h3>

  <p>Die Summe der Fehlerquadrate wird mit RSS (Residual Sum of Squares) abgekürzt. Es handelt sich hierbei um die Summe der Quadrate der vertikalen Abweichungen von jedem Datenpunkt zur Anpassungslinie der Regression. Sie wird mit Hilfe der <a href="../../UserGuide/UserGuide/The_Least_Squares_Method.html" title="UserGuide:The Least Squares Method">Methode der kleinsten Quadrate</a> berechnet. Sie können rückschließen, dass Ihre Daten perfekt angepasst sind, wenn der Wert der RSS gleich Null ist. Diese Statistik kann hilfreich sein, wenn die angepasste Regressionslinie ein guter Fit für Ihre Daten ist. Im Allgemeinen kann man sagen, dass je kleiner die Summe der Fehlerquadrate ist, desto besser passt Ihr Modell Ihre Daten an.</p>

  <h3><a name="Scale_Error_with_sqrt.28Reduced_Chi-Sqr.29"></a><span class="mw-headline">Skalierungsfehler mit Quadrat (Reduziertes Chi-Quadrat)</span></h3>

  <p>Der Wert des reduzierten Chi-Quadrats ist gleich der Summe der Fehlerquadrate geteilt durch den Freiheitsgrad. Normalerweise bedeutet ein Wert des reduzierten Chi-Quadrats nahe bei 1 ein gutes Anpassungsergebnis. Er weist darauf hin, dass die Differenz zwischen den beobachteten Daten und den angepassten Daten im Hinblick auf die Fehlervarianz konsistent ist. Wenn die Fehlervarianz überschätzt wird, ist der Wert des reduzierten Chi-Quadrats kleiner als 1. Für eine unterschätzte Fehlervarianz ist der Wert viel größer als 1. Beachten Sie, dass die korrekte Varianz im Anpassungsprozess für das reduzierte Chi-Quadrat ausgewählt werden muss. Wenn die Y-Daten beispielsweise mit einem Skalierungsfaktor multipliziert wurden, wird auch das reduzierte Chi-Quadrat skaliert. Nur wenn Sie die Fehlervarianz auch mit einem korrekten Faktor skalieren, wird der Wert des reduzierten Chi-Quadrats in einen normalen Wert zurückverwandelt.</p>

  <h3><a name="Pearson.27s_r"></a><span class="mw-headline">Pearson r</span></h3>

  <p>Pearsons Korrelationskoeffizient, bezeichnet als Pearsons r, kann dabei helfen, die Stärke der linearen Beziehung zwischen gepaarten Daten zu messen. Der Wert von Pearsons r ist beschränkt auf den Bereich zwischen -1 und 1. In der linearen Regression weist ein positiver Wert von Pearsons r darauf hin, dass es eine positive lineare Korrelation zwischen der Prädiktorvariablen (x) und der Antwortvariablen (y) gibt, während ein negativer Wert von Pearsons r darauf hinweist, das eine negative lineare Korrelation zwischen der Prädiktorvariablen (x) und der Antwortvariablen (y) besteht. Der Wert von Null zeigt, dass es keine lineare Korrelation zwischen den Daten gibt. Außerdem gilt, je näher der Wert an -1 oder 1 liegt, desto stärker ist die lineare Korrelation.</p>

  <h3><a name="R-Square_.28COD.29"></a><span class="mw-headline">R-Quadrat (COD)</span></h3>

  <p>R-Quadrat, auch als Determinationskoeffizient (COD) bezeichnet, ist ein statistisches Maß zur qualitativen Bewertung der linearen Regression. Es ist ein Prozentanteil der Variation der Antwortvariablen, der durch die angepasste Regressionslinie erklärt wird. Das R-Quadrat zum Beispiel lässt vermuten, dass das Modell ca. mehr als 89% der Streuung in der Antwortvariablen erklärt. R-Quadrat muss demnach zwischen 0 und 1 liegen. Wenn R-Quadrat 0 ist, weist es darauf hin, dass die angepasste Linie die Streuung der Antwortdaten um ihren Mittelwert nicht erklärt; ist R-Quadrat dagegen 1, weist dies darauf hin, dass die angepasste Linie die gesamte Streuung der Antwortdaten um ihren Mittelwert erklärt. Allgemein kann man sagen, je größer R-Quadrat, desto besser passt die angepasste Linie Ihre Daten an.</p>

  <h3><a name="Adj._R-Square"></a><span class="mw-headline">Kor. R-Quadrat</span></h3>

  <p>R-Quadrat kann verwendet werden, um zu bewerten, wie gut ein Modell die Daten anpasst. R-Quadrat wird immer größer, wenn ein neuer Prädiktor hinzugefügt wird. Es ist Missverständnis, dass ein Modell mit mehr Prädiktoren eine bessere Anpassung bietet. Das Kor. R-Quadrat ist eine modifizierte Version von R-Quadrat, die für die Anzahl der Prädiktoren in der angepassten Linie ausgerichtet ist. Daher kann zum Vergleichen der angepassten Linien mit unterschiedlichen Anzahlen von Prädiktoren verwendet werden. Wenn die Anzahl der Prädiktoren größer ist als 1, dann ist das korrigierte R-Quadrat kleiner als R-Quadrat.</p>

  <h2><a name="In_ANOVA_Table"></a><span class="mw-headline">ANOVA-Tabelle</span></h2>

  <p>Wie die Regressionsgleichung die Variabilität in den y-Werten berücksichtigt, wird in der ANOVA-Tabelle beantwortet, wie unten zu sehen:</p>

  <dl>
    <dd><a class="image"><img alt="Interpret Linear Regression Results 3.png" src="../images/Interpreting_regression_results/Interpret_Linear_Regression_Results_3.png" width="486" height="93"></a></dd>
  </dl>

  <h3><a name="F_Value"></a><span class="mw-headline">F -Wert</span></h3>

  <p>Der F-Wert ist ein Verhältnis von zwei mittleren Quadraten, die berechnet werden können, indem das mittlere Quadrat des angepassten Modells durch das mittlere Fehlerquadrat geteilt wird. Der F-Wert des Modells oben ist zum Beispiel 65764,4768/16441,1192=2103,59577. Es ist eine Teststatistik, um zu testen, ob das angepasste Modell sich signifikant von dem Modell y = konstant unterscheidet, das eine flache Linie mit einer Steigung gleich Null ist. Es kann rückgeschlossen werden, dass je mehr dieses Verhältnis von 1 abweicht, desto stärker ist der Beweis, dass das angepasste Modell sich signifikant von dem Modell y = konstant unterscheidet.</p>

  <h3><a name="Prob.3EF"></a><span class="mw-headline">Wahrsch.&gt;F</span></h3>

  <p>Wahrsch.&gt;F ist ein p-Wert für den F-Test, das heißt eine Wahrscheinlichkeit mit einem Wert zwischen 0 und 1. Wenn der p-Wert für den F-Test kleiner ist als das Signifikanzniveau <img src="../images/Interpreting_regression_results/math-06f7895cd704b1cb0921cf98aec71926.png" title="\alpha\,\!" alt="\alpha\,\!" class="tex"> (normalerweise 5%), dann kann geschlussfolgert werden, dass das angepasste Modell sich signifikant von dem Modell y = konstant unterscheidet. Dies lässt darauf rückschließen, dass das angepasste Modell eine nichtlineare Kurve oder eine lineare Kurve mit einer Steigung ist, die sich signifikant von 0 unterscheidet.</p>

  <table class="note">
    <tr>
      <td><b>Hinweise:</b> Wenn bei der linearen Regression der Schnittpunkt mit der Y-Achse bei einem bestimmten Wert festgelegt wird, ist der p-Wert für den F-Test nicht bedeutungsvoll und unterscheidet sich von dem in der linearen Regression ohne die Nebenbedingung des Schnittpunkts mit der Y-Achse.</td>
    </tr>
  </table>

  <h2><a name="In_Covariance_and_Correlation_Table"></a><span class="mw-headline">Kovarianz- und Korrelationstabelle</span></h2>

  <p>Die Beziehung zwischen den Variablen kann der Kovarianz- und Korrelationstabelle entnommen werden, wie unten zu sehen:<br>
  <a class="image"><img alt="Interpret Linear Regression Results 6.png" src="../images/Interpreting_regression_results/Interpret_Linear_Regression_Results_6.png" width="397" height="263"></a></p>

  <h3><a name="Covariance"></a><span class="mw-headline">Kovarianz</span></h3>

  <p>Der Kovarianzwert indiziert die Korrelation zwischen zwei Variablen und die Matrizen der Kovarianz in der Regression zeigen die Zwischenkorrelationen unter allen Parametern. Die diagonalen Werte der Kovarianzmatrix gleichen dem Quadrat des Parameterfehlers.</p>

  <h3><a name="Correlation"></a><span class="mw-headline">Korrelation</span></h3>

  <p>Die Korrelationsmatrix skaliert die Kovarianzwerte so, dass sie im Bereich von -1 bis +1 liegen. Ein Wert nahe +1 bedeutet, die beiden Parameter sind positiv korreliert, während ein Wert nahe -1 eine negative Korrelation anzeigt. Ein Wert von Null bedeutet, dass die beiden Parameter völlig unabhängig voneinander sind.</p>

  <h2><a name="In_Fitted_Curves_Plot"></a><span class="mw-headline"><a href="../../UserGuide/UserGuide/Fitted_Curves_Plot_Analysis.html" title="UserGuide:Fitted Curves Plot Analysis">Angepasstes Kurvendiagramm</a></span></h2>

  <p>Die angepasste Kurve sowie das Konfidenzband, das Prognoseband und die Ellipse werden im angepassten Kurvendiagramm gezeichnet, wie unten zu sehen. Sie unterstützt bei der Interpretation des Regressionsmodells auf intuitivere Weise.</p>

  <dl>
    <dd><a class="image"><img alt="Interpret Linear Regression Results 5.png" src="../images/Interpreting_regression_results/Interpret_Linear_Regression_Results_5.png" width="400" height="279"></a></dd>
  </dl>

  <ul>
    <li><a href="../../UserGuide/UserGuide/Fitted_Curves_Plot_Analysis.html#Confidence_and_Prediction_Bands" title="UserGuide:Fitted Curves Plot Analysis">Konfidenz- und Prognosebänder</a></li>

    <li><a href="../../UserGuide/UserGuide/Fitted_Curves_Plot_Analysis.html#Ellipse_Plots" title="UserGuide:Fitted Curves Plot Analysis">Ellipsendiagramme</a></li>
  </ul>

  <h2><a name="In_Residual_Plot"></a><span class="mw-headline"><a href="../../UserGuide/UserGuide/Graphic_Residual_Analysis.html" title="UserGuide:Graphic Residual Analysis">Residuendiagramm</a></span></h2>

  <p>Das Residuum ist definiert als:</p>

  <p><img src="../images/Interpreting_regression_results/math-04f8f09e63a269a044ceeee72a32143d.png" title="r_i=y_i-y=observed\,value\,of\,y-predicted\,value\,of\,y" alt="r_i=y_i-y=observed\,value\,of\,y-predicted\,value\,of\,y" class="tex"></p>

  <p>Residuendiagramme können verwendet werden, um die Qualität einer Regression zu bewerten, und befinden sich normalerweise am Ende des Berichts, wie unten zu sehen:</p>

  <dl>
    <dd><a class="image"><img alt="Interpret Linear Regression Results 4.png" src="../images/Interpreting_regression_results/Interpret_Linear_Regression_Results_4.png" width="400" height="279"></a></dd>
  </dl>

  <ul>
    <li><a href="../../UserGuide/UserGuide/Graphic_Residual_Analysis.html#Checking_the_error_variance" title="UserGuide:Graphic Residual Analysis">Fehlervarianz prüfen</a></li>

    <li><a href="../../UserGuide/UserGuide/Graphic_Residual_Analysis.html#Checking_the_process_drift" title="UserGuide:Graphic Residual Analysis">Nullpunktfehler des Prozesses prüfen</a></li>

    <li><a href="../../UserGuide/UserGuide/Graphic_Residual_Analysis.html#Checking_independence_of_the_error_term" title="UserGuide:Graphic Residual Analysis">Unabhängigkeit des Fehlerterms prüfen</a></li>

    <li><a href="../../UserGuide/UserGuide/Graphic_Residual_Analysis.html#Checking_normality_of_variance" title="UserGuide:Graphic Residual Analysis">Normalverteilung der Varianzen prüfen</a></li>

    <li><a href="../../UserGuide/UserGuide/Graphic_Residual_Analysis.html#Improving_the_regression_model_using_residuals_plots" title="UserGuide:Graphic Residual Analysis">Regressionsmodell mit Hilfe des Residuendiagramms verbessern</a></li>

    <li><a href="../../UserGuide/UserGuide/Graphic_Residual_Analysis.html#Detecting_outliers_by_transforming_residuals" title="UserGuide:Graphic Residual Analysis">Ausreißer mit Hilfe von Residuentransformation erkennen</a></li>

    <li><a href="../../UserGuide/UserGuide/Graphic_Residual_Analysis.html#Residual_contour_plots_for_surface_fitting" title="UserGuide:Graphic Residual Analysis">Konturdiagramme mit Residuen für die Oberflächenanpassung</a></li>
  </ul>
