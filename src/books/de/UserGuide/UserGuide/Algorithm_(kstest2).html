<h1 class="firstHeading">Algorithmen (Kolmogorov-Smirnov-Test bei zwei Stichproben)</h1>

  <p class='urlname' style='display: none'>KS-Test-Algorithm</p>

  <p>Die Vorgehensweise unten basiert auf NAG-Algorithmen.</p>

  <p>Es werden zwei unabhängige Stichproben betrachtet, X und Y, mit der Größe <img src="../images/Algorithm_(kstest2)/math-8d88a43872d6db6535d8672a15f09ce2.png" title="n_1\,\!" alt="n_1\,\!" class="tex"> und <img src="../images/Algorithm_(kstest2)/math-ede03c8aef1b07c898c7747b489fd765.png" title="n_2\,\! " alt="n_2\,\! " class="tex">. Sie werden als <img src="../images/Algorithm_(kstest2)/math-d79752c45b6e0288c460390908ff4157.png" title="x_1,x_2,\ldots ,x_{n_1}\,\!" alt="x_1,x_2,\ldots ,x_{n_1}\,\!" class="tex"> bzw. <img src="../images/Algorithm_(kstest2)/math-ba3bf26bc53cf72dd2f7e804e8351ba7.png" title="y_1,y_2,\ldots ,y_{n_1}\,\!" alt="y_1,y_2,\ldots ,y_{n_1}\,\!" class="tex"> bezeichnet. Angenommen, F(x) und G(x) stellen ihre jeweiligen unbekannten Verteilungsfunktionen dar. Weiterhin wird angenommen, dass <img src="../images/Algorithm_(kstest2)/math-2eaa8777a1f571cbad7bfca3adf83c34.png" title=" S_1(x)\,\! " alt=" S_1(x)\,\! " class="tex"> und <img src="../images/Algorithm_(kstest2)/math-17118f898c20f6dbf66463ce22714faa.png" title=" S_2(x)\,\! " alt=" S_2(x)\,\! " class="tex"> die Stichprobenwerte der empirischen Verteilungsfunktionen bezeichnen.</p>

  <p>Die Nullhypothese: F(x)=G(x)</p>

  <p>Die Alternativhypothese ist <img src="../images/Algorithm_(kstest2)/math-fabff59271b950125b7a360fba21de2c.png" title="H_1\,\!" alt="H_1\,\!" class="tex">:F(x)&lt;&gt;G(x), der zugehörige p-Wert ist eine beidseitige Wahrscheinlichkeit;</p>

  <p>oder<img src="../images/Algorithm_(kstest2)/math-fabff59271b950125b7a360fba21de2c.png" title="H_1\,\!" alt="H_1\,\!" class="tex"> :F(x)&gt;G(x), der zugehörige p-Wert ist eine obere Wahrscheinlichkeit,</p>

  <p>oder <img src="../images/Algorithm_(kstest2)/math-fabff59271b950125b7a360fba21de2c.png" title="H_1\,\!" alt="H_1\,\!" class="tex">: F(x)&lt;G(x), der zugehörige p-Wert ist eine untere Wahrscheinlichkeit.</p>

  <p>Im ersten Fall von <img src="../images/Algorithm_(kstest2)/math-fabff59271b950125b7a360fba21de2c.png" title="H_1\,\!" alt="H_1\,\!" class="tex"> stellt die Statistik <img src="../images/Algorithm_(kstest2)/math-a9aca3b08301eb7213e2408c0ab85104.png" title="D_{n_1,n_2} \,\!" alt="D_{n_1,n_2} \,\!" class="tex"> die größte absolute Abweichung der zwei empirischen Verteilungsfunktionen dar.</p>

  <p>Im zweiten Fall von <img src="../images/Algorithm_(kstest2)/math-fabff59271b950125b7a360fba21de2c.png" title="H_1\,\!" alt="H_1\,\!" class="tex"> stellt die Statistik <img src="../images/Algorithm_(kstest2)/math-4cd60644c5463cc66c7631c167ed3936.png" title="D_{n_1,n_2}^{+} \,\!" alt="D_{n_1,n_2}^{+} \,\!" class="tex"> die größte positive Abweichung zwischen der empirischen Verteilungsfunktion der ersten Stichprobe und der empirischen Verteilungsfunktion der zweiten Stichprobe dar, das heißt <img src="../images/Algorithm_(kstest2)/math-9cf98ed19b4ee4732ba5e4524e54a3f8.png" title="D_{n_1,n_2}^{+}=\max \{S_1(x)-S_2(x),0\}\,\!" alt="D_{n_1,n_2}^{+}=\max \{S_1(x)-S_2(x),0\}\,\!" class="tex">.</p>

  <p>Im dritten Fall von <img src="../images/Algorithm_(kstest2)/math-fabff59271b950125b7a360fba21de2c.png" title="H_1\,\!" alt="H_1\,\!" class="tex"> stellt die Statistik <img src="../images/Algorithm_(kstest2)/math-8af9c1a0d88a260554650e06fd515607.png" title="D_{n_1,n_2}^{-} \,\!" alt="D_{n_1,n_2}^{-} \,\!" class="tex"> die größte positive Abweichung zwischen der empirischen Verteilungsfunktion der zweiten Stichprobe und der empirischen Verteilungsfunktion der ersten Stichprobe dar, das heißt <img src="../images/Algorithm_(kstest2)/math-6a6a55b10a26fafb59197daab9f6d53b.png" title="D_{n_1,n_2}^{-}=\max \{S_2(x)-S_1(x),0\}\,\!" alt="D_{n_1,n_2}^{-}=\max \{S_2(x)-S_1(x),0\}\,\!" class="tex">.</p>

  <p>KS-test2 gibt auch die Standardstatistik <img src="../images/Algorithm_(kstest2)/math-3e29b728262edf3639e74270b72e638a.png" title="Z=\sqrt{(n_1*n_2)/(n_1+n_2)}*D\,\!" alt="Z=\sqrt{(n_1*n_2)/(n_1+n_2)}*D\,\!" class="tex"> zurück,</p>

  <p>wobei <img src="../images/Algorithm_(kstest2)/math-a7c6c783c5d03fc91d0594b217f56580.png" title="D\,\!" alt="D\,\!" class="tex"> vielleicht <img src="../images/Algorithm_(kstest2)/math-3f75caf92b4b313ec5ec353b2df6a0b0.png" title="D_{n_1,n_2}\,\!" alt="D_{n_1,n_2}\,\!" class="tex">,<img src="../images/Algorithm_(kstest2)/math-4cd60644c5463cc66c7631c167ed3936.png" title="D_{n_1,n_2}^{+} \,\!" alt="D_{n_1,n_2}^{+} \,\!" class="tex">, <img src="../images/Algorithm_(kstest2)/math-8af9c1a0d88a260554650e06fd515607.png" title="D_{n_1,n_2}^{-} \,\!" alt="D_{n_1,n_2}^{-} \,\!" class="tex"> abhängig von der Wahl der Alternativhypothese.</p>

  <p>Die Verteilung der Statistik <img src="../images/Algorithm_(kstest2)/math-07b1048bc60901fe82394ae47282671c.png" title="Z\,\!" alt="Z\,\!" class="tex"> konvergiert asymptotisch zu einer Verteilung nach Smirnov, wenn <img src="../images/Algorithm_(kstest2)/math-8d88a43872d6db6535d8672a15f09ce2.png" title="n_1\,\!" alt="n_1\,\!" class="tex"> und <img src="../images/Algorithm_(kstest2)/math-2f6fac59fce80e76d698bcf5ea77bab6.png" title="n_2\,\!" alt="n_2\,\!" class="tex"> steigen. Es wird die Wahrscheinlichkeit berechnet, unter der Nullhypothese einen Wert der Teststatistik zu erhalten, der so extrem ist, wie der beobachtete Wert.</p>

  <p>Bei <img src="../images/Algorithm_(kstest2)/math-caeb72e22c815c3c25d6a8b427c8aaad.png" title="max(n_1,n_2)\leq 2500\,\!" alt="max(n_1,n_2)\leq 2500\,\!" class="tex"> und <img src="../images/Algorithm_(kstest2)/math-be2983946ebf66a1fd9de27574f27b22.png" title="n_1*n_2\leq 10000\,\!" alt="n_1*n_2\leq 10000\,\!" class="tex"> steht eine genaue Methode nach Kim und Jinrich zur Verfügung. Ansonsten wird <img src="../images/Algorithm_(kstest2)/math-c0f582773fdbd168bbab09a1e6159c46.png" title="p\,\!" alt="p\,\!" class="tex"> berechnet mit Hilfe der von Kim and Jenrich (1973) vorschlagenenen Approximationen.</p>

  <p>Beachten Sie, dass die verwendete Methode nur für kontinuierliche theoretische Verteilungen verwendet wird.</p>

  <p>Diese Methode berechnet die beidseitige Wahrscheinlichkeit. Die einseitigen Wahrscheinlichkeiten werden mit Hilfe der beidseitigen Wahrscheinlichkeit geschätzt. Dies ist eine gute Schätzung für kleine <img src="../images/Algorithm_(kstest2)/math-c0f582773fdbd168bbab09a1e6159c46.png" title="p\,\!" alt="p\,\!" class="tex">, das heißt <img src="../images/Algorithm_(kstest2)/math-cd60a65bcbb8b47dc37b5c879ed79777.png" title="p\leq 0.10\,\!" alt="p\leq 0.10\,\!" class="tex">, wird aber schwächer für größere <img src="../images/Algorithm_(kstest2)/math-c0f582773fdbd168bbab09a1e6159c46.png" title="p\,\!" alt="p\,\!" class="tex">.</p>

  <p>Weitere Einzelheiten zum dem Algorithmus finden Sie unter <a class="external text" href="http://www.originlab.com/pdfs/nagcl09/manual/pdf/g08/g08cdc.pdf" target="_blank"><b>nag_2_sample_ks_test (g08cdc)</b></a>.</p>
